{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#      0=================================0\n",
    "#      |    Kernel Point Convolutions    |\n",
    "#      0=================================0\n",
    "#\n",
    "#\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "#\n",
    "#      Callable script to start a training on AHN dataset\n",
    "#\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "#\n",
    "#      Hugues THOMAS - 06/03/2020\n",
    "#\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "#\n",
    "#           Imports and global variables\n",
    "#       \\**********************************/\n",
    "#\n",
    "\n",
    "# Common libs\n",
    "import signal\n",
    "import os\n",
    "\n",
    "# Dataset\n",
    "from datasets.AHN import *\n",
    "#from datasets.S3DIS import *  # kuramin added\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils.config import Config\n",
    "from utils.trainer import ModelTrainer\n",
    "from models.architectures import KPFCNN\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "#\n",
    "#           Config Class\n",
    "#       \\******************/\n",
    "#\n",
    "class AHNConfig(Config):\n",
    "    \"\"\"\n",
    "    Override the parameters you want to modify for this dataset\n",
    "    \"\"\"\n",
    "\n",
    "    ####################\n",
    "    # Dataset parameters\n",
    "    ####################\n",
    "\n",
    "    # Dataset name\n",
    "    dataset = 'AHN'\n",
    "\n",
    "    # Number of classes in the dataset (This value is overwritten by dataset class when Initializating dataset).\n",
    "    num_classes = None\n",
    "\n",
    "    # Type of task performed on this dataset (also overwritten)\n",
    "    dataset_task = ''\n",
    "\n",
    "    # Number of CPU threads for the input pipeline\n",
    "    input_threads = 10  # 10 kuramin changed\n",
    "\n",
    "    #########################\n",
    "    # Architecture definition\n",
    "    #########################\n",
    "\n",
    "    # Define layers\n",
    "    architecture = ['simple',\n",
    "                    'resnetb',\n",
    "                    'resnetb_strided',\n",
    "                    'resnetb',\n",
    "                    'resnetb',\n",
    "                    'resnetb_strided',\n",
    "                    'resnetb_deformable',\n",
    "                    'resnetb_deformable',\n",
    "                    'resnetb_deformable_strided',\n",
    "                    'resnetb_deformable',\n",
    "                    'resnetb_deformable',\n",
    "                    'resnetb_deformable_strided',\n",
    "                    'resnetb_deformable',\n",
    "                    'resnetb_deformable',\n",
    "                    'nearest_upsample',\n",
    "                    'unary',\n",
    "                    'nearest_upsample',\n",
    "                    'unary',\n",
    "                    'nearest_upsample',\n",
    "                    'unary',\n",
    "                    'nearest_upsample',\n",
    "                    'unary']\n",
    "\n",
    "    ###################\n",
    "    # KPConv parameters\n",
    "    ###################\n",
    "\n",
    "    # Radius of the input sphere\n",
    "    in_radius = 15 #1.5 kuramin changed from s3dis to ahn\n",
    "\n",
    "    # Number of kernel points\n",
    "    num_kernel_points = 15  # kuramin changed back from 9\n",
    "\n",
    "    # Size of the first subsampling grid in meter\n",
    "    first_subsampling_dl = 1.5  # 0.5 # was 2.0 #0.03 kuramin changed from s3dis to ahn\n",
    "\n",
    "    # Radius of convolution in \"number grid cell\". (2.5 is the standard value)\n",
    "    conv_radius = 3.5  # 2.5\n",
    "\n",
    "    # Radius of deformable convolution in \"number grid cell\". Larger so that deformed kernel can spread out\n",
    "    deform_radius = 8.0  # 6.0\n",
    "\n",
    "    # Radius of the area of influence of each kernel point in \"number grid cell\". (1.0 is the standard value)\n",
    "    KP_extent = 1.2\n",
    "\n",
    "    # Behavior of convolutions in ('constant', 'linear', 'gaussian')\n",
    "    KP_influence = 'linear'\n",
    "\n",
    "    # Aggregation function of KPConv in ('closest', 'sum')\n",
    "    aggregation_mode = 'sum'\n",
    "\n",
    "    # Choice of input features\n",
    "    first_features_dim = 128 # kuramin changed back from 8\n",
    "    in_features_dim = 5 # kuramin changed back from 4\n",
    "\n",
    "    # Can the network learn modulations\n",
    "    modulated = False\n",
    "\n",
    "    # Batch normalization parameters\n",
    "    use_batch_norm = True\n",
    "    batch_norm_momentum = 0.02\n",
    "\n",
    "    # Deformable offset loss\n",
    "    # 'point2point' fitting geometry by penalizing distance from deform point to input points\n",
    "    # 'point2plane' fitting geometry by penalizing distance from deform point to input point triplet (not implemented)\n",
    "    deform_fitting_mode = 'point2point'\n",
    "    deform_fitting_power = 1.0              # Multiplier for the fitting/repulsive loss\n",
    "    deform_lr_factor = 0.1                  # Multiplier for learning rate applied to the deformations\n",
    "    repulse_extent = 1.2                    # Distance of repulsion for deformed kernel points\n",
    "\n",
    "    #####################\n",
    "    # Training parameters\n",
    "    #####################\n",
    "\n",
    "    # Maximal number of epochs\n",
    "    max_epoch = 20  # 500  kuramin changed\n",
    "\n",
    "    # Learning rate management\n",
    "    learning_rate = 1e-2\n",
    "    momentum = 0.98\n",
    "    lr_decays = {i: 0.1 ** (1 / 150) for i in range(1, max_epoch)}\n",
    "    grad_clip_norm = 100.0\n",
    "\n",
    "    # Number of batch\n",
    "    batch_num = 6  # target_aver_batch_size will be set equal to it\n",
    "\n",
    "    # Number of steps per epoch (how many batches will be created from dataloader by enumerate(dataloader))\n",
    "    steps_per_epoch = 100 # 50  # kuramin changed back from 100\n",
    "\n",
    "    # Number of validation examples per epoch\n",
    "    validation_size = 100 # 50\n",
    "\n",
    "    # Number of epoch between each checkpoint\n",
    "    checkpoint_gap = 50\n",
    "\n",
    "    # Augmentations\n",
    "    augment_scale_anisotropic = True\n",
    "    augment_symmetries = [True, False, False]\n",
    "    augment_rotation = 'vertical'\n",
    "    augment_scale_min = 0.8\n",
    "    augment_scale_max = 1.2\n",
    "    augment_noise = 0.001\n",
    "    augment_color = 0.8\n",
    "\n",
    "    # The way we balance segmentation loss\n",
    "    #   > 'none': Each point in the whole batch has the same contribution.\n",
    "    #   > 'class': Each class has the same contribution (points are weighted according to class balance)\n",
    "    #   > 'batch': Each cloud in the batch has the same contribution (points are weighted according cloud sizes)\n",
    "    segloss_balance = 'none'\n",
    "\n",
    "    # Do we need to save convergence\n",
    "    saving = True\n",
    "    saving_path = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs is 4\n",
      "GPU_ID is 3\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "#\n",
    "#           Main Call\n",
    "#       \\***************/\n",
    "#\n",
    "#if __name__ == '__main__':\n",
    "\n",
    "############################\n",
    "# Initialize the environment\n",
    "############################\n",
    "\n",
    "# Set which gpu is going to be used\n",
    "number_of_gpus = str(subprocess.check_output([\"nvidia-smi\", \"-L\"])).count('UUID')\n",
    "print('Number of GPUs is', number_of_gpus)\n",
    "\n",
    "if number_of_gpus == 1:\n",
    "    GPU_ID = '0'\n",
    "else:\n",
    "    GPU_ID = '3'\n",
    "print('GPU_ID is', GPU_ID)\n",
    "\n",
    "# Set GPU visible device\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = GPU_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "# Previous chkp\n",
    "###############\n",
    "\n",
    "# Choose here if you want to start training from a previous snapshot (None for new training)\n",
    "# previous_training_path = 'Log_2020-03-19_19-53-27'\n",
    "previous_training_path = ''\n",
    "\n",
    "# Choose index of checkpoint to start from. If None, uses the latest chkp\n",
    "chkp_idx = None\n",
    "if previous_training_path:\n",
    "\n",
    "    # Find all snapshot in the chosen training folder\n",
    "    chkp_path = os.path.join('results', previous_training_path, 'checkpoints')\n",
    "    chkps = [f for f in os.listdir(chkp_path) if f[:4] == 'chkp']\n",
    "\n",
    "    # Find which snapshot to restore\n",
    "    if chkp_idx is None:\n",
    "        chosen_chkp = 'current_chkp.tar'\n",
    "    else:\n",
    "        chosen_chkp = np.sort(chkps)[chkp_idx]\n",
    "    chosen_chkp = os.path.join('results', previous_training_path, 'checkpoints', chosen_chkp)\n",
    "\n",
    "else:\n",
    "    chosen_chkp = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Preparation\n",
      "****************\n",
      "self.deform_layers set to [False, False, True, True, True]\n"
     ]
    }
   ],
   "source": [
    "##############\n",
    "# Prepare Data (several cells)\n",
    "##############\n",
    "\n",
    "print()\n",
    "print('Data Preparation')\n",
    "print('****************')\n",
    "\n",
    "# Initialize configuration class\n",
    "config = AHNConfig()\n",
    "if previous_training_path:\n",
    "    config.load(os.path.join('results', previous_training_path))\n",
    "    config.saving_path = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.saving_path is None\n"
     ]
    }
   ],
   "source": [
    "# Get path from argument if given\n",
    "if len(sys.argv) > 1:\n",
    "    config.saving_path = None  #sys.argv[1]\n",
    "    print('config.saving_path is', config.saving_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.deform_layers set to []\n",
      "\n",
      "Preparing KDTree for cloud 1_rgb, subsampled at 1.500\n",
      "labels has size 4530785 hist is (array([1240229, 2729158,       0,       0,       0,  560786,       0,\n",
      "             0,     612]), array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]))\n",
      "field_list[0].shape[0] is 355719\n",
      "10.0 MB loaded in 4.6s\n",
      "\n",
      "Preparing potentials\n",
      "Done in 0.7s\n",
      "\n",
      "self.deform_layers set to []\n",
      "\n",
      "Preparing KDTree for cloud 2_rgb, subsampled at 1.500\n",
      "labels has size 5595766 hist is (array([ 939744, 4184252,       0,       0,       0,  471138,       0,\n",
      "             0,     632]), array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]))\n",
      "field_list[0].shape[0] is 382707\n",
      "10.7 MB loaded in 5.4s\n",
      "\n",
      "Preparing potentials\n",
      "Done in 0.7s\n",
      "\n",
      "Preparing reprojection indices for testing\n",
      "(5595766,)\n",
      "(5595766,)\n",
      "2_rgb done in 9.1s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize datasets\n",
    "training_dataset = AHNDataset(config, set='training', use_potentials=True)  # kuramin commented\n",
    "test_dataset = AHNDataset(config, set='validation', use_potentials=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize samplers\n",
    "training_sampler = AHNSampler(training_dataset)  # defines the strategy to draw samples from the dataset\n",
    "test_sampler = AHNSampler(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the dataloader\n",
    "r\"\"\"\n",
    "    dataset (Dataset): dataset from which to load the data.\n",
    "    batch_size (int, optional): how many samples per batch to load\n",
    "        (default: ``1``).\n",
    "    shuffle (bool, optional): set to ``True`` to have the data reshuffled\n",
    "        at every epoch (default: ``False``).\n",
    "    sampler (Sampler, optional): defines the strategy to draw samples from\n",
    "        the dataset. If specified, :attr:`shuffle` must be ``False``.\n",
    "    batch_sampler (Sampler, optional): like :attr:`sampler`, but returns a batch of\n",
    "        indices at a time. Mutually exclusive with :attr:`batch_size`,\n",
    "        :attr:`shuffle`, :attr:`sampler`, and :attr:`drop_last`.\n",
    "    num_workers (int, optional): how many subprocesses to use for data\n",
    "        loading. ``0`` means that the data will be loaded in the main process.\n",
    "        (default: ``0``)\n",
    "    collate_fn (callable, optional): merges a list of samples to form a\n",
    "        mini-batch of Tensor(s).  Used when using batched loading from a\n",
    "        map-style dataset.\n",
    "    pin_memory (bool, optional): If ``True``, the data loader will copy Tensors\n",
    "        into CUDA pinned memory before returning them.  If your data elements\n",
    "        are a custom type, or your :attr:`collate_fn` returns a batch that is a custom type,\n",
    "        see the example below.\n",
    "    drop_last (bool, optional): set to ``True`` to drop the last incomplete batch,\n",
    "        if the dataset size is not divisible by the batch size. If ``False`` and\n",
    "        the size of dataset is not divisible by the batch size, then the last batch\n",
    "        will be smaller. (default: ``False``)\n",
    "    timeout (numeric, optional): if positive, the timeout value for collecting a batch\n",
    "        from workers. Should always be non-negative. (default: ``0``)\n",
    "    worker_init_fn (callable, optional): If not ``None``, this will be called on each\n",
    "        worker subprocess with the worker id (an int in ``[0, num_workers - 1]``) as\n",
    "        input, after seeding and before data loading. (default: ``None``)\n",
    "\"\"\"\n",
    "training_loader = DataLoader(training_dataset,\n",
    "                             batch_size=1,\n",
    "                             sampler=training_sampler,\n",
    "                             collate_fn=AHNCollate,\n",
    "                             num_workers=config.input_threads,\n",
    "                             pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size=1,\n",
    "                         sampler=test_sampler,\n",
    "                         collate_fn=AHNCollate,\n",
    "                         num_workers=config.input_threads,\n",
    "                         pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Calibration (use verbose=True for more details)\n",
      "\n",
      "Previous calibration found:\n",
      "Check batch limit dictionary\n",
      "\u001b[91m\"potentials_15.000_1.500_6\": ?\u001b[0m\n",
      "Check neighbors limit dictionary\n",
      "\u001b[91m\"1.500_5.250\": ?\u001b[0m\n",
      "\u001b[91m\"3.000_10.500\": ?\u001b[0m\n",
      "\u001b[91m\"6.000_48.000\": ?\u001b[0m\n",
      "\u001b[91m\"12.000_96.000\": ?\u001b[0m\n",
      "\u001b[91m\"24.000_192.000\": ?\u001b[0m\n",
      "Step     1, estim_aver_bat_size = 0.10, b =  1, bat_lim =    501, error =  5, sm_append = 5.90000, lets_finer =5.90000, max_a_sm_err = 5.9000000, low_pass =  10, finer = 0\n",
      "Step     2, estim_aver_bat_size = 0.19, b =  1, bat_lim =   1001, error =  5, sm_append = 5.81000, lets_finer =5.81000, max_a_sm_err = 5.9000000, low_pass =  10, finer = 0\n",
      "Step     3, estim_aver_bat_size = 0.27, b =  1, bat_lim =   1501, error =  5, sm_append = 5.72900, lets_finer =5.72900, max_a_sm_err = 5.9000000, low_pass =  10, finer = 0\n",
      "Step     4, estim_aver_bat_size = 0.34, b =  1, bat_lim =   2001, error =  5, sm_append = 5.65610, lets_finer =5.65610, max_a_sm_err = 5.9000000, low_pass =  10, finer = 0\n",
      "Step     5, estim_aver_bat_size = 0.41, b =  1, bat_lim =   2501, error =  5, sm_append = 5.59049, lets_finer =5.59049, max_a_sm_err = 5.9000000, low_pass =  10, finer = 0\n",
      "Step     6, estim_aver_bat_size = 0.47, b =  1, bat_lim =   3001, error =  5, sm_append = 5.53144, lets_finer =5.53144, max_a_sm_err = 5.9000000, low_pass =  10, finer = 0\n",
      "Step     7, estim_aver_bat_size = 0.52, b =  1, bat_lim =   3501, error =  5, sm_append = 5.47830, lets_finer =5.47830, max_a_sm_err = 5.9000000, low_pass =  10, finer = 0\n",
      "Step     8, estim_aver_bat_size = 0.57, b =  1, bat_lim =   4001, error =  5, sm_append = 5.43047, lets_finer =5.43047, max_a_sm_err = 5.9000000, low_pass =  10, finer = 0\n",
      "Step     9, estim_aver_bat_size = 0.61, b =  1, bat_lim =   4501, error =  5, sm_append = 5.38742, lets_finer =5.38742, max_a_sm_err = 5.9000000, low_pass =  10, finer = 0\n",
      "Step    10, estim_aver_bat_size = 0.75, b =  2, bat_lim =   4901, error =  4, sm_append = 5.24868, lets_finer =5.24868, max_a_sm_err = 5.9000000, low_pass =  10, finer = 0\n",
      "Step    11, estim_aver_bat_size = 0.88, b =  2, bat_lim =   5301, error =  4, sm_append = 5.12381, lets_finer =5.12381, max_a_sm_err = 5.8100000, low_pass =  10, finer = 0\n",
      "Step    12, estim_aver_bat_size = 0.89, b =  1, bat_lim =   5801, error =  5, sm_append = 5.11143, lets_finer =5.11143, max_a_sm_err = 5.7290000, low_pass =  10, finer = 0\n",
      "Step    13, estim_aver_bat_size = 0.90, b =  1, bat_lim =   6301, error =  5, sm_append = 5.10029, lets_finer =5.10029, max_a_sm_err = 5.6561000, low_pass =  10, finer = 0\n",
      "Step    14, estim_aver_bat_size = 0.91, b =  1, bat_lim =   6801, error =  5, sm_append = 5.09026, lets_finer =5.09026, max_a_sm_err = 5.5904900, low_pass =  10, finer = 0\n",
      "Step    15, estim_aver_bat_size = 1.02, b =  2, bat_lim =   7201, error =  4, sm_append = 4.98123, lets_finer =4.98123, max_a_sm_err = 5.5314410, low_pass =  10, finer = 0\n",
      "Step    16, estim_aver_bat_size = 1.32, b =  4, bat_lim =   7401, error =  2, sm_append = 4.68311, lets_finer =4.68311, max_a_sm_err = 5.4782969, low_pass =  10, finer = 0\n",
      "Step    17, estim_aver_bat_size = 1.59, b =  4, bat_lim =   7601, error =  2, sm_append = 4.41480, lets_finer =4.41480, max_a_sm_err = 5.4304672, low_pass =  10, finer = 0\n",
      "Step    18, estim_aver_bat_size = 1.53, b =  1, bat_lim =   8101, error =  5, sm_append = 4.47332, lets_finer =4.47332, max_a_sm_err = 5.3874205, low_pass =  10, finer = 0\n",
      "Step    19, estim_aver_bat_size = 1.87, b =  5, bat_lim =   8201, error =  1, sm_append = 4.12599, lets_finer =4.12599, max_a_sm_err = 5.2486784, low_pass =  10, finer = 0\n",
      "Step    20, estim_aver_bat_size = 1.79, b =  1, bat_lim =   8701, error =  5, sm_append = 4.21339, lets_finer =4.21339, max_a_sm_err = 5.1238106, low_pass =  10, finer = 0\n",
      "Step    21, estim_aver_bat_size = 1.71, b =  1, bat_lim =   9201, error =  5, sm_append = 4.29205, lets_finer =4.29205, max_a_sm_err = 5.1114295, low_pass =  10, finer = 0\n",
      "Step    22, estim_aver_bat_size = 1.64, b =  1, bat_lim =   9701, error =  5, sm_append = 4.36284, lets_finer =4.36284, max_a_sm_err = 5.1002866, low_pass =  10, finer = 0\n",
      "Step    23, estim_aver_bat_size = 1.97, b =  5, bat_lim =   9801, error =  1, sm_append = 4.02656, lets_finer =4.02656, max_a_sm_err = 5.0902579, low_pass =  10, finer = 0\n",
      "Step    24, estim_aver_bat_size = 2.28, b =  5, bat_lim =   9901, error =  1, sm_append = 3.72390, lets_finer =3.72390, max_a_sm_err = 4.9812321, low_pass =  10, finer = 0\n",
      "Step    25, estim_aver_bat_size = 2.45, b =  4, bat_lim =  10101, error =  2, sm_append = 3.55151, lets_finer =3.55151, max_a_sm_err = 4.6831089, low_pass =  10, finer = 0\n",
      "Step    26, estim_aver_bat_size = 3.80, b = 16, bat_lim =   9101, error = -10, sm_append = 2.19636, lets_finer =2.19636, max_a_sm_err = 4.4733182, low_pass =  10, finer = 0\n",
      "Step    27, estim_aver_bat_size = 5.12, b = 17, bat_lim =   8001, error = -11, sm_append = 0.87673, lets_finer =0.87673, max_a_sm_err = 4.4733182, low_pass = 100, finer = 1\n",
      "Step    28, estim_aver_bat_size = 5.22, b = 15, bat_lim =   7101, error = -9, sm_append = 0.77796, lets_finer =0.77796, max_a_sm_err = 4.3628441, low_pass = 100, finer = 1\n",
      "Step    29, estim_aver_bat_size = 5.34, b = 17, bat_lim =   6001, error = -11, sm_append = 0.66018, lets_finer =0.66018, max_a_sm_err = 4.3628441, low_pass = 100, finer = 1\n",
      "Step    30, estim_aver_bat_size = 5.47, b = 18, bat_lim =   4801, error = -12, sm_append = 0.53358, lets_finer =0.53358, max_a_sm_err = 4.3628441, low_pass = 100, finer = 1\n",
      "Step    31, estim_aver_bat_size = 5.59, b = 18, bat_lim =   3601, error = -12, sm_append = 0.40824, lets_finer =0.40824, max_a_sm_err = 4.3628441, low_pass = 100, finer = 1\n",
      "Step    32, estim_aver_bat_size = 5.71, b = 17, bat_lim =   2501, error = -11, sm_append = 0.29416, lets_finer =0.29416, max_a_sm_err = 4.0265597, low_pass = 100, finer = 1\n",
      "Step    33, estim_aver_bat_size = 5.79, b = 14, bat_lim =   1701, error = -8, sm_append = 0.21122, lets_finer =0.21122, max_a_sm_err = 3.7239037, low_pass = 100, finer = 1\n",
      "Step    34, estim_aver_bat_size = 5.93, b = 20, bat_lim =    301, error = -14, sm_append = 0.06911, lets_finer =0.06911, max_a_sm_err = 3.5515133, low_pass = 100, finer = 1\n",
      "Step    35, estim_aver_bat_size = 6.04, b = 17, bat_lim =   -799, error = -11, sm_append = -0.04159, lets_finer =0.04159, max_a_sm_err = 2.1963620, low_pass = 100, finer = 1\n",
      "Step    36, estim_aver_bat_size = 6.11, b = 13, bat_lim =  -1499, error = -7, sm_append = -0.11117, lets_finer =0.11117, max_a_sm_err = 0.8767258, low_pass = 100, finer = 1\n",
      "Step    37, estim_aver_bat_size = 6.18, b = 13, bat_lim =  -2199, error = -7, sm_append = -0.18006, lets_finer =0.18006, max_a_sm_err = 0.7779585, low_pass = 100, finer = 1\n",
      "Step    38, estim_aver_bat_size = 6.21, b =  9, bat_lim =  -2499, error = -3, sm_append = -0.20826, lets_finer =0.20826, max_a_sm_err = 0.6601790, low_pass = 100, finer = 1\n",
      "Step    39, estim_aver_bat_size = 6.24, b =  9, bat_lim =  -2799, error = -3, sm_append = -0.23618, lets_finer =0.23618, max_a_sm_err = 0.5335772, low_pass = 100, finer = 1\n",
      "Step    40, estim_aver_bat_size = 6.27, b = 10, bat_lim =  -3199, error = -4, sm_append = -0.27381, lets_finer =0.27381, max_a_sm_err = 0.4082414, low_pass = 100, finer = 1\n",
      "Step    41, estim_aver_bat_size = 6.33, b = 12, bat_lim =  -3799, error = -6, sm_append = -0.33108, lets_finer =0.33108, max_a_sm_err = 0.3310752, low_pass = 100, finer = 1\n",
      "Step    42, estim_aver_bat_size = 6.36, b =  9, bat_lim =  -4099, error = -3, sm_append = -0.35776, lets_finer =0.35776, max_a_sm_err = 0.3577645, low_pass = 100, finer = 1\n",
      "Step    43, estim_aver_bat_size = 6.39, b = 10, bat_lim =  -4499, error = -4, sm_append = -0.39419, lets_finer =0.39419, max_a_sm_err = 0.3941868, low_pass = 100, finer = 1\n",
      "Step    44, estim_aver_bat_size = 6.46, b = 13, bat_lim =  -5199, error = -7, sm_append = -0.46024, lets_finer =0.46024, max_a_sm_err = 0.4602450, low_pass = 100, finer = 1\n",
      "Step    45, estim_aver_bat_size = 6.55, b = 15, bat_lim =  -6099, error = -9, sm_append = -0.54564, lets_finer =0.54564, max_a_sm_err = 0.5456425, low_pass = 100, finer = 1\n",
      "Step    46, estim_aver_bat_size = 6.49, b =  1, bat_lim =  -5599, error =  5, sm_append = -0.49019, lets_finer =0.49019, max_a_sm_err = 0.5456425, low_pass = 100, finer = 1\n",
      "Step    47, estim_aver_bat_size = 6.44, b =  1, bat_lim =  -5099, error =  5, sm_append = -0.43528, lets_finer =0.43528, max_a_sm_err = 0.5456425, low_pass = 100, finer = 1\n",
      "Step    48, estim_aver_bat_size = 6.38, b =  1, bat_lim =  -4599, error =  5, sm_append = -0.38093, lets_finer =0.38093, max_a_sm_err = 0.5456425, low_pass = 100, finer = 1\n",
      "Step    49, estim_aver_bat_size = 6.33, b =  1, bat_lim =  -4099, error =  5, sm_append = -0.32712, lets_finer =0.32712, max_a_sm_err = 0.5456425, low_pass = 100, finer = 1\n",
      "Step    50, estim_aver_bat_size = 6.27, b =  1, bat_lim =  -3599, error =  5, sm_append = -0.27385, lets_finer =0.27385, max_a_sm_err = 0.5456425, low_pass = 100, finer = 1\n",
      "Step    51, estim_aver_bat_size = 6.22, b =  1, bat_lim =  -3099, error =  5, sm_append = -0.22111, lets_finer =0.22111, max_a_sm_err = 0.5456425, low_pass = 100, finer = 1\n",
      "Step    52, estim_aver_bat_size = 6.17, b =  1, bat_lim =  -2599, error =  5, sm_append = -0.16890, lets_finer =0.16890, max_a_sm_err = 0.5456425, low_pass = 100, finer = 1\n",
      "Step    53, estim_aver_bat_size = 6.12, b =  1, bat_lim =  -2099, error =  5, sm_append = -0.11721, lets_finer =0.11721, max_a_sm_err = 0.5456425, low_pass = 100, finer = 1\n",
      "Step    54, estim_aver_bat_size = 6.07, b =  1, bat_lim =  -1599, error =  5, sm_append = -0.06604, lets_finer =0.06604, max_a_sm_err = 0.5456425, low_pass = 100, finer = 1\n",
      "Step    55, estim_aver_bat_size = 6.02, b =  1, bat_lim =  -1099, error =  5, sm_append = -0.01538, lets_finer =0.01538, max_a_sm_err = 0.4901861, low_pass = 100, finer = 1\n",
      "Step    56, estim_aver_bat_size = 5.97, b =  1, bat_lim =   -599, error =  5, sm_append = 0.03477, lets_finer =0.03477, max_a_sm_err = 0.4352842, low_pass = 100, finer = 1\n",
      "Step    57, estim_aver_bat_size = 5.92, b =  1, bat_lim =    -99, error =  5, sm_append = 0.08443, lets_finer =0.08443, max_a_sm_err = 0.3809314, low_pass = 100, finer = 1\n",
      "Step    58, estim_aver_bat_size = 5.87, b =  1, bat_lim =    401, error =  5, sm_append = 0.13358, lets_finer =0.13358, max_a_sm_err = 0.3271221, low_pass = 100, finer = 1\n",
      "Step    59, estim_aver_bat_size = 5.82, b =  1, bat_lim =    901, error =  5, sm_append = 0.18225, lets_finer =0.18225, max_a_sm_err = 0.2738508, low_pass = 100, finer = 1\n",
      "Step    60, estim_aver_bat_size = 5.77, b =  1, bat_lim =   1401, error =  5, sm_append = 0.23042, lets_finer =0.23042, max_a_sm_err = 0.2304238, low_pass = 100, finer = 1\n",
      "Step    61, estim_aver_bat_size = 5.72, b =  1, bat_lim =   1901, error =  5, sm_append = 0.27812, lets_finer =0.27812, max_a_sm_err = 0.2781196, low_pass = 100, finer = 1\n",
      "Step    62, estim_aver_bat_size = 5.67, b =  1, bat_lim =   2401, error =  5, sm_append = 0.32534, lets_finer =0.32534, max_a_sm_err = 0.3253384, low_pass = 100, finer = 1\n",
      "Step    63, estim_aver_bat_size = 5.63, b =  1, bat_lim =   2901, error =  5, sm_append = 0.37209, lets_finer =0.37209, max_a_sm_err = 0.3720850, low_pass = 100, finer = 1\n",
      "Step    64, estim_aver_bat_size = 5.58, b =  1, bat_lim =   3401, error =  5, sm_append = 0.41836, lets_finer =0.41836, max_a_sm_err = 0.4183642, low_pass = 100, finer = 1\n",
      "Step    65, estim_aver_bat_size = 5.54, b =  1, bat_lim =   3901, error =  5, sm_append = 0.46418, lets_finer =0.46418, max_a_sm_err = 0.4641805, low_pass = 100, finer = 1\n",
      "Step    66, estim_aver_bat_size = 5.49, b =  1, bat_lim =   4401, error =  5, sm_append = 0.50954, lets_finer =0.50954, max_a_sm_err = 0.5095387, low_pass = 100, finer = 1\n",
      "Step    67, estim_aver_bat_size = 5.45, b =  1, bat_lim =   4901, error =  5, sm_append = 0.55444, lets_finer =0.55444, max_a_sm_err = 0.5544433, low_pass = 100, finer = 1\n",
      "Step    68, estim_aver_bat_size = 5.40, b =  1, bat_lim =   5401, error =  5, sm_append = 0.59890, lets_finer =0.59890, max_a_sm_err = 0.5988989, low_pass = 100, finer = 1\n",
      "Step    69, estim_aver_bat_size = 5.36, b =  1, bat_lim =   5901, error =  5, sm_append = 0.64291, lets_finer =0.64291, max_a_sm_err = 0.6429099, low_pass = 100, finer = 1\n",
      "Step    70, estim_aver_bat_size = 5.31, b =  1, bat_lim =   6401, error =  5, sm_append = 0.68648, lets_finer =0.68648, max_a_sm_err = 0.6864808, low_pass = 100, finer = 1\n",
      "Step    71, estim_aver_bat_size = 5.27, b =  1, bat_lim =   6901, error =  5, sm_append = 0.72962, lets_finer =0.72962, max_a_sm_err = 0.7296160, low_pass = 100, finer = 1\n",
      "Step    72, estim_aver_bat_size = 5.23, b =  1, bat_lim =   7401, error =  5, sm_append = 0.77232, lets_finer =0.77232, max_a_sm_err = 0.7723198, low_pass = 100, finer = 1\n",
      "Step    73, estim_aver_bat_size = 5.19, b =  1, bat_lim =   7901, error =  5, sm_append = 0.81460, lets_finer =0.81460, max_a_sm_err = 0.8145966, low_pass = 100, finer = 1\n",
      "Step    74, estim_aver_bat_size = 5.14, b =  1, bat_lim =   8401, error =  5, sm_append = 0.85645, lets_finer =0.85645, max_a_sm_err = 0.8564507, low_pass = 100, finer = 1\n",
      "Step    75, estim_aver_bat_size = 5.10, b =  1, bat_lim =   8901, error =  5, sm_append = 0.89789, lets_finer =0.89789, max_a_sm_err = 0.8978862, low_pass = 100, finer = 1\n",
      "Step    76, estim_aver_bat_size = 5.06, b =  1, bat_lim =   9401, error =  5, sm_append = 0.93891, lets_finer =0.93891, max_a_sm_err = 0.9389073, low_pass = 100, finer = 1\n",
      "Step    77, estim_aver_bat_size = 5.02, b =  1, bat_lim =   9901, error =  5, sm_append = 0.97952, lets_finer =0.97952, max_a_sm_err = 0.9795182, low_pass = 100, finer = 1\n",
      "Step    78, estim_aver_bat_size = 4.98, b =  1, bat_lim =  10401, error =  5, sm_append = 1.01972, lets_finer =1.01972, max_a_sm_err = 1.0197230, low_pass = 100, finer = 1\n",
      "Step    79, estim_aver_bat_size = 5.11, b = 18, bat_lim =   9201, error = -12, sm_append = 0.88953, lets_finer =0.88953, max_a_sm_err = 1.0197230, low_pass = 100, finer = 1\n",
      "Step    80, estim_aver_bat_size = 5.22, b = 16, bat_lim =   8201, error = -10, sm_append = 0.78063, lets_finer =0.78063, max_a_sm_err = 1.0197230, low_pass = 100, finer = 1\n",
      "Step    81, estim_aver_bat_size = 5.36, b = 19, bat_lim =   6901, error = -13, sm_append = 0.64282, lets_finer =0.64282, max_a_sm_err = 1.0197230, low_pass = 100, finer = 1\n",
      "Step    82, estim_aver_bat_size = 5.49, b = 19, bat_lim =   5601, error = -13, sm_append = 0.50640, lets_finer =0.50640, max_a_sm_err = 1.0197230, low_pass = 100, finer = 1\n",
      "Step    83, estim_aver_bat_size = 5.62, b = 18, bat_lim =   4401, error = -12, sm_append = 0.38133, lets_finer =0.38133, max_a_sm_err = 1.0197230, low_pass = 100, finer = 1\n",
      "Step    84, estim_aver_bat_size = 5.76, b = 20, bat_lim =   3001, error = -14, sm_append = 0.23752, lets_finer =0.23752, max_a_sm_err = 1.0197230, low_pass = 100, finer = 1\n",
      "Step    85, estim_aver_bat_size = 5.87, b = 17, bat_lim =   1901, error = -11, sm_append = 0.12514, lets_finer =0.12514, max_a_sm_err = 1.0197230, low_pass = 100, finer = 1\n",
      "Step    86, estim_aver_bat_size = 6.04, b = 22, bat_lim =    301, error = -16, sm_append = -0.03611, lets_finer =0.03611, max_a_sm_err = 1.0197230, low_pass = 100, finer = 1\n",
      "Step    87, estim_aver_bat_size = 6.14, b = 16, bat_lim =   -699, error = -10, sm_append = -0.13575, lets_finer =0.13575, max_a_sm_err = 1.0197230, low_pass = 100, finer = 1\n",
      "Step    88, estim_aver_bat_size = 6.28, b = 21, bat_lim =  -2199, error = -15, sm_append = -0.28439, lets_finer =0.28439, max_a_sm_err = 0.8895258, low_pass = 100, finer = 1\n",
      "Step    89, estim_aver_bat_size = 6.33, b = 11, bat_lim =  -2699, error = -5, sm_append = -0.33155, lets_finer =0.33155, max_a_sm_err = 0.7806306, low_pass = 100, finer = 1\n",
      "Step    90, estim_aver_bat_size = 6.35, b =  8, bat_lim =  -2899, error = -2, sm_append = -0.34823, lets_finer =0.34823, max_a_sm_err = 0.6428243, low_pass = 100, finer = 1\n",
      "Step    91, estim_aver_bat_size = 6.36, b =  8, bat_lim =  -3099, error = -2, sm_append = -0.36475, lets_finer =0.36475, max_a_sm_err = 0.5063960, low_pass = 100, finer = 1\n",
      "Step    92, estim_aver_bat_size = 6.47, b = 17, bat_lim =  -4199, error = -11, sm_append = -0.47110, lets_finer =0.47110, max_a_sm_err = 0.4711002, low_pass = 100, finer = 1\n",
      "Step    93, estim_aver_bat_size = 6.51, b = 10, bat_lim =  -4599, error = -4, sm_append = -0.50639, lets_finer =0.50639, max_a_sm_err = 0.5063892, low_pass = 100, finer = 1\n",
      "Step    94, estim_aver_bat_size = 6.61, b = 17, bat_lim =  -5699, error = -11, sm_append = -0.61133, lets_finer =0.61133, max_a_sm_err = 0.6113253, low_pass = 100, finer = 1\n",
      "Step    95, estim_aver_bat_size = 6.64, b =  9, bat_lim =  -5999, error = -3, sm_append = -0.63521, lets_finer =0.63521, max_a_sm_err = 0.6352121, low_pass = 100, finer = 1\n",
      "Step    96, estim_aver_bat_size = 6.78, b = 21, bat_lim =  -7499, error = -15, sm_append = -0.77886, lets_finer =0.77886, max_a_sm_err = 0.7788600, low_pass = 100, finer = 1\n",
      "Step    97, estim_aver_bat_size = 6.83, b = 12, bat_lim =  -8099, error = -6, sm_append = -0.83107, lets_finer =0.83107, max_a_sm_err = 0.8310714, low_pass = 100, finer = 1\n",
      "Step    98, estim_aver_bat_size = 6.94, b = 18, bat_lim =  -9299, error = -12, sm_append = -0.94276, lets_finer =0.94276, max_a_sm_err = 0.9427606, low_pass = 100, finer = 1\n",
      "Step    99, estim_aver_bat_size = 6.88, b =  1, bat_lim =  -8799, error =  5, sm_append = -0.88333, lets_finer =0.88333, max_a_sm_err = 0.9427606, low_pass = 100, finer = 1\n",
      "Step   100, estim_aver_bat_size = 6.82, b =  1, bat_lim =  -8299, error =  5, sm_append = -0.82450, lets_finer =0.82450, max_a_sm_err = 0.9427606, low_pass = 100, finer = 1\n",
      "Step   101, estim_aver_bat_size = 6.77, b =  1, bat_lim =  -7799, error =  5, sm_append = -0.76625, lets_finer =0.76625, max_a_sm_err = 0.9427606, low_pass = 100, finer = 1\n",
      "Step   102, estim_aver_bat_size = 6.71, b =  1, bat_lim =  -7299, error =  5, sm_append = -0.70859, lets_finer =0.70859, max_a_sm_err = 0.9427606, low_pass = 100, finer = 1\n",
      "Step   103, estim_aver_bat_size = 6.65, b =  1, bat_lim =  -6799, error =  5, sm_append = -0.65151, lets_finer =0.65151, max_a_sm_err = 0.9427606, low_pass = 100, finer = 1\n",
      "Step   104, estim_aver_bat_size = 6.59, b =  1, bat_lim =  -6299, error =  5, sm_append = -0.59499, lets_finer =0.59499, max_a_sm_err = 0.9427606, low_pass = 100, finer = 1\n",
      "Step   105, estim_aver_bat_size = 6.54, b =  1, bat_lim =  -5799, error =  5, sm_append = -0.53904, lets_finer =0.53904, max_a_sm_err = 0.9427606, low_pass = 100, finer = 1\n",
      "Step   106, estim_aver_bat_size = 6.48, b =  1, bat_lim =  -5299, error =  5, sm_append = -0.48365, lets_finer =0.48365, max_a_sm_err = 0.9427606, low_pass = 100, finer = 1\n",
      "Step   107, estim_aver_bat_size = 6.43, b =  1, bat_lim =  -4799, error =  5, sm_append = -0.42881, lets_finer =0.42881, max_a_sm_err = 0.9427606, low_pass = 100, finer = 1\n",
      "Step   108, estim_aver_bat_size = 6.37, b =  1, bat_lim =  -4299, error =  5, sm_append = -0.37453, lets_finer =0.37453, max_a_sm_err = 0.8833330, low_pass = 100, finer = 1\n",
      "Step   109, estim_aver_bat_size = 6.32, b =  1, bat_lim =  -3799, error =  5, sm_append = -0.32078, lets_finer =0.32078, max_a_sm_err = 0.8244997, low_pass = 100, finer = 1\n",
      "Step   110, estim_aver_bat_size = 6.27, b =  1, bat_lim =  -3299, error =  5, sm_append = -0.26757, lets_finer =0.26757, max_a_sm_err = 0.7662547, low_pass = 100, finer = 1\n",
      "Step   111, estim_aver_bat_size = 6.21, b =  1, bat_lim =  -2799, error =  5, sm_append = -0.21490, lets_finer =0.21490, max_a_sm_err = 0.7085922, low_pass = 100, finer = 1\n",
      "Step   112, estim_aver_bat_size = 6.16, b =  1, bat_lim =  -2299, error =  5, sm_append = -0.16275, lets_finer =0.16275, max_a_sm_err = 0.6515062, low_pass = 100, finer = 1\n",
      "Step   113, estim_aver_bat_size = 6.11, b =  1, bat_lim =  -1799, error =  5, sm_append = -0.11112, lets_finer =0.11112, max_a_sm_err = 0.5949912, low_pass = 100, finer = 1\n",
      "Step   114, estim_aver_bat_size = 6.06, b =  1, bat_lim =  -1299, error =  5, sm_append = -0.06001, lets_finer =0.06001, max_a_sm_err = 0.5390413, low_pass = 100, finer = 1\n",
      "Step   115, estim_aver_bat_size = 6.01, b =  1, bat_lim =   -799, error =  5, sm_append = -0.00941, lets_finer =0.00941, max_a_sm_err = 0.4836509, low_pass = 100, finer = 1\n",
      "Step   116, estim_aver_bat_size = 5.96, b =  1, bat_lim =   -299, error =  5, sm_append = 0.04068, lets_finer =0.04068, max_a_sm_err = 0.4288143, low_pass = 100, finer = 1\n",
      "Step   117, estim_aver_bat_size = 5.91, b =  1, bat_lim =    201, error =  5, sm_append = 0.09028, lets_finer =0.09028, max_a_sm_err = 0.3745262, low_pass = 100, finer = 1\n",
      "Step   118, estim_aver_bat_size = 5.86, b =  1, bat_lim =    701, error =  5, sm_append = 0.13937, lets_finer =0.13937, max_a_sm_err = 0.3207809, low_pass = 100, finer = 1\n",
      "Step   119, estim_aver_bat_size = 5.81, b =  1, bat_lim =   1201, error =  5, sm_append = 0.18798, lets_finer =0.18798, max_a_sm_err = 0.2675731, low_pass = 100, finer = 1\n",
      "Step   120, estim_aver_bat_size = 5.76, b =  1, bat_lim =   1701, error =  5, sm_append = 0.23610, lets_finer =0.23610, max_a_sm_err = 0.2361013, low_pass = 100, finer = 1\n",
      "Step   121, estim_aver_bat_size = 5.72, b =  1, bat_lim =   2201, error =  5, sm_append = 0.28374, lets_finer =0.28374, max_a_sm_err = 0.2837403, low_pass = 100, finer = 1\n",
      "Step   122, estim_aver_bat_size = 5.67, b =  1, bat_lim =   2701, error =  5, sm_append = 0.33090, lets_finer =0.33090, max_a_sm_err = 0.3309029, low_pass = 100, finer = 1\n",
      "Step   123, estim_aver_bat_size = 5.62, b =  1, bat_lim =   3201, error =  5, sm_append = 0.37759, lets_finer =0.37759, max_a_sm_err = 0.3775938, low_pass = 100, finer = 1\n",
      "Step   124, estim_aver_bat_size = 5.58, b =  1, bat_lim =   3701, error =  5, sm_append = 0.42382, lets_finer =0.42382, max_a_sm_err = 0.4238179, low_pass = 100, finer = 1\n",
      "Step   125, estim_aver_bat_size = 5.53, b =  1, bat_lim =   4201, error =  5, sm_append = 0.46958, lets_finer =0.46958, max_a_sm_err = 0.4695797, low_pass = 100, finer = 1\n",
      "Step   126, estim_aver_bat_size = 5.49, b =  1, bat_lim =   4701, error =  5, sm_append = 0.51488, lets_finer =0.51488, max_a_sm_err = 0.5148839, low_pass = 100, finer = 1\n",
      "Step   127, estim_aver_bat_size = 5.44, b =  1, bat_lim =   5201, error =  5, sm_append = 0.55974, lets_finer =0.55974, max_a_sm_err = 0.5597351, low_pass = 100, finer = 1\n",
      "Step   128, estim_aver_bat_size = 5.40, b =  1, bat_lim =   5701, error =  5, sm_append = 0.60414, lets_finer =0.60414, max_a_sm_err = 0.6041377, low_pass = 100, finer = 1\n",
      "Step   129, estim_aver_bat_size = 5.35, b =  1, bat_lim =   6201, error =  5, sm_append = 0.64810, lets_finer =0.64810, max_a_sm_err = 0.6480964, low_pass = 100, finer = 1\n",
      "Step   130, estim_aver_bat_size = 5.31, b =  1, bat_lim =   6701, error =  5, sm_append = 0.69162, lets_finer =0.69162, max_a_sm_err = 0.6916154, low_pass = 100, finer = 1\n",
      "Step   131, estim_aver_bat_size = 5.27, b =  1, bat_lim =   7201, error =  5, sm_append = 0.73470, lets_finer =0.73470, max_a_sm_err = 0.7346992, low_pass = 100, finer = 1\n",
      "Step   132, estim_aver_bat_size = 5.22, b =  1, bat_lim =   7701, error =  5, sm_append = 0.77735, lets_finer =0.77735, max_a_sm_err = 0.7773522, low_pass = 100, finer = 1\n",
      "Step   133, estim_aver_bat_size = 5.18, b =  1, bat_lim =   8201, error =  5, sm_append = 0.81958, lets_finer =0.81958, max_a_sm_err = 0.8195787, low_pass = 100, finer = 1\n",
      "Step   134, estim_aver_bat_size = 5.18, b =  5, bat_lim =   8301, error =  1, sm_append = 0.82138, lets_finer =0.82138, max_a_sm_err = 0.8213829, low_pass = 100, finer = 1\n",
      "Step   135, estim_aver_bat_size = 5.20, b =  7, bat_lim =   8201, error = -1, sm_append = 0.80317, lets_finer =0.80317, max_a_sm_err = 0.8213829, low_pass = 100, finer = 1\n",
      "Step   136, estim_aver_bat_size = 5.20, b =  6, bat_lim =   8201, error =  0, sm_append = 0.79514, lets_finer =0.79514, max_a_sm_err = 0.8213829, low_pass = 100, finer = 1\n",
      "Step   137, estim_aver_bat_size = 5.21, b =  6, bat_lim =   8201, error =  0, sm_append = 0.78719, lets_finer =0.78719, max_a_sm_err = 0.8213829, low_pass = 100, finer = 1\n",
      "Step   138, estim_aver_bat_size = 5.21, b =  5, bat_lim =   8301, error =  1, sm_append = 0.78931, lets_finer =0.78931, max_a_sm_err = 0.8213829, low_pass = 100, finer = 1\n",
      "Step   139, estim_aver_bat_size = 5.22, b =  6, bat_lim =   8301, error =  0, sm_append = 0.78142, lets_finer =0.78142, max_a_sm_err = 0.8213829, low_pass = 100, finer = 1\n",
      "Step   140, estim_aver_bat_size = 5.22, b =  5, bat_lim =   8401, error =  1, sm_append = 0.78361, lets_finer =0.78361, max_a_sm_err = 0.8213829, low_pass = 100, finer = 1\n",
      "Step   141, estim_aver_bat_size = 5.22, b =  6, bat_lim =   8401, error =  0, sm_append = 0.77577, lets_finer =0.77577, max_a_sm_err = 0.8213829, low_pass = 100, finer = 1\n",
      "Step   142, estim_aver_bat_size = 5.23, b =  6, bat_lim =   8401, error =  0, sm_append = 0.76801, lets_finer =0.76801, max_a_sm_err = 0.8213829, low_pass = 100, finer = 1\n",
      "Step   143, estim_aver_bat_size = 5.37, b = 19, bat_lim =   7101, error = -13, sm_append = 0.63033, lets_finer =0.63033, max_a_sm_err = 0.8213829, low_pass = 100, finer = 1\n",
      "Step   144, estim_aver_bat_size = 5.48, b = 16, bat_lim =   6101, error = -10, sm_append = 0.52403, lets_finer =0.52403, max_a_sm_err = 0.8031691, low_pass = 100, finer = 1\n",
      "Step   145, estim_aver_bat_size = 5.59, b = 17, bat_lim =   5001, error = -11, sm_append = 0.40879, lets_finer =0.40879, max_a_sm_err = 0.7951374, low_pass = 100, finer = 1\n",
      "Step   146, estim_aver_bat_size = 5.70, b = 16, bat_lim =   4001, error = -10, sm_append = 0.30470, lets_finer =0.30470, max_a_sm_err = 0.7893142, low_pass = 100, finer = 1\n",
      "Step   147, estim_aver_bat_size = 5.80, b = 16, bat_lim =   3001, error = -10, sm_append = 0.20165, lets_finer =0.20165, max_a_sm_err = 0.7893142, low_pass = 100, finer = 1\n",
      "Step   148, estim_aver_bat_size = 5.91, b = 17, bat_lim =   1901, error = -11, sm_append = 0.08964, lets_finer =0.08964, max_a_sm_err = 0.7836068, low_pass = 100, finer = 1\n",
      "Step   149, estim_aver_bat_size = 6.04, b = 19, bat_lim =    601, error = -13, sm_append = -0.04126, lets_finer =0.04126, max_a_sm_err = 0.7836068, low_pass = 100, finer = 1\n",
      "Step   150, estim_aver_bat_size = 6.11, b = 13, bat_lim =    -99, error = -7, sm_append = -0.11085, lets_finer =0.11085, max_a_sm_err = 0.7757708, low_pass = 100, finer = 1\n",
      "Step   151, estim_aver_bat_size = 6.23, b = 18, bat_lim =  -1299, error = -12, sm_append = -0.22974, lets_finer =0.22974, max_a_sm_err = 0.7680131, low_pass = 100, finer = 1\n",
      "Step   152, estim_aver_bat_size = 6.36, b = 19, bat_lim =  -2599, error = -13, sm_append = -0.35744, lets_finer =0.35744, max_a_sm_err = 0.6303329, low_pass = 100, finer = 1\n",
      "Step   153, estim_aver_bat_size = 6.38, b =  9, bat_lim =  -2899, error = -3, sm_append = -0.38387, lets_finer =0.38387, max_a_sm_err = 0.5240296, low_pass = 100, finer = 1\n",
      "Step   154, estim_aver_bat_size = 6.40, b =  8, bat_lim =  -3099, error = -2, sm_append = -0.40003, lets_finer =0.40003, max_a_sm_err = 0.4087893, low_pass = 100, finer = 1\n",
      "Step   155, estim_aver_bat_size = 6.44, b = 10, bat_lim =  -3499, error = -4, sm_append = -0.43603, lets_finer =0.43603, max_a_sm_err = 0.4360268, low_pass = 100, finer = 1\n",
      "Step   156, estim_aver_bat_size = 6.44, b =  7, bat_lim =  -3599, error = -1, sm_append = -0.44167, lets_finer =0.44167, max_a_sm_err = 0.4416665, low_pass = 100, finer = 1\n",
      "Step   157, estim_aver_bat_size = 6.47, b =  9, bat_lim =  -3899, error = -3, sm_append = -0.46725, lets_finer =0.46725, max_a_sm_err = 0.4672498, low_pass = 100, finer = 1\n",
      "Step   158, estim_aver_bat_size = 6.56, b = 16, bat_lim =  -4899, error = -10, sm_append = -0.56258, lets_finer =0.56258, max_a_sm_err = 0.5625774, low_pass = 100, finer = 1\n",
      "Step   159, estim_aver_bat_size = 6.60, b = 10, bat_lim =  -5299, error = -4, sm_append = -0.59695, lets_finer =0.59695, max_a_sm_err = 0.5969516, low_pass = 100, finer = 1\n",
      "Step   160, estim_aver_bat_size = 6.59, b =  6, bat_lim =  -5299, error =  0, sm_append = -0.59098, lets_finer =0.59098, max_a_sm_err = 0.5969516, low_pass = 100, finer = 1\n",
      "Step   161, estim_aver_bat_size = 6.68, b = 15, bat_lim =  -6199, error = -9, sm_append = -0.67507, lets_finer =0.67507, max_a_sm_err = 0.6750722, low_pass = 100, finer = 1\n",
      "Step   162, estim_aver_bat_size = 6.73, b = 12, bat_lim =  -6799, error = -6, sm_append = -0.72832, lets_finer =0.72832, max_a_sm_err = 0.7283215, low_pass = 100, finer = 1\n",
      "Step   163, estim_aver_bat_size = 6.67, b =  1, bat_lim =  -6299, error =  5, sm_append = -0.67104, lets_finer =0.67104, max_a_sm_err = 0.7283215, low_pass = 100, finer = 1\n",
      "Step   164, estim_aver_bat_size = 6.61, b =  1, bat_lim =  -5799, error =  5, sm_append = -0.61433, lets_finer =0.61433, max_a_sm_err = 0.7283215, low_pass = 100, finer = 1\n",
      "Step   165, estim_aver_bat_size = 6.56, b =  1, bat_lim =  -5299, error =  5, sm_append = -0.55818, lets_finer =0.55818, max_a_sm_err = 0.7283215, low_pass = 100, finer = 1\n",
      "Step   166, estim_aver_bat_size = 6.50, b =  1, bat_lim =  -4799, error =  5, sm_append = -0.50260, lets_finer =0.50260, max_a_sm_err = 0.7283215, low_pass = 100, finer = 1\n",
      "Step   167, estim_aver_bat_size = 6.45, b =  1, bat_lim =  -4299, error =  5, sm_append = -0.44758, lets_finer =0.44758, max_a_sm_err = 0.7283215, low_pass = 100, finer = 1\n",
      "Step   168, estim_aver_bat_size = 6.39, b =  1, bat_lim =  -3799, error =  5, sm_append = -0.39310, lets_finer =0.39310, max_a_sm_err = 0.7283215, low_pass = 100, finer = 1\n",
      "Step   169, estim_aver_bat_size = 6.34, b =  1, bat_lim =  -3299, error =  5, sm_append = -0.33917, lets_finer =0.33917, max_a_sm_err = 0.7283215, low_pass = 100, finer = 1\n",
      "Step   170, estim_aver_bat_size = 6.29, b =  1, bat_lim =  -2799, error =  5, sm_append = -0.28578, lets_finer =0.28578, max_a_sm_err = 0.7283215, low_pass = 100, finer = 1\n",
      "Step   171, estim_aver_bat_size = 6.23, b =  1, bat_lim =  -2299, error =  5, sm_append = -0.23292, lets_finer =0.23292, max_a_sm_err = 0.7283215, low_pass = 100, finer = 1\n",
      "Step   172, estim_aver_bat_size = 6.18, b =  1, bat_lim =  -1799, error =  5, sm_append = -0.18059, lets_finer =0.18059, max_a_sm_err = 0.6710383, low_pass = 100, finer = 1\n",
      "Step   173, estim_aver_bat_size = 6.13, b =  1, bat_lim =  -1299, error =  5, sm_append = -0.12879, lets_finer =0.12879, max_a_sm_err = 0.6143279, low_pass = 100, finer = 1\n",
      "Step   174, estim_aver_bat_size = 6.08, b =  1, bat_lim =   -799, error =  5, sm_append = -0.07750, lets_finer =0.07750, max_a_sm_err = 0.5581846, low_pass = 100, finer = 1\n",
      "Step   175, estim_aver_bat_size = 6.03, b =  1, bat_lim =   -299, error =  5, sm_append = -0.02672, lets_finer =0.02672, max_a_sm_err = 0.5026028, low_pass = 100, finer = 1\n",
      "Step   176, estim_aver_bat_size = 5.98, b =  1, bat_lim =    201, error =  5, sm_append = 0.02354, lets_finer =0.02354, max_a_sm_err = 0.4475768, low_pass = 100, finer = 1\n",
      "Step   177, estim_aver_bat_size = 5.93, b =  1, bat_lim =    701, error =  5, sm_append = 0.07331, lets_finer =0.07331, max_a_sm_err = 0.3931010, low_pass = 100, finer = 1\n",
      "Step   178, estim_aver_bat_size = 5.88, b =  1, bat_lim =   1201, error =  5, sm_append = 0.12258, lets_finer =0.12258, max_a_sm_err = 0.3391700, low_pass = 100, finer = 1\n",
      "Step   179, estim_aver_bat_size = 5.83, b =  1, bat_lim =   1701, error =  5, sm_append = 0.17135, lets_finer =0.17135, max_a_sm_err = 0.2857783, low_pass = 100, finer = 1\n",
      "Step   180, estim_aver_bat_size = 5.78, b =  1, bat_lim =   2201, error =  5, sm_append = 0.21964, lets_finer =0.21964, max_a_sm_err = 0.2329205, low_pass = 100, finer = 1\n",
      "Step   181, estim_aver_bat_size = 5.73, b =  1, bat_lim =   2701, error =  5, sm_append = 0.26744, lets_finer =0.26744, max_a_sm_err = 0.2674405, low_pass = 100, finer = 1\n",
      "Step   182, estim_aver_bat_size = 5.69, b =  1, bat_lim =   3201, error =  5, sm_append = 0.31477, lets_finer =0.31477, max_a_sm_err = 0.3147661, low_pass = 100, finer = 1\n",
      "Step   183, estim_aver_bat_size = 5.64, b =  1, bat_lim =   3701, error =  5, sm_append = 0.36162, lets_finer =0.36162, max_a_sm_err = 0.3616184, low_pass = 100, finer = 1\n",
      "Step   184, estim_aver_bat_size = 5.59, b =  1, bat_lim =   4201, error =  5, sm_append = 0.40800, lets_finer =0.40800, max_a_sm_err = 0.4080022, low_pass = 100, finer = 1\n",
      "Step   185, estim_aver_bat_size = 5.55, b =  1, bat_lim =   4701, error =  5, sm_append = 0.45392, lets_finer =0.45392, max_a_sm_err = 0.4539222, low_pass = 100, finer = 1\n",
      "Step   186, estim_aver_bat_size = 5.50, b =  1, bat_lim =   5201, error =  5, sm_append = 0.49938, lets_finer =0.49938, max_a_sm_err = 0.4993830, low_pass = 100, finer = 1\n",
      "Step   187, estim_aver_bat_size = 5.46, b =  1, bat_lim =   5701, error =  5, sm_append = 0.54439, lets_finer =0.54439, max_a_sm_err = 0.5443892, low_pass = 100, finer = 1\n",
      "Step   188, estim_aver_bat_size = 5.41, b =  1, bat_lim =   6201, error =  5, sm_append = 0.58895, lets_finer =0.58895, max_a_sm_err = 0.5889453, low_pass = 100, finer = 1\n",
      "Step   189, estim_aver_bat_size = 5.37, b =  1, bat_lim =   6701, error =  5, sm_append = 0.63306, lets_finer =0.63306, max_a_sm_err = 0.6330558, low_pass = 100, finer = 1\n",
      "Step   190, estim_aver_bat_size = 5.32, b =  1, bat_lim =   7201, error =  5, sm_append = 0.67673, lets_finer =0.67673, max_a_sm_err = 0.6767253, low_pass = 100, finer = 1\n",
      "Step   191, estim_aver_bat_size = 5.28, b =  1, bat_lim =   7701, error =  5, sm_append = 0.71996, lets_finer =0.71996, max_a_sm_err = 0.7199580, low_pass = 100, finer = 1\n",
      "Step   192, estim_aver_bat_size = 5.24, b =  1, bat_lim =   8201, error =  5, sm_append = 0.76276, lets_finer =0.76276, max_a_sm_err = 0.7627584, low_pass = 100, finer = 1\n",
      "Step   193, estim_aver_bat_size = 5.19, b =  1, bat_lim =   8701, error =  5, sm_append = 0.80513, lets_finer =0.80513, max_a_sm_err = 0.8051308, low_pass = 100, finer = 1\n",
      "Step   194, estim_aver_bat_size = 5.15, b =  1, bat_lim =   9201, error =  5, sm_append = 0.84708, lets_finer =0.84708, max_a_sm_err = 0.8470795, low_pass = 100, finer = 1\n",
      "Step   195, estim_aver_bat_size = 5.11, b =  1, bat_lim =   9701, error =  5, sm_append = 0.88861, lets_finer =0.88861, max_a_sm_err = 0.8886087, low_pass = 100, finer = 1\n",
      "Step   196, estim_aver_bat_size = 5.07, b =  1, bat_lim =  10201, error =  5, sm_append = 0.92972, lets_finer =0.92972, max_a_sm_err = 0.9297227, low_pass = 100, finer = 1\n",
      "Step   197, estim_aver_bat_size = 5.13, b = 11, bat_lim =   9701, error = -5, sm_append = 0.87043, lets_finer =0.87043, max_a_sm_err = 0.9297227, low_pass = 100, finer = 1\n",
      "Step   198, estim_aver_bat_size = 5.21, b = 13, bat_lim =   9001, error = -7, sm_append = 0.79172, lets_finer =0.79172, max_a_sm_err = 0.9297227, low_pass = 100, finer = 1\n",
      "Step   199, estim_aver_bat_size = 5.27, b = 11, bat_lim =   8501, error = -5, sm_append = 0.73380, lets_finer =0.73380, max_a_sm_err = 0.9297227, low_pass = 100, finer = 1\n",
      "Step   200, estim_aver_bat_size = 5.36, b = 15, bat_lim =   7601, error = -9, sm_append = 0.63647, lets_finer =0.63647, max_a_sm_err = 0.9297227, low_pass = 100, finer = 1\n",
      "Step   201, estim_aver_bat_size = 5.48, b = 17, bat_lim =   6501, error = -11, sm_append = 0.52010, lets_finer =0.52010, max_a_sm_err = 0.9297227, low_pass = 100, finer = 1\n",
      "Step   202, estim_aver_bat_size = 5.60, b = 17, bat_lim =   5401, error = -11, sm_append = 0.40490, lets_finer =0.40490, max_a_sm_err = 0.9297227, low_pass = 100, finer = 1\n",
      "Step   203, estim_aver_bat_size = 5.73, b = 19, bat_lim =   4101, error = -13, sm_append = 0.27085, lets_finer =0.27085, max_a_sm_err = 0.9297227, low_pass = 100, finer = 1\n",
      "Step   204, estim_aver_bat_size = 5.87, b = 20, bat_lim =   2701, error = -14, sm_append = 0.12814, lets_finer =0.12814, max_a_sm_err = 0.9297227, low_pass = 100, finer = 1\n",
      "Step   205, estim_aver_bat_size = 5.98, b = 17, bat_lim =   1601, error = -11, sm_append = 0.01686, lets_finer =0.01686, max_a_sm_err = 0.9297227, low_pass = 100, finer = 1\n",
      "Step   206, estim_aver_bat_size = 6.08, b = 16, bat_lim =    601, error = -10, sm_append = -0.08331, lets_finer =0.08331, max_a_sm_err = 0.8704254, low_pass = 100, finer = 1\n",
      "Step   207, estim_aver_bat_size = 6.18, b = 16, bat_lim =   -399, error = -10, sm_append = -0.18247, lets_finer =0.18247, max_a_sm_err = 0.7917212, low_pass = 100, finer = 1\n",
      "Step   208, estim_aver_bat_size = 6.25, b = 13, bat_lim =  -1099, error = -7, sm_append = -0.25065, lets_finer =0.25065, max_a_sm_err = 0.7338040, low_pass = 100, finer = 1\n",
      "Step   209, estim_aver_bat_size = 6.36, b = 17, bat_lim =  -2199, error = -11, sm_append = -0.35814, lets_finer =0.35814, max_a_sm_err = 0.6364659, low_pass = 100, finer = 1\n",
      "Step   210, estim_aver_bat_size = 6.44, b = 15, bat_lim =  -3099, error = -9, sm_append = -0.44456, lets_finer =0.44456, max_a_sm_err = 0.5201013, low_pass = 100, finer = 1\n",
      "Step   211, estim_aver_bat_size = 6.44, b =  6, bat_lim =  -3099, error =  0, sm_append = -0.44012, lets_finer =0.44012, max_a_sm_err = 0.4445616, low_pass = 100, finer = 1\n",
      "Step   212, estim_aver_bat_size = 6.44, b =  6, bat_lim =  -3099, error =  0, sm_append = -0.43571, lets_finer =0.43571, max_a_sm_err = 0.4445616, low_pass = 100, finer = 1\n",
      "Step   213, estim_aver_bat_size = 6.46, b =  9, bat_lim =  -3399, error = -3, sm_append = -0.46136, lets_finer =0.46136, max_a_sm_err = 0.4613576, low_pass = 100, finer = 1\n",
      "Step   214, estim_aver_bat_size = 6.47, b =  7, bat_lim =  -3499, error = -1, sm_append = -0.46674, lets_finer =0.46674, max_a_sm_err = 0.4667441, low_pass = 100, finer = 1\n",
      "Step   215, estim_aver_bat_size = 6.47, b =  7, bat_lim =  -3599, error = -1, sm_append = -0.47208, lets_finer =0.47208, max_a_sm_err = 0.4720766, low_pass = 100, finer = 1\n",
      "Step   216, estim_aver_bat_size = 6.47, b =  6, bat_lim =  -3599, error =  0, sm_append = -0.46736, lets_finer =0.46736, max_a_sm_err = 0.4720766, low_pass = 100, finer = 1\n",
      "Step   217, estim_aver_bat_size = 6.47, b =  7, bat_lim =  -3699, error = -1, sm_append = -0.47268, lets_finer =0.47268, max_a_sm_err = 0.4726823, low_pass = 100, finer = 1\n",
      "Step   218, estim_aver_bat_size = 6.46, b =  5, bat_lim =  -3599, error =  1, sm_append = -0.45796, lets_finer =0.45796, max_a_sm_err = 0.4726823, low_pass = 100, finer = 1\n",
      "Step   219, estim_aver_bat_size = 6.45, b =  6, bat_lim =  -3599, error =  0, sm_append = -0.45338, lets_finer =0.45338, max_a_sm_err = 0.4726823, low_pass = 100, finer = 1\n",
      "Step   220, estim_aver_bat_size = 6.45, b =  6, bat_lim =  -3599, error =  0, sm_append = -0.44884, lets_finer =0.44884, max_a_sm_err = 0.4726823, low_pass = 100, finer = 1\n",
      "Step   221, estim_aver_bat_size = 6.39, b =  1, bat_lim =  -3099, error =  5, sm_append = -0.39435, lets_finer =0.39435, max_a_sm_err = 0.4726823, low_pass = 100, finer = 1\n",
      "Step   222, estim_aver_bat_size = 6.39, b =  6, bat_lim =  -3099, error =  0, sm_append = -0.39041, lets_finer =0.39041, max_a_sm_err = 0.4726823, low_pass = 100, finer = 1\n",
      "Step   223, estim_aver_bat_size = 6.40, b =  7, bat_lim =  -3199, error = -1, sm_append = -0.39651, lets_finer =0.39651, max_a_sm_err = 0.4726823, low_pass = 100, finer = 1\n",
      "Step   224, estim_aver_bat_size = 6.38, b =  5, bat_lim =  -3099, error =  1, sm_append = -0.38254, lets_finer =0.38254, max_a_sm_err = 0.4726823, low_pass = 100, finer = 1\n",
      "Step   225, estim_aver_bat_size = 6.34, b =  2, bat_lim =  -2699, error =  4, sm_append = -0.33872, lets_finer =0.33872, max_a_sm_err = 0.4726823, low_pass = 100, finer = 1\n",
      "Step   226, estim_aver_bat_size = 6.30, b =  2, bat_lim =  -2299, error =  4, sm_append = -0.29533, lets_finer =0.29533, max_a_sm_err = 0.4726823, low_pass = 100, finer = 1\n",
      "Step   227, estim_aver_bat_size = 6.24, b =  1, bat_lim =  -1799, error =  5, sm_append = -0.24238, lets_finer =0.24238, max_a_sm_err = 0.4579555, low_pass = 100, finer = 1\n",
      "Step   228, estim_aver_bat_size = 6.19, b =  1, bat_lim =  -1299, error =  5, sm_append = -0.18995, lets_finer =0.18995, max_a_sm_err = 0.4533759, low_pass = 100, finer = 1\n",
      "Step   229, estim_aver_bat_size = 6.14, b =  1, bat_lim =   -799, error =  5, sm_append = -0.13805, lets_finer =0.13805, max_a_sm_err = 0.4488422, low_pass = 100, finer = 1\n",
      "Step   230, estim_aver_bat_size = 6.09, b =  1, bat_lim =   -299, error =  5, sm_append = -0.08667, lets_finer =0.08667, max_a_sm_err = 0.3965061, low_pass = 100, finer = 1\n",
      "Step   231, estim_aver_bat_size = 6.04, b =  1, bat_lim =    201, error =  5, sm_append = -0.03580, lets_finer =0.03580, max_a_sm_err = 0.3965061, low_pass = 100, finer = 1\n",
      "Step   232, estim_aver_bat_size = 5.99, b =  1, bat_lim =    701, error =  5, sm_append = 0.01455, lets_finer =0.01455, max_a_sm_err = 0.3965061, low_pass = 100, finer = 1\n",
      "Step   233, estim_aver_bat_size = 5.94, b =  1, bat_lim =   1201, error =  5, sm_append = 0.06441, lets_finer =0.06441, max_a_sm_err = 0.3825410, low_pass = 100, finer = 1\n",
      "Step   234, estim_aver_bat_size = 5.89, b =  1, bat_lim =   1701, error =  5, sm_append = 0.11376, lets_finer =0.11376, max_a_sm_err = 0.3387156, low_pass = 100, finer = 1\n",
      "Step   235, estim_aver_bat_size = 5.84, b =  1, bat_lim =   2201, error =  5, sm_append = 0.16263, lets_finer =0.16263, max_a_sm_err = 0.2953285, low_pass = 100, finer = 1\n",
      "Step   236, estim_aver_bat_size = 5.79, b =  1, bat_lim =   2701, error =  5, sm_append = 0.21100, lets_finer =0.21100, max_a_sm_err = 0.2423752, low_pass = 100, finer = 1\n",
      "Step   237, estim_aver_bat_size = 5.74, b =  1, bat_lim =   3201, error =  5, sm_append = 0.25889, lets_finer =0.25889, max_a_sm_err = 0.2588899, low_pass = 100, finer = 1\n",
      "Step   238, estim_aver_bat_size = 5.69, b =  1, bat_lim =   3701, error =  5, sm_append = 0.30630, lets_finer =0.30630, max_a_sm_err = 0.3063010, low_pass = 100, finer = 1\n",
      "Step   239, estim_aver_bat_size = 5.65, b =  1, bat_lim =   4201, error =  5, sm_append = 0.35324, lets_finer =0.35324, max_a_sm_err = 0.3532379, low_pass = 100, finer = 1\n",
      "Step   240, estim_aver_bat_size = 5.60, b =  1, bat_lim =   4701, error =  5, sm_append = 0.39971, lets_finer =0.39971, max_a_sm_err = 0.3997056, low_pass = 100, finer = 1\n",
      "Step   241, estim_aver_bat_size = 5.55, b =  1, bat_lim =   5201, error =  5, sm_append = 0.44571, lets_finer =0.44571, max_a_sm_err = 0.4457085, low_pass = 100, finer = 1\n",
      "Step   242, estim_aver_bat_size = 5.51, b =  1, bat_lim =   5701, error =  5, sm_append = 0.49125, lets_finer =0.49125, max_a_sm_err = 0.4912514, low_pass = 100, finer = 1\n",
      "Step   243, estim_aver_bat_size = 5.46, b =  1, bat_lim =   6201, error =  5, sm_append = 0.53634, lets_finer =0.53634, max_a_sm_err = 0.5363389, low_pass = 100, finer = 1\n",
      "Step   244, estim_aver_bat_size = 5.42, b =  1, bat_lim =   6701, error =  5, sm_append = 0.58098, lets_finer =0.58098, max_a_sm_err = 0.5809755, low_pass = 100, finer = 1\n",
      "Step   245, estim_aver_bat_size = 5.37, b =  1, bat_lim =   7201, error =  5, sm_append = 0.62517, lets_finer =0.62517, max_a_sm_err = 0.6251658, low_pass = 100, finer = 1\n",
      "Step   246, estim_aver_bat_size = 5.33, b =  1, bat_lim =   7701, error =  5, sm_append = 0.66891, lets_finer =0.66891, max_a_sm_err = 0.6689141, low_pass = 100, finer = 1\n",
      "Step   247, estim_aver_bat_size = 5.29, b =  1, bat_lim =   8201, error =  5, sm_append = 0.71222, lets_finer =0.71222, max_a_sm_err = 0.7122250, low_pass = 100, finer = 1\n",
      "Step   248, estim_aver_bat_size = 5.24, b =  1, bat_lim =   8701, error =  5, sm_append = 0.75510, lets_finer =0.75510, max_a_sm_err = 0.7551027, low_pass = 100, finer = 1\n",
      "Step   249, estim_aver_bat_size = 5.20, b =  1, bat_lim =   9201, error =  5, sm_append = 0.79755, lets_finer =0.79755, max_a_sm_err = 0.7975517, low_pass = 100, finer = 1\n",
      "Step   250, estim_aver_bat_size = 5.16, b =  1, bat_lim =   9701, error =  5, sm_append = 0.83958, lets_finer =0.83958, max_a_sm_err = 0.8395762, low_pass = 100, finer = 1\n",
      "Step   251, estim_aver_bat_size = 5.17, b =  6, bat_lim =   9701, error =  0, sm_append = 0.83118, lets_finer =0.83118, max_a_sm_err = 0.8395762, low_pass = 100, finer = 1\n",
      "Step   252, estim_aver_bat_size = 5.16, b =  4, bat_lim =   9901, error =  2, sm_append = 0.84287, lets_finer =0.84287, max_a_sm_err = 0.8428686, low_pass = 100, finer = 1\n",
      "Step   253, estim_aver_bat_size = 5.20, b =  9, bat_lim =   9601, error = -3, sm_append = 0.80444, lets_finer =0.80444, max_a_sm_err = 0.8428686, low_pass = 100, finer = 1\n",
      "Step   254, estim_aver_bat_size = 5.22, b =  8, bat_lim =   9401, error = -2, sm_append = 0.77640, lets_finer =0.77640, max_a_sm_err = 0.8428686, low_pass = 100, finer = 1\n",
      "Step   255, estim_aver_bat_size = 5.20, b =  3, bat_lim =   9701, error =  3, sm_append = 0.79863, lets_finer =0.79863, max_a_sm_err = 0.8428686, low_pass = 100, finer = 1\n",
      "Step   256, estim_aver_bat_size = 5.26, b = 11, bat_lim =   9201, error = -5, sm_append = 0.74065, lets_finer =0.74065, max_a_sm_err = 0.8428686, low_pass = 100, finer = 1\n",
      "Step   257, estim_aver_bat_size = 5.31, b = 10, bat_lim =   8801, error = -4, sm_append = 0.69324, lets_finer =0.69324, max_a_sm_err = 0.8428686, low_pass = 100, finer = 1\n",
      "Step   258, estim_aver_bat_size = 5.36, b = 11, bat_lim =   8301, error = -5, sm_append = 0.63631, lets_finer =0.63631, max_a_sm_err = 0.8428686, low_pass = 100, finer = 1\n",
      "Step   259, estim_aver_bat_size = 5.41, b = 10, bat_lim =   7901, error = -4, sm_append = 0.58994, lets_finer =0.58994, max_a_sm_err = 0.8428686, low_pass = 100, finer = 1\n",
      "Step   260, estim_aver_bat_size = 5.47, b = 11, bat_lim =   7401, error = -5, sm_append = 0.53404, lets_finer =0.53404, max_a_sm_err = 0.8428686, low_pass = 100, finer = 1\n",
      "Step   261, estim_aver_bat_size = 5.50, b =  9, bat_lim =   7101, error = -3, sm_append = 0.49870, lets_finer =0.49870, max_a_sm_err = 0.8428686, low_pass = 100, finer = 1\n",
      "Step   262, estim_aver_bat_size = 5.65, b = 20, bat_lim =   5701, error = -14, sm_append = 0.35372, lets_finer =0.35372, max_a_sm_err = 0.8044399, low_pass = 100, finer = 1\n",
      "Step   263, estim_aver_bat_size = 5.77, b = 18, bat_lim =   4501, error = -12, sm_append = 0.23018, lets_finer =0.23018, max_a_sm_err = 0.7986316, low_pass = 100, finer = 1\n",
      "Step   264, estim_aver_bat_size = 5.89, b = 18, bat_lim =   3301, error = -12, sm_append = 0.10788, lets_finer =0.10788, max_a_sm_err = 0.7986316, low_pass = 100, finer = 1\n",
      "Step   265, estim_aver_bat_size = 6.01, b = 18, bat_lim =   2101, error = -12, sm_append = -0.01320, lets_finer =0.01320, max_a_sm_err = 0.7406452, low_pass = 100, finer = 1\n",
      "Step   266, estim_aver_bat_size = 6.14, b = 19, bat_lim =    801, error = -13, sm_append = -0.14307, lets_finer =0.14307, max_a_sm_err = 0.6932388, low_pass = 100, finer = 1\n",
      "Step   267, estim_aver_bat_size = 6.28, b = 20, bat_lim =   -599, error = -14, sm_append = -0.28164, lets_finer =0.28164, max_a_sm_err = 0.6363064, low_pass = 100, finer = 1\n",
      "Step   268, estim_aver_bat_size = 6.41, b = 19, bat_lim =  -1899, error = -13, sm_append = -0.40882, lets_finer =0.40882, max_a_sm_err = 0.5899433, low_pass = 100, finer = 1\n",
      "Step   269, estim_aver_bat_size = 6.53, b = 19, bat_lim =  -3199, error = -13, sm_append = -0.53473, lets_finer =0.53473, max_a_sm_err = 0.5347340, low_pass = 100, finer = 1\n",
      "Step   270, estim_aver_bat_size = 6.64, b = 17, bat_lim =  -4299, error = -11, sm_append = -0.63939, lets_finer =0.63939, max_a_sm_err = 0.6393866, low_pass = 100, finer = 1\n",
      "Step   271, estim_aver_bat_size = 6.76, b = 19, bat_lim =  -5599, error = -13, sm_append = -0.76299, lets_finer =0.76299, max_a_sm_err = 0.7629928, low_pass = 100, finer = 1\n",
      "Step   272, estim_aver_bat_size = 6.88, b = 18, bat_lim =  -6799, error = -12, sm_append = -0.87536, lets_finer =0.87536, max_a_sm_err = 0.8753628, low_pass = 100, finer = 1\n",
      "Step   273, estim_aver_bat_size = 6.93, b = 12, bat_lim =  -7399, error = -6, sm_append = -0.92661, lets_finer =0.92661, max_a_sm_err = 0.9266092, low_pass = 100, finer = 1\n",
      "Step   274, estim_aver_bat_size = 7.00, b = 14, bat_lim =  -8199, error = -8, sm_append = -0.99734, lets_finer =0.99734, max_a_sm_err = 0.9973431, low_pass = 100, finer = 1\n",
      "Step   275, estim_aver_bat_size = 7.06, b = 13, bat_lim =  -8899, error = -7, sm_append = -1.05737, lets_finer =1.05737, max_a_sm_err = 1.0573697, low_pass = 100, finer = 1\n",
      "Step   276, estim_aver_bat_size = 7.13, b = 14, bat_lim =  -9699, error = -8, sm_append = -1.12680, lets_finer =1.12680, max_a_sm_err = 1.1267960, low_pass = 100, finer = 1\n",
      "Step   277, estim_aver_bat_size = 7.20, b = 14, bat_lim = -10499, error = -8, sm_append = -1.19553, lets_finer =1.19553, max_a_sm_err = 1.1955280, low_pass = 100, finer = 1\n",
      "Step   278, estim_aver_bat_size = 7.23, b = 11, bat_lim = -10999, error = -5, sm_append = -1.23357, lets_finer =1.23357, max_a_sm_err = 1.2335728, low_pass = 100, finer = 1\n",
      "Step   279, estim_aver_bat_size = 7.29, b = 13, bat_lim = -11699, error = -7, sm_append = -1.29124, lets_finer =1.29124, max_a_sm_err = 1.2912370, low_pass = 100, finer = 1\n",
      "Step   280, estim_aver_bat_size = 7.36, b = 14, bat_lim = -12499, error = -8, sm_append = -1.35832, lets_finer =1.35832, max_a_sm_err = 1.3583247, low_pass = 100, finer = 1\n",
      "Step   281, estim_aver_bat_size = 7.40, b = 12, bat_lim = -13099, error = -6, sm_append = -1.40474, lets_finer =1.40474, max_a_sm_err = 1.4047414, low_pass = 100, finer = 1\n",
      "Step   282, estim_aver_bat_size = 7.41, b =  8, bat_lim = -13299, error = -2, sm_append = -1.41069, lets_finer =1.41069, max_a_sm_err = 1.4106940, low_pass = 100, finer = 1\n",
      "Step   283, estim_aver_bat_size = 7.44, b = 10, bat_lim = -13699, error = -4, sm_append = -1.43659, lets_finer =1.43659, max_a_sm_err = 1.4365871, low_pass = 100, finer = 1\n",
      "Step   284, estim_aver_bat_size = 7.39, b =  3, bat_lim = -13399, error =  3, sm_append = -1.39222, lets_finer =1.39222, max_a_sm_err = 1.4365871, low_pass = 100, finer = 1\n",
      "Step   285, estim_aver_bat_size = 7.34, b =  2, bat_lim = -12999, error =  4, sm_append = -1.33830, lets_finer =1.33830, max_a_sm_err = 1.4365871, low_pass = 100, finer = 1\n",
      "Step   286, estim_aver_bat_size = 7.28, b =  2, bat_lim = -12599, error =  4, sm_append = -1.28492, lets_finer =1.28492, max_a_sm_err = 1.4365871, low_pass = 100, finer = 1\n",
      "Step   287, estim_aver_bat_size = 7.22, b =  1, bat_lim = -12099, error =  5, sm_append = -1.22207, lets_finer =1.22207, max_a_sm_err = 1.4365871, low_pass = 100, finer = 1\n",
      "Step   288, estim_aver_bat_size = 7.16, b =  1, bat_lim = -11599, error =  5, sm_append = -1.15985, lets_finer =1.15985, max_a_sm_err = 1.4365871, low_pass = 100, finer = 1\n",
      "Step   289, estim_aver_bat_size = 7.10, b =  1, bat_lim = -11099, error =  5, sm_append = -1.09825, lets_finer =1.09825, max_a_sm_err = 1.4365871, low_pass = 100, finer = 1\n",
      "Step   290, estim_aver_bat_size = 7.04, b =  1, bat_lim = -10599, error =  5, sm_append = -1.03727, lets_finer =1.03727, max_a_sm_err = 1.4365871, low_pass = 100, finer = 1\n",
      "Step   291, estim_aver_bat_size = 6.98, b =  1, bat_lim = -10099, error =  5, sm_append = -0.97689, lets_finer =0.97689, max_a_sm_err = 1.4365871, low_pass = 100, finer = 1\n",
      "Step   292, estim_aver_bat_size = 6.92, b =  1, bat_lim =  -9599, error =  5, sm_append = -0.91712, lets_finer =0.91712, max_a_sm_err = 1.4365871, low_pass = 100, finer = 1\n",
      "Step   293, estim_aver_bat_size = 6.86, b =  1, bat_lim =  -9099, error =  5, sm_append = -0.85795, lets_finer =0.85795, max_a_sm_err = 1.3922212, low_pass = 100, finer = 1\n",
      "Step   294, estim_aver_bat_size = 6.80, b =  1, bat_lim =  -8599, error =  5, sm_append = -0.79937, lets_finer =0.79937, max_a_sm_err = 1.3382990, low_pass = 100, finer = 1\n",
      "Step   295, estim_aver_bat_size = 6.74, b =  1, bat_lim =  -8099, error =  5, sm_append = -0.74138, lets_finer =0.74138, max_a_sm_err = 1.2849160, low_pass = 100, finer = 1\n",
      "Step   296, estim_aver_bat_size = 6.68, b =  1, bat_lim =  -7599, error =  5, sm_append = -0.68397, lets_finer =0.68397, max_a_sm_err = 1.2220668, low_pass = 100, finer = 1\n",
      "Step   297, estim_aver_bat_size = 6.63, b =  1, bat_lim =  -7099, error =  5, sm_append = -0.62713, lets_finer =0.62713, max_a_sm_err = 1.1598462, low_pass = 100, finer = 1\n",
      "Step   298, estim_aver_bat_size = 6.57, b =  1, bat_lim =  -6599, error =  5, sm_append = -0.57085, lets_finer =0.57085, max_a_sm_err = 1.0982477, low_pass = 100, finer = 1\n",
      "Step   299, estim_aver_bat_size = 6.52, b =  1, bat_lim =  -6099, error =  5, sm_append = -0.51515, lets_finer =0.51515, max_a_sm_err = 1.0372652, low_pass = 100, finer = 1\n",
      "Step   300, estim_aver_bat_size = 6.46, b =  1, bat_lim =  -5599, error =  5, sm_append = -0.45999, lets_finer =0.45999, max_a_sm_err = 0.9768926, low_pass = 100, finer = 1\n",
      "Step   301, estim_aver_bat_size = 6.41, b =  1, bat_lim =  -5099, error =  5, sm_append = -0.40539, lets_finer =0.40539, max_a_sm_err = 0.9171236, low_pass = 100, finer = 1\n",
      "Step   302, estim_aver_bat_size = 6.35, b =  1, bat_lim =  -4599, error =  5, sm_append = -0.35134, lets_finer =0.35134, max_a_sm_err = 0.8579524, low_pass = 100, finer = 1\n",
      "Step   303, estim_aver_bat_size = 6.30, b =  1, bat_lim =  -4099, error =  5, sm_append = -0.29783, lets_finer =0.29783, max_a_sm_err = 0.7993729, low_pass = 100, finer = 1\n",
      "Step   304, estim_aver_bat_size = 6.24, b =  1, bat_lim =  -3599, error =  5, sm_append = -0.24485, lets_finer =0.24485, max_a_sm_err = 0.7413792, low_pass = 100, finer = 1\n",
      "Step   305, estim_aver_bat_size = 6.19, b =  1, bat_lim =  -3099, error =  5, sm_append = -0.19240, lets_finer =0.19240, max_a_sm_err = 0.6839654, low_pass = 100, finer = 1\n",
      "Step   306, estim_aver_bat_size = 6.14, b =  1, bat_lim =  -2599, error =  5, sm_append = -0.14048, lets_finer =0.14048, max_a_sm_err = 0.6271257, low_pass = 100, finer = 1\n",
      "Step   307, estim_aver_bat_size = 6.09, b =  1, bat_lim =  -2099, error =  5, sm_append = -0.08907, lets_finer =0.08907, max_a_sm_err = 0.5708545, low_pass = 100, finer = 1\n",
      "Step   308, estim_aver_bat_size = 6.04, b =  1, bat_lim =  -1599, error =  5, sm_append = -0.03818, lets_finer =0.03818, max_a_sm_err = 0.5151459, low_pass = 100, finer = 1\n",
      "Step   309, estim_aver_bat_size = 5.99, b =  1, bat_lim =  -1099, error =  5, sm_append = 0.01220, lets_finer =0.01220, max_a_sm_err = 0.4599944, low_pass = 100, finer = 1\n",
      "Step   310, estim_aver_bat_size = 5.94, b =  1, bat_lim =   -599, error =  5, sm_append = 0.06208, lets_finer =0.06208, max_a_sm_err = 0.4053945, low_pass = 100, finer = 1\n",
      "Step   311, estim_aver_bat_size = 5.89, b =  1, bat_lim =    -99, error =  5, sm_append = 0.11146, lets_finer =0.11146, max_a_sm_err = 0.3513406, low_pass = 100, finer = 1\n",
      "Step   312, estim_aver_bat_size = 5.84, b =  1, bat_lim =    401, error =  5, sm_append = 0.16034, lets_finer =0.16034, max_a_sm_err = 0.2978272, low_pass = 100, finer = 1\n",
      "Step   313, estim_aver_bat_size = 5.79, b =  1, bat_lim =    901, error =  5, sm_append = 0.20874, lets_finer =0.20874, max_a_sm_err = 0.2448489, low_pass = 100, finer = 1\n",
      "Step   314, estim_aver_bat_size = 5.74, b =  1, bat_lim =   1401, error =  5, sm_append = 0.25665, lets_finer =0.25665, max_a_sm_err = 0.2566527, low_pass = 100, finer = 1\n",
      "Step   315, estim_aver_bat_size = 5.70, b =  1, bat_lim =   1901, error =  5, sm_append = 0.30409, lets_finer =0.30409, max_a_sm_err = 0.3040862, low_pass = 100, finer = 1\n",
      "Step   316, estim_aver_bat_size = 5.65, b =  1, bat_lim =   2401, error =  5, sm_append = 0.35105, lets_finer =0.35105, max_a_sm_err = 0.3510453, low_pass = 100, finer = 1\n",
      "Step   317, estim_aver_bat_size = 5.60, b =  1, bat_lim =   2901, error =  5, sm_append = 0.39753, lets_finer =0.39753, max_a_sm_err = 0.3975348, low_pass = 100, finer = 1\n",
      "Step   318, estim_aver_bat_size = 5.56, b =  1, bat_lim =   3401, error =  5, sm_append = 0.44356, lets_finer =0.44356, max_a_sm_err = 0.4435595, low_pass = 100, finer = 1\n",
      "Step   319, estim_aver_bat_size = 5.51, b =  1, bat_lim =   3901, error =  5, sm_append = 0.48912, lets_finer =0.48912, max_a_sm_err = 0.4891239, low_pass = 100, finer = 1\n",
      "Step   320, estim_aver_bat_size = 5.47, b =  1, bat_lim =   4401, error =  5, sm_append = 0.53423, lets_finer =0.53423, max_a_sm_err = 0.5342327, low_pass = 100, finer = 1\n",
      "Step   321, estim_aver_bat_size = 5.42, b =  1, bat_lim =   4901, error =  5, sm_append = 0.57889, lets_finer =0.57889, max_a_sm_err = 0.5788903, low_pass = 100, finer = 1\n",
      "Step   322, estim_aver_bat_size = 5.38, b =  1, bat_lim =   5401, error =  5, sm_append = 0.62310, lets_finer =0.62310, max_a_sm_err = 0.6231014, low_pass = 100, finer = 1\n",
      "Step   323, estim_aver_bat_size = 5.33, b =  1, bat_lim =   5901, error =  5, sm_append = 0.66687, lets_finer =0.66687, max_a_sm_err = 0.6668704, low_pass = 100, finer = 1\n",
      "Step   324, estim_aver_bat_size = 5.29, b =  1, bat_lim =   6401, error =  5, sm_append = 0.71020, lets_finer =0.71020, max_a_sm_err = 0.7102017, low_pass = 100, finer = 1\n",
      "Step   325, estim_aver_bat_size = 5.25, b =  1, bat_lim =   6901, error =  5, sm_append = 0.75310, lets_finer =0.75310, max_a_sm_err = 0.7530997, low_pass = 100, finer = 1\n",
      "Step   326, estim_aver_bat_size = 5.20, b =  1, bat_lim =   7401, error =  5, sm_append = 0.79557, lets_finer =0.79557, max_a_sm_err = 0.7955687, low_pass = 100, finer = 1\n",
      "Step   327, estim_aver_bat_size = 5.16, b =  1, bat_lim =   7901, error =  5, sm_append = 0.83761, lets_finer =0.83761, max_a_sm_err = 0.8376130, low_pass = 100, finer = 1\n",
      "Step   328, estim_aver_bat_size = 5.26, b = 15, bat_lim =   7001, error = -9, sm_append = 0.73924, lets_finer =0.73924, max_a_sm_err = 0.8376130, low_pass = 100, finer = 1\n",
      "Step   329, estim_aver_bat_size = 5.37, b = 16, bat_lim =   6001, error = -10, sm_append = 0.63184, lets_finer =0.63184, max_a_sm_err = 0.8376130, low_pass = 100, finer = 1\n",
      "Step   330, estim_aver_bat_size = 5.46, b = 15, bat_lim =   5101, error = -9, sm_append = 0.53553, lets_finer =0.53553, max_a_sm_err = 0.8376130, low_pass = 100, finer = 1\n",
      "Step   331, estim_aver_bat_size = 5.54, b = 13, bat_lim =   4401, error = -7, sm_append = 0.46017, lets_finer =0.46017, max_a_sm_err = 0.8376130, low_pass = 100, finer = 1\n",
      "Step   332, estim_aver_bat_size = 5.65, b = 17, bat_lim =   3301, error = -11, sm_append = 0.34557, lets_finer =0.34557, max_a_sm_err = 0.8376130, low_pass = 100, finer = 1\n",
      "Step   333, estim_aver_bat_size = 5.78, b = 18, bat_lim =   2101, error = -12, sm_append = 0.22211, lets_finer =0.22211, max_a_sm_err = 0.8376130, low_pass = 100, finer = 1\n",
      "Step   334, estim_aver_bat_size = 5.87, b = 15, bat_lim =   1201, error = -9, sm_append = 0.12989, lets_finer =0.12989, max_a_sm_err = 0.8376130, low_pass = 100, finer = 1\n",
      "Step   335, estim_aver_bat_size = 5.96, b = 15, bat_lim =    301, error = -9, sm_append = 0.03859, lets_finer =0.03859, max_a_sm_err = 0.8376130, low_pass = 100, finer = 1\n",
      "Step   336, estim_aver_bat_size = 6.06, b = 16, bat_lim =   -699, error = -10, sm_append = -0.06179, lets_finer =0.06179, max_a_sm_err = 0.8376130, low_pass = 100, finer = 1\n",
      "Step   337, estim_aver_bat_size = 6.18, b = 18, bat_lim =  -1899, error = -12, sm_append = -0.18117, lets_finer =0.18117, max_a_sm_err = 0.7392369, low_pass = 100, finer = 1\n",
      "Step   338, estim_aver_bat_size = 6.20, b =  8, bat_lim =  -2099, error = -2, sm_append = -0.19936, lets_finer =0.19936, max_a_sm_err = 0.6318445, low_pass = 100, finer = 1\n",
      "Step   339, estim_aver_bat_size = 6.23, b =  9, bat_lim =  -2399, error = -3, sm_append = -0.22737, lets_finer =0.22737, max_a_sm_err = 0.5355261, low_pass = 100, finer = 1\n",
      "Step   340, estim_aver_bat_size = 6.26, b =  9, bat_lim =  -2699, error = -3, sm_append = -0.25510, lets_finer =0.25510, max_a_sm_err = 0.4601708, low_pass = 100, finer = 1\n",
      "Step   341, estim_aver_bat_size = 6.29, b = 10, bat_lim =  -3099, error = -4, sm_append = -0.29254, lets_finer =0.29254, max_a_sm_err = 0.3455691, low_pass = 100, finer = 1\n",
      "Step   342, estim_aver_bat_size = 6.30, b =  7, bat_lim =  -3199, error = -1, sm_append = -0.29962, lets_finer =0.29962, max_a_sm_err = 0.2996192, low_pass = 100, finer = 1\n",
      "Step   343, estim_aver_bat_size = 6.34, b = 10, bat_lim =  -3599, error = -4, sm_append = -0.33662, lets_finer =0.33662, max_a_sm_err = 0.3366230, low_pass = 100, finer = 1\n",
      "Step   344, estim_aver_bat_size = 6.36, b =  9, bat_lim =  -3899, error = -3, sm_append = -0.36326, lets_finer =0.36326, max_a_sm_err = 0.3632568, low_pass = 100, finer = 1\n",
      "Step   345, estim_aver_bat_size = 6.42, b = 12, bat_lim =  -4499, error = -6, sm_append = -0.41962, lets_finer =0.41962, max_a_sm_err = 0.4196242, low_pass = 100, finer = 1\n",
      "Step   346, estim_aver_bat_size = 6.43, b =  7, bat_lim =  -4599, error = -1, sm_append = -0.42543, lets_finer =0.42543, max_a_sm_err = 0.4254280, low_pass = 100, finer = 1\n",
      "Step   347, estim_aver_bat_size = 6.47, b = 11, bat_lim =  -5099, error = -5, sm_append = -0.47117, lets_finer =0.47117, max_a_sm_err = 0.4711737, low_pass = 100, finer = 1\n",
      "Step   348, estim_aver_bat_size = 6.42, b =  1, bat_lim =  -4599, error =  5, sm_append = -0.41646, lets_finer =0.41646, max_a_sm_err = 0.4711737, low_pass = 100, finer = 1\n",
      "Step   349, estim_aver_bat_size = 6.41, b =  6, bat_lim =  -4599, error =  0, sm_append = -0.41230, lets_finer =0.41230, max_a_sm_err = 0.4711737, low_pass = 100, finer = 1\n",
      "Step   350, estim_aver_bat_size = 6.39, b =  4, bat_lim =  -4399, error =  2, sm_append = -0.38817, lets_finer =0.38817, max_a_sm_err = 0.4711737, low_pass = 100, finer = 1\n",
      "Step   351, estim_aver_bat_size = 6.35, b =  3, bat_lim =  -4099, error =  3, sm_append = -0.35429, lets_finer =0.35429, max_a_sm_err = 0.4711737, low_pass = 100, finer = 1\n",
      "Step   352, estim_aver_bat_size = 6.32, b =  3, bat_lim =  -3799, error =  3, sm_append = -0.32075, lets_finer =0.32075, max_a_sm_err = 0.4711737, low_pass = 100, finer = 1\n",
      "Step   353, estim_aver_bat_size = 6.28, b =  2, bat_lim =  -3399, error =  4, sm_append = -0.27754, lets_finer =0.27754, max_a_sm_err = 0.4711737, low_pass = 100, finer = 1\n",
      "Step   354, estim_aver_bat_size = 6.22, b =  1, bat_lim =  -2899, error =  5, sm_append = -0.22477, lets_finer =0.22477, max_a_sm_err = 0.4711737, low_pass = 100, finer = 1\n",
      "Step   355, estim_aver_bat_size = 6.17, b =  1, bat_lim =  -2399, error =  5, sm_append = -0.17252, lets_finer =0.17252, max_a_sm_err = 0.4711737, low_pass = 100, finer = 1\n",
      "Step   356, estim_aver_bat_size = 6.12, b =  1, bat_lim =  -1899, error =  5, sm_append = -0.12079, lets_finer =0.12079, max_a_sm_err = 0.4711737, low_pass = 100, finer = 1\n",
      "Step   357, estim_aver_bat_size = 6.07, b =  1, bat_lim =  -1399, error =  5, sm_append = -0.06959, lets_finer =0.06959, max_a_sm_err = 0.4164619, low_pass = 100, finer = 1\n",
      "Step   358, estim_aver_bat_size = 6.02, b =  1, bat_lim =   -899, error =  5, sm_append = -0.01889, lets_finer =0.01889, max_a_sm_err = 0.4122973, low_pass = 100, finer = 1\n",
      "Step   359, estim_aver_bat_size = 5.97, b =  1, bat_lim =   -399, error =  5, sm_append = 0.03130, lets_finer =0.03130, max_a_sm_err = 0.3881743, low_pass = 100, finer = 1\n",
      "Step   360, estim_aver_bat_size = 5.92, b =  1, bat_lim =    101, error =  5, sm_append = 0.08099, lets_finer =0.08099, max_a_sm_err = 0.3542926, low_pass = 100, finer = 1\n",
      "Step   361, estim_aver_bat_size = 5.87, b =  1, bat_lim =    601, error =  5, sm_append = 0.13018, lets_finer =0.13018, max_a_sm_err = 0.3207497, low_pass = 100, finer = 1\n",
      "Step   362, estim_aver_bat_size = 5.82, b =  1, bat_lim =   1101, error =  5, sm_append = 0.17887, lets_finer =0.17887, max_a_sm_err = 0.2775422, low_pass = 100, finer = 1\n",
      "Step   363, estim_aver_bat_size = 5.77, b =  1, bat_lim =   1601, error =  5, sm_append = 0.22709, lets_finer =0.22709, max_a_sm_err = 0.2270855, low_pass = 100, finer = 1\n",
      "Step   364, estim_aver_bat_size = 5.73, b =  1, bat_lim =   2101, error =  5, sm_append = 0.27481, lets_finer =0.27481, max_a_sm_err = 0.2748146, low_pass = 100, finer = 1\n",
      "Step   365, estim_aver_bat_size = 5.68, b =  1, bat_lim =   2601, error =  5, sm_append = 0.32207, lets_finer =0.32207, max_a_sm_err = 0.3220665, low_pass = 100, finer = 1\n",
      "Step   366, estim_aver_bat_size = 5.63, b =  1, bat_lim =   3101, error =  5, sm_append = 0.36885, lets_finer =0.36885, max_a_sm_err = 0.3688458, low_pass = 100, finer = 1\n",
      "Step   367, estim_aver_bat_size = 5.58, b =  1, bat_lim =   3601, error =  5, sm_append = 0.41516, lets_finer =0.41516, max_a_sm_err = 0.4151573, low_pass = 100, finer = 1\n",
      "Step   368, estim_aver_bat_size = 5.54, b =  1, bat_lim =   4101, error =  5, sm_append = 0.46101, lets_finer =0.46101, max_a_sm_err = 0.4610058, low_pass = 100, finer = 1\n",
      "Step   369, estim_aver_bat_size = 5.49, b =  1, bat_lim =   4601, error =  5, sm_append = 0.50640, lets_finer =0.50640, max_a_sm_err = 0.5063957, low_pass = 100, finer = 1\n",
      "Step   370, estim_aver_bat_size = 5.45, b =  1, bat_lim =   5101, error =  5, sm_append = 0.55133, lets_finer =0.55133, max_a_sm_err = 0.5513317, low_pass = 100, finer = 1\n",
      "Step   371, estim_aver_bat_size = 5.40, b =  1, bat_lim =   5601, error =  5, sm_append = 0.59582, lets_finer =0.59582, max_a_sm_err = 0.5958184, low_pass = 100, finer = 1\n",
      "Step   372, estim_aver_bat_size = 5.36, b =  1, bat_lim =   6101, error =  5, sm_append = 0.63986, lets_finer =0.63986, max_a_sm_err = 0.6398602, low_pass = 100, finer = 1\n",
      "Step   373, estim_aver_bat_size = 5.32, b =  1, bat_lim =   6601, error =  5, sm_append = 0.68346, lets_finer =0.68346, max_a_sm_err = 0.6834616, low_pass = 100, finer = 1\n",
      "Step   374, estim_aver_bat_size = 5.27, b =  1, bat_lim =   7101, error =  5, sm_append = 0.72663, lets_finer =0.72663, max_a_sm_err = 0.7266270, low_pass = 100, finer = 1\n",
      "Step   375, estim_aver_bat_size = 5.23, b =  1, bat_lim =   7601, error =  5, sm_append = 0.76936, lets_finer =0.76936, max_a_sm_err = 0.7693608, low_pass = 100, finer = 1\n",
      "Step   376, estim_aver_bat_size = 5.19, b =  1, bat_lim =   8101, error =  5, sm_append = 0.81167, lets_finer =0.81167, max_a_sm_err = 0.8116671, low_pass = 100, finer = 1\n",
      "Step   377, estim_aver_bat_size = 5.15, b =  1, bat_lim =   8601, error =  5, sm_append = 0.85355, lets_finer =0.85355, max_a_sm_err = 0.8535505, low_pass = 100, finer = 1\n",
      "Step   378, estim_aver_bat_size = 5.22, b = 13, bat_lim =   7901, error = -7, sm_append = 0.77501, lets_finer =0.77501, max_a_sm_err = 0.8535505, low_pass = 100, finer = 1\n",
      "Step   379, estim_aver_bat_size = 5.34, b = 17, bat_lim =   6801, error = -11, sm_append = 0.65726, lets_finer =0.65726, max_a_sm_err = 0.8535505, low_pass = 100, finer = 1\n",
      "Step   380, estim_aver_bat_size = 5.44, b = 15, bat_lim =   5901, error = -9, sm_append = 0.56069, lets_finer =0.56069, max_a_sm_err = 0.8535505, low_pass = 100, finer = 1\n",
      "Step   381, estim_aver_bat_size = 5.57, b = 19, bat_lim =   4601, error = -13, sm_append = 0.42509, lets_finer =0.42509, max_a_sm_err = 0.8535505, low_pass = 100, finer = 1\n",
      "Step   382, estim_aver_bat_size = 5.70, b = 18, bat_lim =   3401, error = -12, sm_append = 0.30083, lets_finer =0.30083, max_a_sm_err = 0.8535505, low_pass = 100, finer = 1\n",
      "Step   383, estim_aver_bat_size = 5.78, b = 14, bat_lim =   2601, error = -8, sm_append = 0.21783, lets_finer =0.21783, max_a_sm_err = 0.8535505, low_pass = 100, finer = 1\n",
      "Step   384, estim_aver_bat_size = 5.87, b = 15, bat_lim =   1701, error = -9, sm_append = 0.12565, lets_finer =0.12565, max_a_sm_err = 0.8535505, low_pass = 100, finer = 1\n",
      "Step   385, estim_aver_bat_size = 5.95, b = 13, bat_lim =   1001, error = -7, sm_append = 0.05439, lets_finer =0.05439, max_a_sm_err = 0.8535505, low_pass = 100, finer = 1\n",
      "Step   386, estim_aver_bat_size = 6.04, b = 15, bat_lim =    101, error = -9, sm_append = -0.03615, lets_finer =0.03615, max_a_sm_err = 0.8535505, low_pass = 100, finer = 1\n",
      "Step   387, estim_aver_bat_size = 6.18, b = 20, bat_lim =  -1299, error = -14, sm_append = -0.17579, lets_finer =0.17579, max_a_sm_err = 0.7750150, low_pass = 100, finer = 1\n",
      "Step   388, estim_aver_bat_size = 6.20, b =  9, bat_lim =  -1599, error = -3, sm_append = -0.20403, lets_finer =0.20403, max_a_sm_err = 0.6572648, low_pass = 100, finer = 1\n",
      "Step   389, estim_aver_bat_size = 6.27, b = 13, bat_lim =  -2299, error = -7, sm_append = -0.27199, lets_finer =0.27199, max_a_sm_err = 0.5606922, low_pass = 100, finer = 1\n",
      "Step   390, estim_aver_bat_size = 6.30, b =  9, bat_lim =  -2599, error = -3, sm_append = -0.29927, lets_finer =0.29927, max_a_sm_err = 0.4250852, low_pass = 100, finer = 1\n",
      "Step   391, estim_aver_bat_size = 6.35, b = 11, bat_lim =  -3099, error = -5, sm_append = -0.34628, lets_finer =0.34628, max_a_sm_err = 0.3462802, low_pass = 100, finer = 1\n",
      "Step   392, estim_aver_bat_size = 6.40, b = 12, bat_lim =  -3699, error = -6, sm_append = -0.40282, lets_finer =0.40282, max_a_sm_err = 0.4028174, low_pass = 100, finer = 1\n",
      "Step   393, estim_aver_bat_size = 6.40, b =  6, bat_lim =  -3699, error =  0, sm_append = -0.39879, lets_finer =0.39879, max_a_sm_err = 0.4028174, low_pass = 100, finer = 1\n",
      "Step   394, estim_aver_bat_size = 6.39, b =  6, bat_lim =  -3699, error =  0, sm_append = -0.39480, lets_finer =0.39480, max_a_sm_err = 0.4028174, low_pass = 100, finer = 1\n",
      "Step   395, estim_aver_bat_size = 6.40, b =  7, bat_lim =  -3799, error = -1, sm_append = -0.40085, lets_finer =0.40085, max_a_sm_err = 0.4028174, low_pass = 100, finer = 1\n",
      "Step   396, estim_aver_bat_size = 6.44, b = 10, bat_lim =  -4199, error = -4, sm_append = -0.43684, lets_finer =0.43684, max_a_sm_err = 0.4368448, low_pass = 100, finer = 1\n",
      "Step   397, estim_aver_bat_size = 6.48, b = 11, bat_lim =  -4699, error = -5, sm_append = -0.48248, lets_finer =0.48248, max_a_sm_err = 0.4824763, low_pass = 100, finer = 1\n",
      "Step   398, estim_aver_bat_size = 6.44, b =  2, bat_lim =  -4299, error =  4, sm_append = -0.43765, lets_finer =0.43765, max_a_sm_err = 0.4824763, low_pass = 100, finer = 1\n",
      "Step   399, estim_aver_bat_size = 6.41, b =  4, bat_lim =  -4099, error =  2, sm_append = -0.41328, lets_finer =0.41328, max_a_sm_err = 0.4824763, low_pass = 100, finer = 1\n",
      "Step   400, estim_aver_bat_size = 6.38, b =  3, bat_lim =  -3799, error =  3, sm_append = -0.37914, lets_finer =0.37914, max_a_sm_err = 0.4824763, low_pass = 100, finer = 1\n",
      "Step   401, estim_aver_bat_size = 6.33, b =  1, bat_lim =  -3299, error =  5, sm_append = -0.32535, lets_finer =0.32535, max_a_sm_err = 0.4824763, low_pass = 100, finer = 1\n",
      "Step   402, estim_aver_bat_size = 6.27, b =  1, bat_lim =  -2799, error =  5, sm_append = -0.27210, lets_finer =0.27210, max_a_sm_err = 0.4824763, low_pass = 100, finer = 1\n",
      "Step   403, estim_aver_bat_size = 6.22, b =  1, bat_lim =  -2299, error =  5, sm_append = -0.21938, lets_finer =0.21938, max_a_sm_err = 0.4824763, low_pass = 100, finer = 1\n",
      "Step   404, estim_aver_bat_size = 6.17, b =  1, bat_lim =  -1799, error =  5, sm_append = -0.16718, lets_finer =0.16718, max_a_sm_err = 0.4824763, low_pass = 100, finer = 1\n",
      "Step   405, estim_aver_bat_size = 6.12, b =  1, bat_lim =  -1299, error =  5, sm_append = -0.11551, lets_finer =0.11551, max_a_sm_err = 0.4824763, low_pass = 100, finer = 1\n",
      "Step   406, estim_aver_bat_size = 6.06, b =  1, bat_lim =   -799, error =  5, sm_append = -0.06436, lets_finer =0.06436, max_a_sm_err = 0.4824763, low_pass = 100, finer = 1\n",
      "Step   407, estim_aver_bat_size = 6.01, b =  1, bat_lim =   -299, error =  5, sm_append = -0.01371, lets_finer =0.01371, max_a_sm_err = 0.4376515, low_pass = 100, finer = 1\n",
      "Step   408, estim_aver_bat_size = 5.96, b =  1, bat_lim =    201, error =  5, sm_append = 0.03642, lets_finer =0.03642, max_a_sm_err = 0.4132750, low_pass = 100, finer = 1\n",
      "Step   409, estim_aver_bat_size = 5.91, b =  1, bat_lim =    701, error =  5, sm_append = 0.08606, lets_finer =0.08606, max_a_sm_err = 0.3791423, low_pass = 100, finer = 1\n",
      "Step   410, estim_aver_bat_size = 5.86, b =  1, bat_lim =   1201, error =  5, sm_append = 0.13520, lets_finer =0.13520, max_a_sm_err = 0.3253509, low_pass = 100, finer = 1\n",
      "Step   411, estim_aver_bat_size = 5.82, b =  1, bat_lim =   1701, error =  5, sm_append = 0.18385, lets_finer =0.18385, max_a_sm_err = 0.2720974, low_pass = 100, finer = 1\n",
      "Step   412, estim_aver_bat_size = 5.77, b =  1, bat_lim =   2201, error =  5, sm_append = 0.23201, lets_finer =0.23201, max_a_sm_err = 0.2320097, low_pass = 100, finer = 1\n",
      "Step   413, estim_aver_bat_size = 5.72, b =  1, bat_lim =   2701, error =  5, sm_append = 0.27969, lets_finer =0.27969, max_a_sm_err = 0.2796896, low_pass = 100, finer = 1\n",
      "Step   414, estim_aver_bat_size = 5.67, b =  1, bat_lim =   3201, error =  5, sm_append = 0.32689, lets_finer =0.32689, max_a_sm_err = 0.3268927, low_pass = 100, finer = 1\n",
      "Step   415, estim_aver_bat_size = 5.63, b =  1, bat_lim =   3701, error =  5, sm_append = 0.37362, lets_finer =0.37362, max_a_sm_err = 0.3736237, low_pass = 100, finer = 1\n",
      "Step   416, estim_aver_bat_size = 5.58, b =  1, bat_lim =   4201, error =  5, sm_append = 0.41989, lets_finer =0.41989, max_a_sm_err = 0.4198875, low_pass = 100, finer = 1\n",
      "Step   417, estim_aver_bat_size = 5.53, b =  1, bat_lim =   4701, error =  5, sm_append = 0.46569, lets_finer =0.46569, max_a_sm_err = 0.4656886, low_pass = 100, finer = 1\n",
      "Step   418, estim_aver_bat_size = 5.49, b =  1, bat_lim =   5201, error =  5, sm_append = 0.51103, lets_finer =0.51103, max_a_sm_err = 0.5110317, low_pass = 100, finer = 1\n",
      "Step   419, estim_aver_bat_size = 5.44, b =  1, bat_lim =   5701, error =  5, sm_append = 0.55592, lets_finer =0.55592, max_a_sm_err = 0.5559214, low_pass = 100, finer = 1\n",
      "Step   420, estim_aver_bat_size = 5.40, b =  1, bat_lim =   6201, error =  5, sm_append = 0.60036, lets_finer =0.60036, max_a_sm_err = 0.6003622, low_pass = 100, finer = 1\n",
      "Step   421, estim_aver_bat_size = 5.36, b =  1, bat_lim =   6701, error =  5, sm_append = 0.64436, lets_finer =0.64436, max_a_sm_err = 0.6443586, low_pass = 100, finer = 1\n",
      "Step   422, estim_aver_bat_size = 5.31, b =  1, bat_lim =   7201, error =  5, sm_append = 0.68792, lets_finer =0.68792, max_a_sm_err = 0.6879150, low_pass = 100, finer = 1\n",
      "Step   423, estim_aver_bat_size = 5.27, b =  1, bat_lim =   7701, error =  5, sm_append = 0.73104, lets_finer =0.73104, max_a_sm_err = 0.7310359, low_pass = 100, finer = 1\n",
      "Step   424, estim_aver_bat_size = 5.23, b =  1, bat_lim =   8201, error =  5, sm_append = 0.77373, lets_finer =0.77373, max_a_sm_err = 0.7737255, low_pass = 100, finer = 1\n",
      "Step   425, estim_aver_bat_size = 5.18, b =  1, bat_lim =   8701, error =  5, sm_append = 0.81599, lets_finer =0.81599, max_a_sm_err = 0.8159882, low_pass = 100, finer = 1\n",
      "Step   426, estim_aver_bat_size = 5.14, b =  1, bat_lim =   9201, error =  5, sm_append = 0.85783, lets_finer =0.85783, max_a_sm_err = 0.8578284, low_pass = 100, finer = 1\n",
      "Step   427, estim_aver_bat_size = 5.10, b =  1, bat_lim =   9701, error =  5, sm_append = 0.89925, lets_finer =0.89925, max_a_sm_err = 0.8992501, low_pass = 100, finer = 1\n",
      "Step   428, estim_aver_bat_size = 5.07, b =  2, bat_lim =  10101, error =  4, sm_append = 0.93026, lets_finer =0.93026, max_a_sm_err = 0.9302576, low_pass = 100, finer = 1\n",
      "Step   429, estim_aver_bat_size = 5.04, b =  2, bat_lim =  10501, error =  4, sm_append = 0.96095, lets_finer =0.96095, max_a_sm_err = 0.9609550, low_pass = 100, finer = 1\n",
      "Step   430, estim_aver_bat_size = 5.21, b = 22, bat_lim =   8901, error = -16, sm_append = 0.79135, lets_finer =0.79135, max_a_sm_err = 0.9609550, low_pass = 100, finer = 1\n",
      "Step   431, estim_aver_bat_size = 5.37, b = 21, bat_lim =   7401, error = -15, sm_append = 0.63343, lets_finer =0.63343, max_a_sm_err = 0.9609550, low_pass = 100, finer = 1\n",
      "Step   432, estim_aver_bat_size = 5.51, b = 20, bat_lim =   6001, error = -14, sm_append = 0.48710, lets_finer =0.48710, max_a_sm_err = 0.9609550, low_pass = 100, finer = 1\n",
      "Step   433, estim_aver_bat_size = 5.66, b = 20, bat_lim =   4601, error = -14, sm_append = 0.34223, lets_finer =0.34223, max_a_sm_err = 0.9609550, low_pass = 100, finer = 1\n",
      "Step   434, estim_aver_bat_size = 5.80, b = 20, bat_lim =   3201, error = -14, sm_append = 0.19880, lets_finer =0.19880, max_a_sm_err = 0.9609550, low_pass = 100, finer = 1\n",
      "Step   435, estim_aver_bat_size = 5.93, b = 19, bat_lim =   1901, error = -13, sm_append = 0.06682, lets_finer =0.06682, max_a_sm_err = 0.9609550, low_pass = 100, finer = 1\n",
      "Step   436, estim_aver_bat_size = 6.06, b = 19, bat_lim =    601, error = -13, sm_append = -0.06385, lets_finer =0.06385, max_a_sm_err = 0.9609550, low_pass = 100, finer = 1\n",
      "Step   437, estim_aver_bat_size = 6.17, b = 17, bat_lim =   -499, error = -11, sm_append = -0.17321, lets_finer =0.17321, max_a_sm_err = 0.9609550, low_pass = 100, finer = 1\n",
      "Step   438, estim_aver_bat_size = 6.30, b = 19, bat_lim =  -1799, error = -13, sm_append = -0.30148, lets_finer =0.30148, max_a_sm_err = 0.9609550, low_pass = 100, finer = 1\n",
      "Step   439, estim_aver_bat_size = 6.44, b = 20, bat_lim =  -3199, error = -14, sm_append = -0.43847, lets_finer =0.43847, max_a_sm_err = 0.7913454, low_pass = 100, finer = 1\n",
      "Step   440, estim_aver_bat_size = 6.50, b = 13, bat_lim =  -3899, error = -7, sm_append = -0.50408, lets_finer =0.50408, max_a_sm_err = 0.6334320, low_pass = 100, finer = 1\n",
      "Step   441, estim_aver_bat_size = 6.52, b =  8, bat_lim =  -4099, error = -2, sm_append = -0.51904, lets_finer =0.51904, max_a_sm_err = 0.5190408, low_pass = 100, finer = 1\n",
      "Step   442, estim_aver_bat_size = 6.52, b =  7, bat_lim =  -4199, error = -1, sm_append = -0.52385, lets_finer =0.52385, max_a_sm_err = 0.5238504, low_pass = 100, finer = 1\n",
      "Step   443, estim_aver_bat_size = 6.55, b =  9, bat_lim =  -4499, error = -3, sm_append = -0.54861, lets_finer =0.54861, max_a_sm_err = 0.5486119, low_pass = 100, finer = 1\n",
      "Step   444, estim_aver_bat_size = 6.56, b =  8, bat_lim =  -4699, error = -2, sm_append = -0.56313, lets_finer =0.56313, max_a_sm_err = 0.5631258, low_pass = 100, finer = 1\n",
      "Step   445, estim_aver_bat_size = 6.57, b =  7, bat_lim =  -4799, error = -1, sm_append = -0.56749, lets_finer =0.56749, max_a_sm_err = 0.5674945, low_pass = 100, finer = 1\n",
      "Step   446, estim_aver_bat_size = 6.56, b =  6, bat_lim =  -4799, error =  0, sm_append = -0.56182, lets_finer =0.56182, max_a_sm_err = 0.5674945, low_pass = 100, finer = 1\n",
      "Step   447, estim_aver_bat_size = 6.59, b =  9, bat_lim =  -5099, error = -3, sm_append = -0.58620, lets_finer =0.58620, max_a_sm_err = 0.5862014, low_pass = 100, finer = 1\n",
      "Step   448, estim_aver_bat_size = 6.59, b =  7, bat_lim =  -5199, error = -1, sm_append = -0.59034, lets_finer =0.59034, max_a_sm_err = 0.5903394, low_pass = 100, finer = 1\n",
      "Step   449, estim_aver_bat_size = 6.59, b =  7, bat_lim =  -5299, error = -1, sm_append = -0.59444, lets_finer =0.59444, max_a_sm_err = 0.5944360, low_pass = 100, finer = 1\n",
      "Step   450, estim_aver_bat_size = 6.54, b =  1, bat_lim =  -4799, error =  5, sm_append = -0.53849, lets_finer =0.53849, max_a_sm_err = 0.5944360, low_pass = 100, finer = 1\n",
      "Step   451, estim_aver_bat_size = 6.53, b =  6, bat_lim =  -4799, error =  0, sm_append = -0.53311, lets_finer =0.53311, max_a_sm_err = 0.5944360, low_pass = 100, finer = 1\n",
      "Step   452, estim_aver_bat_size = 6.53, b =  6, bat_lim =  -4799, error =  0, sm_append = -0.52778, lets_finer =0.52778, max_a_sm_err = 0.5944360, low_pass = 100, finer = 1\n",
      "Step   453, estim_aver_bat_size = 6.53, b =  7, bat_lim =  -4899, error = -1, sm_append = -0.53250, lets_finer =0.53250, max_a_sm_err = 0.5944360, low_pass = 100, finer = 1\n",
      "Step   454, estim_aver_bat_size = 6.48, b =  1, bat_lim =  -4399, error =  5, sm_append = -0.47717, lets_finer =0.47717, max_a_sm_err = 0.5944360, low_pass = 100, finer = 1\n",
      "Step   455, estim_aver_bat_size = 6.43, b =  2, bat_lim =  -3999, error =  4, sm_append = -0.43240, lets_finer =0.43240, max_a_sm_err = 0.5944360, low_pass = 100, finer = 1\n",
      "Step   456, estim_aver_bat_size = 6.39, b =  2, bat_lim =  -3599, error =  4, sm_append = -0.38808, lets_finer =0.38808, max_a_sm_err = 0.5944360, low_pass = 100, finer = 1\n",
      "Step   457, estim_aver_bat_size = 6.33, b =  1, bat_lim =  -3099, error =  5, sm_append = -0.33420, lets_finer =0.33420, max_a_sm_err = 0.5944360, low_pass = 100, finer = 1\n",
      "Step   458, estim_aver_bat_size = 6.28, b =  1, bat_lim =  -2599, error =  5, sm_append = -0.28085, lets_finer =0.28085, max_a_sm_err = 0.5944360, low_pass = 100, finer = 1\n",
      "Step   459, estim_aver_bat_size = 6.23, b =  1, bat_lim =  -2099, error =  5, sm_append = -0.22805, lets_finer =0.22805, max_a_sm_err = 0.5384916, low_pass = 100, finer = 1\n",
      "Step   460, estim_aver_bat_size = 6.18, b =  1, bat_lim =  -1599, error =  5, sm_append = -0.17577, lets_finer =0.17577, max_a_sm_err = 0.5331067, low_pass = 100, finer = 1\n",
      "Step   461, estim_aver_bat_size = 6.12, b =  1, bat_lim =  -1099, error =  5, sm_append = -0.12401, lets_finer =0.12401, max_a_sm_err = 0.5324979, low_pass = 100, finer = 1\n",
      "Step   462, estim_aver_bat_size = 6.07, b =  1, bat_lim =   -599, error =  5, sm_append = -0.07277, lets_finer =0.07277, max_a_sm_err = 0.5324979, low_pass = 100, finer = 1\n",
      "Step   463, estim_aver_bat_size = 6.02, b =  1, bat_lim =    -99, error =  5, sm_append = -0.02204, lets_finer =0.02204, max_a_sm_err = 0.4771729, low_pass = 100, finer = 1\n",
      "Step   464, estim_aver_bat_size = 5.97, b =  1, bat_lim =    401, error =  5, sm_append = 0.02818, lets_finer =0.02818, max_a_sm_err = 0.4324012, low_pass = 100, finer = 1\n",
      "Step   465, estim_aver_bat_size = 5.92, b =  1, bat_lim =    901, error =  5, sm_append = 0.07790, lets_finer =0.07790, max_a_sm_err = 0.3880772, low_pass = 100, finer = 1\n",
      "Step   466, estim_aver_bat_size = 5.87, b =  1, bat_lim =   1401, error =  5, sm_append = 0.12712, lets_finer =0.12712, max_a_sm_err = 0.3341964, low_pass = 100, finer = 1\n",
      "Step   467, estim_aver_bat_size = 5.82, b =  1, bat_lim =   1901, error =  5, sm_append = 0.17585, lets_finer =0.17585, max_a_sm_err = 0.2808544, low_pass = 100, finer = 1\n",
      "Step   468, estim_aver_bat_size = 5.78, b =  1, bat_lim =   2401, error =  5, sm_append = 0.22409, lets_finer =0.22409, max_a_sm_err = 0.2280459, low_pass = 100, finer = 1\n",
      "Step   469, estim_aver_bat_size = 5.73, b =  1, bat_lim =   2901, error =  5, sm_append = 0.27185, lets_finer =0.27185, max_a_sm_err = 0.2718490, low_pass = 100, finer = 1\n",
      "Step   470, estim_aver_bat_size = 5.68, b =  1, bat_lim =   3401, error =  5, sm_append = 0.31913, lets_finer =0.31913, max_a_sm_err = 0.3191305, low_pass = 100, finer = 1\n",
      "Step   471, estim_aver_bat_size = 5.63, b =  1, bat_lim =   3901, error =  5, sm_append = 0.36594, lets_finer =0.36594, max_a_sm_err = 0.3659392, low_pass = 100, finer = 1\n",
      "Step   472, estim_aver_bat_size = 5.59, b =  1, bat_lim =   4401, error =  5, sm_append = 0.41228, lets_finer =0.41228, max_a_sm_err = 0.4122798, low_pass = 100, finer = 1\n",
      "Step   473, estim_aver_bat_size = 5.54, b =  1, bat_lim =   4901, error =  5, sm_append = 0.45816, lets_finer =0.45816, max_a_sm_err = 0.4581570, low_pass = 100, finer = 1\n",
      "Step   474, estim_aver_bat_size = 5.50, b =  1, bat_lim =   5401, error =  5, sm_append = 0.50358, lets_finer =0.50358, max_a_sm_err = 0.5035754, low_pass = 100, finer = 1\n",
      "Step   475, estim_aver_bat_size = 5.45, b =  1, bat_lim =   5901, error =  5, sm_append = 0.54854, lets_finer =0.54854, max_a_sm_err = 0.5485397, low_pass = 100, finer = 1\n",
      "Step   476, estim_aver_bat_size = 5.41, b =  1, bat_lim =   6401, error =  5, sm_append = 0.59305, lets_finer =0.59305, max_a_sm_err = 0.5930543, low_pass = 100, finer = 1\n",
      "Step   477, estim_aver_bat_size = 5.36, b =  1, bat_lim =   6901, error =  5, sm_append = 0.63712, lets_finer =0.63712, max_a_sm_err = 0.6371238, low_pass = 100, finer = 1\n",
      "Step   478, estim_aver_bat_size = 5.32, b =  1, bat_lim =   7401, error =  5, sm_append = 0.68075, lets_finer =0.68075, max_a_sm_err = 0.6807525, low_pass = 100, finer = 1\n",
      "Step   479, estim_aver_bat_size = 5.28, b =  1, bat_lim =   7901, error =  5, sm_append = 0.72394, lets_finer =0.72394, max_a_sm_err = 0.7239450, low_pass = 100, finer = 1\n",
      "Step   480, estim_aver_bat_size = 5.23, b =  1, bat_lim =   8401, error =  5, sm_append = 0.76671, lets_finer =0.76671, max_a_sm_err = 0.7667055, low_pass = 100, finer = 1\n",
      "Step   481, estim_aver_bat_size = 5.33, b = 15, bat_lim =   7501, error = -9, sm_append = 0.66904, lets_finer =0.66904, max_a_sm_err = 0.7667055, low_pass = 100, finer = 1\n",
      "Step   482, estim_aver_bat_size = 5.43, b = 15, bat_lim =   6601, error = -9, sm_append = 0.57235, lets_finer =0.57235, max_a_sm_err = 0.7667055, low_pass = 100, finer = 1\n",
      "Step   483, estim_aver_bat_size = 5.53, b = 16, bat_lim =   5601, error = -10, sm_append = 0.46662, lets_finer =0.46662, max_a_sm_err = 0.7667055, low_pass = 100, finer = 1\n",
      "Step   484, estim_aver_bat_size = 5.65, b = 17, bat_lim =   4501, error = -11, sm_append = 0.35196, lets_finer =0.35196, max_a_sm_err = 0.7667055, low_pass = 100, finer = 1\n",
      "Step   485, estim_aver_bat_size = 5.75, b = 16, bat_lim =   3501, error = -10, sm_append = 0.24844, lets_finer =0.24844, max_a_sm_err = 0.7667055, low_pass = 100, finer = 1\n",
      "Step   486, estim_aver_bat_size = 5.73, b =  4, bat_lim =   3701, error =  2, sm_append = 0.26595, lets_finer =0.26595, max_a_sm_err = 0.7667055, low_pass = 100, finer = 1\n",
      "Step   487, estim_aver_bat_size = 5.83, b = 15, bat_lim =   2801, error = -9, sm_append = 0.17329, lets_finer =0.17329, max_a_sm_err = 0.7667055, low_pass = 100, finer = 1\n",
      "Step   488, estim_aver_bat_size = 5.93, b = 16, bat_lim =   1801, error = -10, sm_append = 0.07156, lets_finer =0.07156, max_a_sm_err = 0.7667055, low_pass = 100, finer = 1\n",
      "Step   489, estim_aver_bat_size = 6.05, b = 18, bat_lim =    601, error = -12, sm_append = -0.04915, lets_finer =0.04915, max_a_sm_err = 0.7667055, low_pass = 100, finer = 1\n",
      "Step   490, estim_aver_bat_size = 6.14, b = 15, bat_lim =   -299, error = -9, sm_append = -0.13866, lets_finer =0.13866, max_a_sm_err = 0.6690385, low_pass = 100, finer = 1\n",
      "Step   491, estim_aver_bat_size = 6.21, b = 13, bat_lim =   -999, error = -7, sm_append = -0.20728, lets_finer =0.20728, max_a_sm_err = 0.5723481, low_pass = 100, finer = 1\n",
      "Step   492, estim_aver_bat_size = 6.24, b =  9, bat_lim =  -1299, error = -3, sm_append = -0.23520, lets_finer =0.23520, max_a_sm_err = 0.4666246, low_pass = 100, finer = 1\n",
      "Step   493, estim_aver_bat_size = 6.27, b = 10, bat_lim =  -1699, error = -4, sm_append = -0.27285, lets_finer =0.27285, max_a_sm_err = 0.3519584, low_pass = 100, finer = 1\n",
      "Step   494, estim_aver_bat_size = 6.30, b =  9, bat_lim =  -1999, error = -3, sm_append = -0.30012, lets_finer =0.30012, max_a_sm_err = 0.3001223, low_pass = 100, finer = 1\n",
      "Step   495, estim_aver_bat_size = 6.32, b =  8, bat_lim =  -2199, error = -2, sm_append = -0.31712, lets_finer =0.31712, max_a_sm_err = 0.3171210, low_pass = 100, finer = 1\n",
      "Step   496, estim_aver_bat_size = 6.40, b = 15, bat_lim =  -3099, error = -9, sm_append = -0.40395, lets_finer =0.40395, max_a_sm_err = 0.4039498, low_pass = 100, finer = 1\n",
      "Step   497, estim_aver_bat_size = 6.41, b =  7, bat_lim =  -3199, error = -1, sm_append = -0.40991, lets_finer =0.40991, max_a_sm_err = 0.4099103, low_pass = 100, finer = 1\n",
      "Step   498, estim_aver_bat_size = 6.42, b =  7, bat_lim =  -3299, error = -1, sm_append = -0.41581, lets_finer =0.41581, max_a_sm_err = 0.4158112, low_pass = 100, finer = 1\n",
      "Step   499, estim_aver_bat_size = 6.42, b =  7, bat_lim =  -3399, error = -1, sm_append = -0.42165, lets_finer =0.42165, max_a_sm_err = 0.4216531, low_pass = 100, finer = 1\n",
      "Step   500, estim_aver_bat_size = 6.42, b =  6, bat_lim =  -3399, error =  0, sm_append = -0.41744, lets_finer =0.41744, max_a_sm_err = 0.4216531, low_pass = 100, finer = 1\n",
      "Step   501, estim_aver_bat_size = 6.36, b =  1, bat_lim =  -2899, error =  5, sm_append = -0.36326, lets_finer =0.36326, max_a_sm_err = 0.4216531, low_pass = 100, finer = 1\n",
      "Step   502, estim_aver_bat_size = 6.31, b =  1, bat_lim =  -2399, error =  5, sm_append = -0.30963, lets_finer =0.30963, max_a_sm_err = 0.4216531, low_pass = 100, finer = 1\n",
      "Step   503, estim_aver_bat_size = 6.26, b =  1, bat_lim =  -1899, error =  5, sm_append = -0.25653, lets_finer =0.25653, max_a_sm_err = 0.4216531, low_pass = 100, finer = 1\n",
      "Step   504, estim_aver_bat_size = 6.20, b =  1, bat_lim =  -1399, error =  5, sm_append = -0.20397, lets_finer =0.20397, max_a_sm_err = 0.4216531, low_pass = 100, finer = 1\n",
      "Step   505, estim_aver_bat_size = 6.15, b =  1, bat_lim =   -899, error =  5, sm_append = -0.15193, lets_finer =0.15193, max_a_sm_err = 0.4216531, low_pass = 100, finer = 1\n",
      "Step   506, estim_aver_bat_size = 6.10, b =  1, bat_lim =   -399, error =  5, sm_append = -0.10041, lets_finer =0.10041, max_a_sm_err = 0.4216531, low_pass = 100, finer = 1\n",
      "Step   507, estim_aver_bat_size = 6.05, b =  1, bat_lim =    101, error =  5, sm_append = -0.04940, lets_finer =0.04940, max_a_sm_err = 0.4216531, low_pass = 100, finer = 1\n",
      "Step   508, estim_aver_bat_size = 6.00, b =  1, bat_lim =    601, error =  5, sm_append = 0.00109, lets_finer =0.00109, max_a_sm_err = 0.4216531, low_pass = 100, finer = 1\n",
      "Step   509, estim_aver_bat_size = 5.95, b =  1, bat_lim =   1101, error =  5, sm_append = 0.05108, lets_finer =0.05108, max_a_sm_err = 0.4174366, low_pass = 100, finer = 1\n",
      "Step   510, estim_aver_bat_size = 5.90, b =  1, bat_lim =   1601, error =  5, sm_append = 0.10057, lets_finer =0.10057, max_a_sm_err = 0.3632622, low_pass = 100, finer = 1\n",
      "Step   511, estim_aver_bat_size = 5.85, b =  1, bat_lim =   2101, error =  5, sm_append = 0.14956, lets_finer =0.14956, max_a_sm_err = 0.3096296, low_pass = 100, finer = 1\n",
      "Step   512, estim_aver_bat_size = 5.80, b =  1, bat_lim =   2601, error =  5, sm_append = 0.19807, lets_finer =0.19807, max_a_sm_err = 0.2565333, low_pass = 100, finer = 1\n",
      "Step   513, estim_aver_bat_size = 5.75, b =  1, bat_lim =   3101, error =  5, sm_append = 0.24609, lets_finer =0.24609, max_a_sm_err = 0.2460855, low_pass = 100, finer = 1\n",
      "Step   514, estim_aver_bat_size = 5.71, b =  1, bat_lim =   3601, error =  5, sm_append = 0.29362, lets_finer =0.29362, max_a_sm_err = 0.2936247, low_pass = 100, finer = 1\n",
      "Step   515, estim_aver_bat_size = 5.66, b =  1, bat_lim =   4101, error =  5, sm_append = 0.34069, lets_finer =0.34069, max_a_sm_err = 0.3406884, low_pass = 100, finer = 1\n",
      "Step   516, estim_aver_bat_size = 5.61, b =  1, bat_lim =   4601, error =  5, sm_append = 0.38728, lets_finer =0.38728, max_a_sm_err = 0.3872815, low_pass = 100, finer = 1\n",
      "Step   517, estim_aver_bat_size = 5.57, b =  1, bat_lim =   5101, error =  5, sm_append = 0.43341, lets_finer =0.43341, max_a_sm_err = 0.4334087, low_pass = 100, finer = 1\n",
      "Step   518, estim_aver_bat_size = 5.52, b =  1, bat_lim =   5601, error =  5, sm_append = 0.47907, lets_finer =0.47907, max_a_sm_err = 0.4790746, low_pass = 100, finer = 1\n",
      "Step   519, estim_aver_bat_size = 5.48, b =  1, bat_lim =   6101, error =  5, sm_append = 0.52428, lets_finer =0.52428, max_a_sm_err = 0.5242839, low_pass = 100, finer = 1\n",
      "Step   520, estim_aver_bat_size = 5.43, b =  1, bat_lim =   6601, error =  5, sm_append = 0.56904, lets_finer =0.56904, max_a_sm_err = 0.5690410, low_pass = 100, finer = 1\n",
      "Step   521, estim_aver_bat_size = 5.39, b =  1, bat_lim =   7101, error =  5, sm_append = 0.61335, lets_finer =0.61335, max_a_sm_err = 0.6133506, low_pass = 100, finer = 1\n",
      "Step   522, estim_aver_bat_size = 5.34, b =  1, bat_lim =   7601, error =  5, sm_append = 0.65722, lets_finer =0.65722, max_a_sm_err = 0.6572171, low_pass = 100, finer = 1\n",
      "Step   523, estim_aver_bat_size = 5.30, b =  1, bat_lim =   8101, error =  5, sm_append = 0.70064, lets_finer =0.70064, max_a_sm_err = 0.7006449, low_pass = 100, finer = 1\n",
      "Step   524, estim_aver_bat_size = 5.26, b =  1, bat_lim =   8601, error =  5, sm_append = 0.74364, lets_finer =0.74364, max_a_sm_err = 0.7436385, low_pass = 100, finer = 1\n",
      "Step   525, estim_aver_bat_size = 5.21, b =  1, bat_lim =   9101, error =  5, sm_append = 0.78620, lets_finer =0.78620, max_a_sm_err = 0.7862021, low_pass = 100, finer = 1\n",
      "Step   526, estim_aver_bat_size = 5.34, b = 18, bat_lim =   7901, error = -12, sm_append = 0.65834, lets_finer =0.65834, max_a_sm_err = 0.7862021, low_pass = 100, finer = 1\n",
      "Step   527, estim_aver_bat_size = 5.43, b = 14, bat_lim =   7101, error = -8, sm_append = 0.57176, lets_finer =0.57176, max_a_sm_err = 0.7862021, low_pass = 100, finer = 1\n",
      "Step   528, estim_aver_bat_size = 5.53, b = 16, bat_lim =   6101, error = -10, sm_append = 0.46604, lets_finer =0.46604, max_a_sm_err = 0.7862021, low_pass = 100, finer = 1\n",
      "Step   529, estim_aver_bat_size = 5.65, b = 17, bat_lim =   5001, error = -11, sm_append = 0.35138, lets_finer =0.35138, max_a_sm_err = 0.7862021, low_pass = 100, finer = 1\n",
      "Step   530, estim_aver_bat_size = 5.78, b = 19, bat_lim =   3701, error = -13, sm_append = 0.21786, lets_finer =0.21786, max_a_sm_err = 0.7862021, low_pass = 100, finer = 1\n",
      "Step   531, estim_aver_bat_size = 5.87, b = 15, bat_lim =   2801, error = -9, sm_append = 0.12569, lets_finer =0.12569, max_a_sm_err = 0.7862021, low_pass = 100, finer = 1\n",
      "Step   532, estim_aver_bat_size = 5.97, b = 15, bat_lim =   1901, error = -9, sm_append = 0.03443, lets_finer =0.03443, max_a_sm_err = 0.7862021, low_pass = 100, finer = 1\n",
      "Step   533, estim_aver_bat_size = 6.07, b = 16, bat_lim =    901, error = -10, sm_append = -0.06591, lets_finer =0.06591, max_a_sm_err = 0.7862021, low_pass = 100, finer = 1\n",
      "Step   534, estim_aver_bat_size = 6.18, b = 17, bat_lim =   -199, error = -11, sm_append = -0.17526, lets_finer =0.17526, max_a_sm_err = 0.7862021, low_pass = 100, finer = 1\n",
      "Step   535, estim_aver_bat_size = 6.27, b = 16, bat_lim =  -1199, error = -10, sm_append = -0.27350, lets_finer =0.27350, max_a_sm_err = 0.6583401, low_pass = 100, finer = 1\n",
      "Step   536, estim_aver_bat_size = 6.37, b = 16, bat_lim =  -2199, error = -10, sm_append = -0.37077, lets_finer =0.37077, max_a_sm_err = 0.5717567, low_pass = 100, finer = 1\n",
      "Step   537, estim_aver_bat_size = 6.40, b =  9, bat_lim =  -2499, error = -3, sm_append = -0.39706, lets_finer =0.39706, max_a_sm_err = 0.4660391, low_pass = 100, finer = 1\n",
      "Step   538, estim_aver_bat_size = 6.45, b = 12, bat_lim =  -3099, error = -6, sm_append = -0.45309, lets_finer =0.45309, max_a_sm_err = 0.4530898, low_pass = 100, finer = 1\n",
      "Step   539, estim_aver_bat_size = 6.50, b = 11, bat_lim =  -3599, error = -5, sm_append = -0.49856, lets_finer =0.49856, max_a_sm_err = 0.4985589, low_pass = 100, finer = 1\n",
      "Step   540, estim_aver_bat_size = 6.56, b = 13, bat_lim =  -4299, error = -7, sm_append = -0.56357, lets_finer =0.56357, max_a_sm_err = 0.5635734, low_pass = 100, finer = 1\n",
      "Step   541, estim_aver_bat_size = 6.62, b = 12, bat_lim =  -4899, error = -6, sm_append = -0.61794, lets_finer =0.61794, max_a_sm_err = 0.6179376, low_pass = 100, finer = 1\n",
      "Step   542, estim_aver_bat_size = 6.64, b =  9, bat_lim =  -5199, error = -3, sm_append = -0.64176, lets_finer =0.64176, max_a_sm_err = 0.6417582, low_pass = 100, finer = 1\n",
      "Step   543, estim_aver_bat_size = 6.71, b = 13, bat_lim =  -5899, error = -7, sm_append = -0.70534, lets_finer =0.70534, max_a_sm_err = 0.7053407, low_pass = 100, finer = 1\n",
      "Step   544, estim_aver_bat_size = 6.76, b = 12, bat_lim =  -6499, error = -6, sm_append = -0.75829, lets_finer =0.75829, max_a_sm_err = 0.7582873, low_pass = 100, finer = 1\n",
      "Step   545, estim_aver_bat_size = 6.82, b = 13, bat_lim =  -7199, error = -7, sm_append = -0.82070, lets_finer =0.82070, max_a_sm_err = 0.8207044, low_pass = 100, finer = 1\n",
      "Step   546, estim_aver_bat_size = 6.76, b =  1, bat_lim =  -6699, error =  5, sm_append = -0.76250, lets_finer =0.76250, max_a_sm_err = 0.8207044, low_pass = 100, finer = 1\n",
      "Step   547, estim_aver_bat_size = 6.70, b =  1, bat_lim =  -6199, error =  5, sm_append = -0.70487, lets_finer =0.70487, max_a_sm_err = 0.8207044, low_pass = 100, finer = 1\n",
      "Step   548, estim_aver_bat_size = 6.65, b =  1, bat_lim =  -5699, error =  5, sm_append = -0.64782, lets_finer =0.64782, max_a_sm_err = 0.8207044, low_pass = 100, finer = 1\n",
      "Step   549, estim_aver_bat_size = 6.59, b =  1, bat_lim =  -5199, error =  5, sm_append = -0.59135, lets_finer =0.59135, max_a_sm_err = 0.8207044, low_pass = 100, finer = 1\n",
      "Step   550, estim_aver_bat_size = 6.54, b =  1, bat_lim =  -4699, error =  5, sm_append = -0.53543, lets_finer =0.53543, max_a_sm_err = 0.8207044, low_pass = 100, finer = 1\n",
      "Step   551, estim_aver_bat_size = 6.48, b =  1, bat_lim =  -4199, error =  5, sm_append = -0.48008, lets_finer =0.48008, max_a_sm_err = 0.8207044, low_pass = 100, finer = 1\n",
      "Step   552, estim_aver_bat_size = 6.43, b =  1, bat_lim =  -3699, error =  5, sm_append = -0.42528, lets_finer =0.42528, max_a_sm_err = 0.8207044, low_pass = 100, finer = 1\n",
      "Step   553, estim_aver_bat_size = 6.37, b =  1, bat_lim =  -3199, error =  5, sm_append = -0.37102, lets_finer =0.37102, max_a_sm_err = 0.8207044, low_pass = 100, finer = 1\n",
      "Step   554, estim_aver_bat_size = 6.32, b =  1, bat_lim =  -2699, error =  5, sm_append = -0.31731, lets_finer =0.31731, max_a_sm_err = 0.8207044, low_pass = 100, finer = 1\n",
      "Step   555, estim_aver_bat_size = 6.26, b =  1, bat_lim =  -2199, error =  5, sm_append = -0.26414, lets_finer =0.26414, max_a_sm_err = 0.7624973, low_pass = 100, finer = 1\n",
      "Step   556, estim_aver_bat_size = 6.21, b =  1, bat_lim =  -1699, error =  5, sm_append = -0.21150, lets_finer =0.21150, max_a_sm_err = 0.7048724, low_pass = 100, finer = 1\n",
      "Step   557, estim_aver_bat_size = 6.16, b =  1, bat_lim =  -1199, error =  5, sm_append = -0.15938, lets_finer =0.15938, max_a_sm_err = 0.6478236, low_pass = 100, finer = 1\n",
      "Step   558, estim_aver_bat_size = 6.11, b =  1, bat_lim =   -699, error =  5, sm_append = -0.10779, lets_finer =0.10779, max_a_sm_err = 0.5913454, low_pass = 100, finer = 1\n",
      "Step   559, estim_aver_bat_size = 6.06, b =  1, bat_lim =   -199, error =  5, sm_append = -0.05671, lets_finer =0.05671, max_a_sm_err = 0.5354319, low_pass = 100, finer = 1\n",
      "Step   560, estim_aver_bat_size = 6.01, b =  1, bat_lim =    301, error =  5, sm_append = -0.00615, lets_finer =0.00615, max_a_sm_err = 0.4800776, low_pass = 100, finer = 1\n",
      "Step   561, estim_aver_bat_size = 5.96, b =  1, bat_lim =    801, error =  5, sm_append = 0.04392, lets_finer =0.04392, max_a_sm_err = 0.4252769, low_pass = 100, finer = 1\n",
      "Step   562, estim_aver_bat_size = 5.91, b =  1, bat_lim =   1301, error =  5, sm_append = 0.09348, lets_finer =0.09348, max_a_sm_err = 0.3710241, low_pass = 100, finer = 1\n",
      "Step   563, estim_aver_bat_size = 5.86, b =  1, bat_lim =   1801, error =  5, sm_append = 0.14254, lets_finer =0.14254, max_a_sm_err = 0.3173138, low_pass = 100, finer = 1\n",
      "Step   564, estim_aver_bat_size = 5.81, b =  1, bat_lim =   2301, error =  5, sm_append = 0.19112, lets_finer =0.19112, max_a_sm_err = 0.2641407, low_pass = 100, finer = 1\n",
      "Step   565, estim_aver_bat_size = 5.76, b =  1, bat_lim =   2801, error =  5, sm_append = 0.23921, lets_finer =0.23921, max_a_sm_err = 0.2392055, low_pass = 100, finer = 1\n",
      "Step   566, estim_aver_bat_size = 5.71, b =  1, bat_lim =   3301, error =  5, sm_append = 0.28681, lets_finer =0.28681, max_a_sm_err = 0.2868135, low_pass = 100, finer = 1\n",
      "Step   567, estim_aver_bat_size = 5.67, b =  1, bat_lim =   3801, error =  5, sm_append = 0.33395, lets_finer =0.33395, max_a_sm_err = 0.3339453, low_pass = 100, finer = 1\n",
      "Step   568, estim_aver_bat_size = 5.62, b =  1, bat_lim =   4301, error =  5, sm_append = 0.38061, lets_finer =0.38061, max_a_sm_err = 0.3806059, low_pass = 100, finer = 1\n",
      "Step   569, estim_aver_bat_size = 5.57, b =  1, bat_lim =   4801, error =  5, sm_append = 0.42680, lets_finer =0.42680, max_a_sm_err = 0.4267998, low_pass = 100, finer = 1\n",
      "Step   570, estim_aver_bat_size = 5.53, b =  1, bat_lim =   5301, error =  5, sm_append = 0.47253, lets_finer =0.47253, max_a_sm_err = 0.4725318, low_pass = 100, finer = 1\n",
      "Step   571, estim_aver_bat_size = 5.48, b =  1, bat_lim =   5801, error =  5, sm_append = 0.51781, lets_finer =0.51781, max_a_sm_err = 0.5178065, low_pass = 100, finer = 1\n",
      "Step   572, estim_aver_bat_size = 5.44, b =  1, bat_lim =   6301, error =  5, sm_append = 0.56263, lets_finer =0.56263, max_a_sm_err = 0.5626284, low_pass = 100, finer = 1\n",
      "Step   573, estim_aver_bat_size = 5.39, b =  1, bat_lim =   6801, error =  5, sm_append = 0.60700, lets_finer =0.60700, max_a_sm_err = 0.6070021, low_pass = 100, finer = 1\n",
      "Step   574, estim_aver_bat_size = 5.35, b =  1, bat_lim =   7301, error =  5, sm_append = 0.65093, lets_finer =0.65093, max_a_sm_err = 0.6509321, low_pass = 100, finer = 1\n",
      "Step   575, estim_aver_bat_size = 5.31, b =  1, bat_lim =   7801, error =  5, sm_append = 0.69442, lets_finer =0.69442, max_a_sm_err = 0.6944228, low_pass = 100, finer = 1\n",
      "Step   576, estim_aver_bat_size = 5.26, b =  1, bat_lim =   8301, error =  5, sm_append = 0.73748, lets_finer =0.73748, max_a_sm_err = 0.7374786, low_pass = 100, finer = 1\n",
      "Step   577, estim_aver_bat_size = 5.22, b =  1, bat_lim =   8801, error =  5, sm_append = 0.78010, lets_finer =0.78010, max_a_sm_err = 0.7801038, low_pass = 100, finer = 1\n",
      "Step   578, estim_aver_bat_size = 5.18, b =  1, bat_lim =   9301, error =  5, sm_append = 0.82230, lets_finer =0.82230, max_a_sm_err = 0.8223027, low_pass = 100, finer = 1\n",
      "Step   579, estim_aver_bat_size = 5.14, b =  1, bat_lim =   9801, error =  5, sm_append = 0.86408, lets_finer =0.86408, max_a_sm_err = 0.8640797, low_pass = 100, finer = 1\n",
      "Step   580, estim_aver_bat_size = 5.10, b =  2, bat_lim =  10201, error =  4, sm_append = 0.89544, lets_finer =0.89544, max_a_sm_err = 0.8954389, low_pass = 100, finer = 1\n",
      "Step   581, estim_aver_bat_size = 5.06, b =  1, bat_lim =  10701, error =  5, sm_append = 0.93648, lets_finer =0.93648, max_a_sm_err = 0.9364845, low_pass = 100, finer = 1\n",
      "Step   582, estim_aver_bat_size = 5.07, b =  6, bat_lim =  10701, error =  0, sm_append = 0.92712, lets_finer =0.92712, max_a_sm_err = 0.9364845, low_pass = 100, finer = 1\n",
      "Step   583, estim_aver_bat_size = 5.07, b =  5, bat_lim =  10801, error =  1, sm_append = 0.92785, lets_finer =0.92785, max_a_sm_err = 0.9364845, low_pass = 100, finer = 1\n",
      "Step   584, estim_aver_bat_size = 5.08, b =  6, bat_lim =  10801, error =  0, sm_append = 0.91857, lets_finer =0.91857, max_a_sm_err = 0.9364845, low_pass = 100, finer = 1\n",
      "Step   585, estim_aver_bat_size = 5.09, b =  6, bat_lim =  10801, error =  0, sm_append = 0.90938, lets_finer =0.90938, max_a_sm_err = 0.9364845, low_pass = 100, finer = 1\n",
      "Step   586, estim_aver_bat_size = 5.14, b = 10, bat_lim =  10401, error = -4, sm_append = 0.86029, lets_finer =0.86029, max_a_sm_err = 0.9364845, low_pass = 100, finer = 1\n",
      "Step   587, estim_aver_bat_size = 5.20, b = 11, bat_lim =   9901, error = -5, sm_append = 0.80169, lets_finer =0.80169, max_a_sm_err = 0.9364845, low_pass = 100, finer = 1\n",
      "Step   588, estim_aver_bat_size = 5.27, b = 12, bat_lim =   9301, error = -6, sm_append = 0.73367, lets_finer =0.73367, max_a_sm_err = 0.9364845, low_pass = 100, finer = 1\n",
      "Step   589, estim_aver_bat_size = 5.30, b =  9, bat_lim =   9001, error = -3, sm_append = 0.69633, lets_finer =0.69633, max_a_sm_err = 0.9364845, low_pass = 100, finer = 1\n",
      "Step   590, estim_aver_bat_size = 5.37, b = 12, bat_lim =   8401, error = -6, sm_append = 0.62937, lets_finer =0.62937, max_a_sm_err = 0.9364845, low_pass = 100, finer = 1\n",
      "Step   591, estim_aver_bat_size = 5.41, b =  9, bat_lim =   8101, error = -3, sm_append = 0.59308, lets_finer =0.59308, max_a_sm_err = 0.9278485, low_pass = 100, finer = 1\n",
      "Step   592, estim_aver_bat_size = 5.54, b = 19, bat_lim =   6801, error = -13, sm_append = 0.45715, lets_finer =0.45715, max_a_sm_err = 0.9278485, low_pass = 100, finer = 1\n",
      "Step   593, estim_aver_bat_size = 5.70, b = 21, bat_lim =   5301, error = -15, sm_append = 0.30257, lets_finer =0.30257, max_a_sm_err = 0.9185700, low_pass = 100, finer = 1\n",
      "Step   594, estim_aver_bat_size = 5.83, b = 19, bat_lim =   4001, error = -13, sm_append = 0.16955, lets_finer =0.16955, max_a_sm_err = 0.9093843, low_pass = 100, finer = 1\n",
      "Step   595, estim_aver_bat_size = 5.96, b = 19, bat_lim =   2701, error = -13, sm_append = 0.03785, lets_finer =0.03785, max_a_sm_err = 0.8602905, low_pass = 100, finer = 1\n",
      "Step   596, estim_aver_bat_size = 6.13, b = 23, bat_lim =   1001, error = -17, sm_append = -0.13253, lets_finer =0.13253, max_a_sm_err = 0.8016876, low_pass = 100, finer = 1\n",
      "Step   597, estim_aver_bat_size = 6.31, b = 24, bat_lim =   -799, error = -18, sm_append = -0.31120, lets_finer =0.31120, max_a_sm_err = 0.7336707, low_pass = 100, finer = 1\n",
      "Step   598, estim_aver_bat_size = 6.44, b = 19, bat_lim =  -2099, error = -13, sm_append = -0.43809, lets_finer =0.43809, max_a_sm_err = 0.6963340, low_pass = 100, finer = 1\n",
      "Step   599, estim_aver_bat_size = 6.57, b = 20, bat_lim =  -3499, error = -14, sm_append = -0.57371, lets_finer =0.57371, max_a_sm_err = 0.6293706, low_pass = 100, finer = 1\n",
      "Step   600, estim_aver_bat_size = 6.72, b = 21, bat_lim =  -4999, error = -15, sm_append = -0.71797, lets_finer =0.71797, max_a_sm_err = 0.7179699, low_pass = 100, finer = 1\n",
      "Step   601, estim_aver_bat_size = 6.66, b =  1, bat_lim =  -4499, error =  5, sm_append = -0.66079, lets_finer =0.66079, max_a_sm_err = 0.7179699, low_pass = 100, finer = 1\n",
      "Step   602, estim_aver_bat_size = 6.60, b =  1, bat_lim =  -3999, error =  5, sm_append = -0.60418, lets_finer =0.60418, max_a_sm_err = 0.7179699, low_pass = 100, finer = 1\n",
      "Step   603, estim_aver_bat_size = 6.55, b =  1, bat_lim =  -3499, error =  5, sm_append = -0.54814, lets_finer =0.54814, max_a_sm_err = 0.7179699, low_pass = 100, finer = 1\n",
      "Step   604, estim_aver_bat_size = 6.49, b =  1, bat_lim =  -2999, error =  5, sm_append = -0.49266, lets_finer =0.49266, max_a_sm_err = 0.7179699, low_pass = 100, finer = 1\n",
      "Step   605, estim_aver_bat_size = 6.44, b =  1, bat_lim =  -2499, error =  5, sm_append = -0.43773, lets_finer =0.43773, max_a_sm_err = 0.7179699, low_pass = 100, finer = 1\n",
      "Step   606, estim_aver_bat_size = 6.38, b =  1, bat_lim =  -1999, error =  5, sm_append = -0.38336, lets_finer =0.38336, max_a_sm_err = 0.7179699, low_pass = 100, finer = 1\n",
      "Step   607, estim_aver_bat_size = 6.33, b =  1, bat_lim =  -1499, error =  5, sm_append = -0.32952, lets_finer =0.32952, max_a_sm_err = 0.7179699, low_pass = 100, finer = 1\n",
      "Step   608, estim_aver_bat_size = 6.28, b =  1, bat_lim =   -999, error =  5, sm_append = -0.27623, lets_finer =0.27623, max_a_sm_err = 0.7179699, low_pass = 100, finer = 1\n",
      "Step   609, estim_aver_bat_size = 6.22, b =  1, bat_lim =   -499, error =  5, sm_append = -0.22346, lets_finer =0.22346, max_a_sm_err = 0.7179699, low_pass = 100, finer = 1\n",
      "Step   610, estim_aver_bat_size = 6.17, b =  1, bat_lim =      1, error =  5, sm_append = -0.17123, lets_finer =0.17123, max_a_sm_err = 0.6607902, low_pass = 100, finer = 1\n",
      "Step   611, estim_aver_bat_size = 6.12, b =  1, bat_lim =    501, error =  5, sm_append = -0.11952, lets_finer =0.11952, max_a_sm_err = 0.6041823, low_pass = 100, finer = 1\n",
      "Step   612, estim_aver_bat_size = 6.07, b =  1, bat_lim =   1001, error =  5, sm_append = -0.06832, lets_finer =0.06832, max_a_sm_err = 0.5481405, low_pass = 100, finer = 1\n",
      "Step   613, estim_aver_bat_size = 6.02, b =  1, bat_lim =   1501, error =  5, sm_append = -0.01764, lets_finer =0.01764, max_a_sm_err = 0.4926590, low_pass = 100, finer = 1\n",
      "Step   614, estim_aver_bat_size = 5.97, b =  1, bat_lim =   2001, error =  5, sm_append = 0.03254, lets_finer =0.03254, max_a_sm_err = 0.4377325, low_pass = 100, finer = 1\n",
      "Step   615, estim_aver_bat_size = 5.92, b =  1, bat_lim =   2501, error =  5, sm_append = 0.08221, lets_finer =0.08221, max_a_sm_err = 0.3833551, low_pass = 100, finer = 1\n",
      "Step   616, estim_aver_bat_size = 5.87, b =  1, bat_lim =   3001, error =  5, sm_append = 0.13139, lets_finer =0.13139, max_a_sm_err = 0.3295216, low_pass = 100, finer = 1\n",
      "Step   617, estim_aver_bat_size = 5.82, b =  1, bat_lim =   3501, error =  5, sm_append = 0.18008, lets_finer =0.18008, max_a_sm_err = 0.2762264, low_pass = 100, finer = 1\n",
      "Step   618, estim_aver_bat_size = 5.77, b =  1, bat_lim =   4001, error =  5, sm_append = 0.22828, lets_finer =0.22828, max_a_sm_err = 0.2282754, low_pass = 100, finer = 1\n",
      "Step   619, estim_aver_bat_size = 5.72, b =  1, bat_lim =   4501, error =  5, sm_append = 0.27599, lets_finer =0.27599, max_a_sm_err = 0.2759927, low_pass = 100, finer = 1\n",
      "Step   620, estim_aver_bat_size = 5.68, b =  1, bat_lim =   5001, error =  5, sm_append = 0.32323, lets_finer =0.32323, max_a_sm_err = 0.3232328, low_pass = 100, finer = 1\n",
      "Step   621, estim_aver_bat_size = 5.63, b =  1, bat_lim =   5501, error =  5, sm_append = 0.37000, lets_finer =0.37000, max_a_sm_err = 0.3700004, low_pass = 100, finer = 1\n",
      "Step   622, estim_aver_bat_size = 5.58, b =  1, bat_lim =   6001, error =  5, sm_append = 0.41630, lets_finer =0.41630, max_a_sm_err = 0.4163004, low_pass = 100, finer = 1\n",
      "Step   623, estim_aver_bat_size = 5.54, b =  1, bat_lim =   6501, error =  5, sm_append = 0.46214, lets_finer =0.46214, max_a_sm_err = 0.4621374, low_pass = 100, finer = 1\n",
      "Step   624, estim_aver_bat_size = 5.49, b =  1, bat_lim =   7001, error =  5, sm_append = 0.50752, lets_finer =0.50752, max_a_sm_err = 0.5075161, low_pass = 100, finer = 1\n",
      "Step   625, estim_aver_bat_size = 5.45, b =  1, bat_lim =   7501, error =  5, sm_append = 0.55244, lets_finer =0.55244, max_a_sm_err = 0.5524409, low_pass = 100, finer = 1\n",
      "Step   626, estim_aver_bat_size = 5.40, b =  1, bat_lim =   8001, error =  5, sm_append = 0.59692, lets_finer =0.59692, max_a_sm_err = 0.5969165, low_pass = 100, finer = 1\n",
      "Step   627, estim_aver_bat_size = 5.36, b =  1, bat_lim =   8501, error =  5, sm_append = 0.64095, lets_finer =0.64095, max_a_sm_err = 0.6409473, low_pass = 100, finer = 1\n",
      "Step   628, estim_aver_bat_size = 5.32, b =  1, bat_lim =   9001, error =  5, sm_append = 0.68454, lets_finer =0.68454, max_a_sm_err = 0.6845378, low_pass = 100, finer = 1\n",
      "Step   629, estim_aver_bat_size = 5.27, b =  1, bat_lim =   9501, error =  5, sm_append = 0.72769, lets_finer =0.72769, max_a_sm_err = 0.7276925, low_pass = 100, finer = 1\n",
      "Step   630, estim_aver_bat_size = 5.23, b =  1, bat_lim =  10001, error =  5, sm_append = 0.77042, lets_finer =0.77042, max_a_sm_err = 0.7704155, low_pass = 100, finer = 1\n",
      "Step   631, estim_aver_bat_size = 5.20, b =  2, bat_lim =  10401, error =  4, sm_append = 0.80271, lets_finer =0.80271, max_a_sm_err = 0.8027114, low_pass = 100, finer = 1\n",
      "Step   632, estim_aver_bat_size = 5.18, b =  3, bat_lim =  10701, error =  3, sm_append = 0.82468, lets_finer =0.82468, max_a_sm_err = 0.8246843, low_pass = 100, finer = 1\n",
      "Step   633, estim_aver_bat_size = 5.34, b = 22, bat_lim =   9101, error = -16, sm_append = 0.65644, lets_finer =0.65644, max_a_sm_err = 0.8246843, low_pass = 100, finer = 1\n",
      "Step   634, estim_aver_bat_size = 5.50, b = 21, bat_lim =   7601, error = -15, sm_append = 0.49987, lets_finer =0.49987, max_a_sm_err = 0.8246843, low_pass = 100, finer = 1\n",
      "Step   635, estim_aver_bat_size = 5.68, b = 23, bat_lim =   5901, error = -17, sm_append = 0.32487, lets_finer =0.32487, max_a_sm_err = 0.8246843, low_pass = 100, finer = 1\n",
      "Step   636, estim_aver_bat_size = 5.83, b = 21, bat_lim =   4401, error = -15, sm_append = 0.17163, lets_finer =0.17163, max_a_sm_err = 0.8246843, low_pass = 100, finer = 1\n",
      "Step   637, estim_aver_bat_size = 5.97, b = 20, bat_lim =   3001, error = -14, sm_append = 0.02991, lets_finer =0.02991, max_a_sm_err = 0.8246843, low_pass = 100, finer = 1\n",
      "Step   638, estim_aver_bat_size = 6.11, b = 20, bat_lim =   1601, error = -14, sm_append = -0.11039, lets_finer =0.11039, max_a_sm_err = 0.8246843, low_pass = 100, finer = 1\n",
      "Step   639, estim_aver_bat_size = 6.26, b = 21, bat_lim =    101, error = -15, sm_append = -0.25929, lets_finer =0.25929, max_a_sm_err = 0.8246843, low_pass = 100, finer = 1\n",
      "Step   640, estim_aver_bat_size = 6.40, b = 20, bat_lim =  -1299, error = -14, sm_append = -0.39669, lets_finer =0.39669, max_a_sm_err = 0.8246843, low_pass = 100, finer = 1\n",
      "Step   641, estim_aver_bat_size = 6.48, b = 15, bat_lim =  -2199, error = -9, sm_append = -0.48273, lets_finer =0.48273, max_a_sm_err = 0.8246843, low_pass = 100, finer = 1\n",
      "Step   642, estim_aver_bat_size = 6.63, b = 21, bat_lim =  -3699, error = -15, sm_append = -0.62790, lets_finer =0.62790, max_a_sm_err = 0.6564374, low_pass = 100, finer = 1\n",
      "Step   643, estim_aver_bat_size = 6.66, b = 10, bat_lim =  -4099, error = -4, sm_append = -0.66162, lets_finer =0.66162, max_a_sm_err = 0.6616198, low_pass = 100, finer = 1\n",
      "Step   644, estim_aver_bat_size = 6.67, b =  7, bat_lim =  -4199, error = -1, sm_append = -0.66500, lets_finer =0.66500, max_a_sm_err = 0.6650036, low_pass = 100, finer = 1\n",
      "Step   645, estim_aver_bat_size = 6.74, b = 14, bat_lim =  -4999, error = -8, sm_append = -0.73835, lets_finer =0.73835, max_a_sm_err = 0.7383536, low_pass = 100, finer = 1\n",
      "Step   646, estim_aver_bat_size = 6.75, b =  8, bat_lim =  -5199, error = -2, sm_append = -0.75097, lets_finer =0.75097, max_a_sm_err = 0.7509701, low_pass = 100, finer = 1\n",
      "Step   647, estim_aver_bat_size = 6.75, b =  7, bat_lim =  -5299, error = -1, sm_append = -0.75346, lets_finer =0.75346, max_a_sm_err = 0.7534604, low_pass = 100, finer = 1\n",
      "Step   648, estim_aver_bat_size = 6.80, b = 11, bat_lim =  -5799, error = -5, sm_append = -0.79593, lets_finer =0.79593, max_a_sm_err = 0.7959258, low_pass = 100, finer = 1\n",
      "Step   649, estim_aver_bat_size = 6.79, b =  6, bat_lim =  -5799, error =  0, sm_append = -0.78797, lets_finer =0.78797, max_a_sm_err = 0.7959258, low_pass = 100, finer = 1\n",
      "Step   650, estim_aver_bat_size = 6.77, b =  5, bat_lim =  -5699, error =  1, sm_append = -0.77009, lets_finer =0.77009, max_a_sm_err = 0.7959258, low_pass = 100, finer = 1\n",
      "Step   651, estim_aver_bat_size = 6.71, b =  1, bat_lim =  -5199, error =  5, sm_append = -0.71239, lets_finer =0.71239, max_a_sm_err = 0.7959258, low_pass = 100, finer = 1\n",
      "Step   652, estim_aver_bat_size = 6.70, b =  5, bat_lim =  -5099, error =  1, sm_append = -0.69526, lets_finer =0.69526, max_a_sm_err = 0.7959258, low_pass = 100, finer = 1\n",
      "Step   653, estim_aver_bat_size = 6.64, b =  1, bat_lim =  -4599, error =  5, sm_append = -0.63831, lets_finer =0.63831, max_a_sm_err = 0.7959258, low_pass = 100, finer = 1\n",
      "Step   654, estim_aver_bat_size = 6.58, b =  1, bat_lim =  -4099, error =  5, sm_append = -0.58193, lets_finer =0.58193, max_a_sm_err = 0.7959258, low_pass = 100, finer = 1\n",
      "Step   655, estim_aver_bat_size = 6.53, b =  1, bat_lim =  -3599, error =  5, sm_append = -0.52611, lets_finer =0.52611, max_a_sm_err = 0.7959258, low_pass = 100, finer = 1\n",
      "Step   656, estim_aver_bat_size = 6.47, b =  1, bat_lim =  -3099, error =  5, sm_append = -0.47085, lets_finer =0.47085, max_a_sm_err = 0.7959258, low_pass = 100, finer = 1\n",
      "Step   657, estim_aver_bat_size = 6.42, b =  1, bat_lim =  -2599, error =  5, sm_append = -0.41614, lets_finer =0.41614, max_a_sm_err = 0.7959258, low_pass = 100, finer = 1\n",
      "Step   658, estim_aver_bat_size = 6.36, b =  1, bat_lim =  -2099, error =  5, sm_append = -0.36198, lets_finer =0.36198, max_a_sm_err = 0.7879665, low_pass = 100, finer = 1\n",
      "Step   659, estim_aver_bat_size = 6.31, b =  1, bat_lim =  -1599, error =  5, sm_append = -0.30836, lets_finer =0.30836, max_a_sm_err = 0.7700868, low_pass = 100, finer = 1\n",
      "Step   660, estim_aver_bat_size = 6.26, b =  1, bat_lim =  -1099, error =  5, sm_append = -0.25527, lets_finer =0.25527, max_a_sm_err = 0.7123860, low_pass = 100, finer = 1\n",
      "Step   661, estim_aver_bat_size = 6.20, b =  1, bat_lim =   -599, error =  5, sm_append = -0.20272, lets_finer =0.20272, max_a_sm_err = 0.6952621, low_pass = 100, finer = 1\n",
      "Step   662, estim_aver_bat_size = 6.15, b =  1, bat_lim =    -99, error =  5, sm_append = -0.15069, lets_finer =0.15069, max_a_sm_err = 0.6383095, low_pass = 100, finer = 1\n",
      "Step   663, estim_aver_bat_size = 6.10, b =  1, bat_lim =    401, error =  5, sm_append = -0.09919, lets_finer =0.09919, max_a_sm_err = 0.5819264, low_pass = 100, finer = 1\n",
      "Step   664, estim_aver_bat_size = 6.05, b =  1, bat_lim =    901, error =  5, sm_append = -0.04819, lets_finer =0.04819, max_a_sm_err = 0.5261071, low_pass = 100, finer = 1\n",
      "Step   665, estim_aver_bat_size = 6.00, b =  1, bat_lim =   1401, error =  5, sm_append = 0.00229, lets_finer =0.00229, max_a_sm_err = 0.4708461, low_pass = 100, finer = 1\n",
      "Step   666, estim_aver_bat_size = 5.95, b =  1, bat_lim =   1901, error =  5, sm_append = 0.05226, lets_finer =0.05226, max_a_sm_err = 0.4161376, low_pass = 100, finer = 1\n",
      "Step   667, estim_aver_bat_size = 5.90, b =  1, bat_lim =   2401, error =  5, sm_append = 0.10174, lets_finer =0.10174, max_a_sm_err = 0.3619762, low_pass = 100, finer = 1\n",
      "Step   668, estim_aver_bat_size = 5.85, b =  1, bat_lim =   2901, error =  5, sm_append = 0.15072, lets_finer =0.15072, max_a_sm_err = 0.3083565, low_pass = 100, finer = 1\n",
      "Step   669, estim_aver_bat_size = 5.80, b =  1, bat_lim =   3401, error =  5, sm_append = 0.19922, lets_finer =0.19922, max_a_sm_err = 0.2552729, low_pass = 100, finer = 1\n",
      "Step   670, estim_aver_bat_size = 5.75, b =  1, bat_lim =   3901, error =  5, sm_append = 0.24723, lets_finer =0.24723, max_a_sm_err = 0.2472254, low_pass = 100, finer = 1\n",
      "Step   671, estim_aver_bat_size = 5.71, b =  1, bat_lim =   4401, error =  5, sm_append = 0.29475, lets_finer =0.29475, max_a_sm_err = 0.2947531, low_pass = 100, finer = 1\n",
      "Step   672, estim_aver_bat_size = 5.66, b =  1, bat_lim =   4901, error =  5, sm_append = 0.34181, lets_finer =0.34181, max_a_sm_err = 0.3418056, low_pass = 100, finer = 1\n",
      "Step   673, estim_aver_bat_size = 5.61, b =  1, bat_lim =   5401, error =  5, sm_append = 0.38839, lets_finer =0.38839, max_a_sm_err = 0.3883876, low_pass = 100, finer = 1\n",
      "Step   674, estim_aver_bat_size = 5.57, b =  1, bat_lim =   5901, error =  5, sm_append = 0.43450, lets_finer =0.43450, max_a_sm_err = 0.4345037, low_pass = 100, finer = 1\n",
      "Step   675, estim_aver_bat_size = 5.52, b =  1, bat_lim =   6401, error =  5, sm_append = 0.48016, lets_finer =0.48016, max_a_sm_err = 0.4801586, low_pass = 100, finer = 1\n",
      "Step   676, estim_aver_bat_size = 5.47, b =  1, bat_lim =   6901, error =  5, sm_append = 0.52536, lets_finer =0.52536, max_a_sm_err = 0.5253571, low_pass = 100, finer = 1\n",
      "Step   677, estim_aver_bat_size = 5.43, b =  1, bat_lim =   7401, error =  5, sm_append = 0.57010, lets_finer =0.57010, max_a_sm_err = 0.5701035, low_pass = 100, finer = 1\n",
      "Step   678, estim_aver_bat_size = 5.41, b =  3, bat_lim =   7701, error =  3, sm_append = 0.59440, lets_finer =0.59440, max_a_sm_err = 0.5944025, low_pass = 100, finer = 1\n",
      "Step   679, estim_aver_bat_size = 5.38, b =  3, bat_lim =   8001, error =  3, sm_append = 0.61846, lets_finer =0.61846, max_a_sm_err = 0.6184584, low_pass = 100, finer = 1\n",
      "Step   680, estim_aver_bat_size = 5.37, b =  4, bat_lim =   8201, error =  2, sm_append = 0.63227, lets_finer =0.63227, max_a_sm_err = 0.6322738, low_pass = 100, finer = 1\n",
      "Step   681, estim_aver_bat_size = 5.33, b =  2, bat_lim =   8601, error =  4, sm_append = 0.66595, lets_finer =0.66595, max_a_sm_err = 0.6659511, low_pass = 100, finer = 1\n",
      "Step   682, estim_aver_bat_size = 5.31, b =  3, bat_lim =   8901, error =  3, sm_append = 0.68929, lets_finer =0.68929, max_a_sm_err = 0.6892916, low_pass = 100, finer = 1\n",
      "Step   683, estim_aver_bat_size = 5.28, b =  2, bat_lim =   9301, error =  4, sm_append = 0.72240, lets_finer =0.72240, max_a_sm_err = 0.7223987, low_pass = 100, finer = 1\n",
      "Step   684, estim_aver_bat_size = 5.26, b =  4, bat_lim =   9501, error =  2, sm_append = 0.73517, lets_finer =0.73517, max_a_sm_err = 0.7351747, low_pass = 100, finer = 1\n",
      "Step   685, estim_aver_bat_size = 5.24, b =  3, bat_lim =   9801, error =  3, sm_append = 0.75782, lets_finer =0.75782, max_a_sm_err = 0.7578229, low_pass = 100, finer = 1\n",
      "Step   686, estim_aver_bat_size = 5.28, b =  9, bat_lim =   9501, error = -3, sm_append = 0.72024, lets_finer =0.72024, max_a_sm_err = 0.7578229, low_pass = 100, finer = 1\n",
      "Step   687, estim_aver_bat_size = 5.32, b =  9, bat_lim =   9201, error = -3, sm_append = 0.68304, lets_finer =0.68304, max_a_sm_err = 0.7578229, low_pass = 100, finer = 1\n",
      "Step   688, estim_aver_bat_size = 5.35, b =  9, bat_lim =   8901, error = -3, sm_append = 0.64621, lets_finer =0.64621, max_a_sm_err = 0.7578229, low_pass = 100, finer = 1\n",
      "Step   689, estim_aver_bat_size = 5.34, b =  4, bat_lim =   9101, error =  2, sm_append = 0.65975, lets_finer =0.65975, max_a_sm_err = 0.7578229, low_pass = 100, finer = 1\n",
      "Step   690, estim_aver_bat_size = 5.36, b =  7, bat_lim =   9001, error = -1, sm_append = 0.64315, lets_finer =0.64315, max_a_sm_err = 0.7578229, low_pass = 100, finer = 1\n",
      "Step   691, estim_aver_bat_size = 5.45, b = 15, bat_lim =   8101, error = -9, sm_append = 0.54672, lets_finer =0.54672, max_a_sm_err = 0.7578229, low_pass = 100, finer = 1\n",
      "Step   692, estim_aver_bat_size = 5.53, b = 13, bat_lim =   7401, error = -7, sm_append = 0.47125, lets_finer =0.47125, max_a_sm_err = 0.7578229, low_pass = 100, finer = 1\n",
      "Step   693, estim_aver_bat_size = 5.60, b = 13, bat_lim =   6701, error = -7, sm_append = 0.39654, lets_finer =0.39654, max_a_sm_err = 0.7578229, low_pass = 100, finer = 1\n",
      "Step   694, estim_aver_bat_size = 5.66, b = 11, bat_lim =   6201, error = -5, sm_append = 0.34258, lets_finer =0.34258, max_a_sm_err = 0.7578229, low_pass = 100, finer = 1\n",
      "Step   695, estim_aver_bat_size = 5.74, b = 14, bat_lim =   5401, error = -8, sm_append = 0.25915, lets_finer =0.25915, max_a_sm_err = 0.7202447, low_pass = 100, finer = 1\n",
      "Step   696, estim_aver_bat_size = 5.81, b = 13, bat_lim =   4701, error = -7, sm_append = 0.18656, lets_finer =0.18656, max_a_sm_err = 0.6830423, low_pass = 100, finer = 1\n",
      "Step   697, estim_aver_bat_size = 5.88, b = 12, bat_lim =   4101, error = -6, sm_append = 0.12469, lets_finer =0.12469, max_a_sm_err = 0.6597497, low_pass = 100, finer = 1\n",
      "Step   698, estim_aver_bat_size = 6.02, b = 20, bat_lim =   2701, error = -14, sm_append = -0.01655, lets_finer =0.01655, max_a_sm_err = 0.6597497, low_pass = 100, finer = 1\n",
      "Step   699, estim_aver_bat_size = 6.15, b = 19, bat_lim =   1401, error = -13, sm_append = -0.14639, lets_finer =0.14639, max_a_sm_err = 0.6431522, low_pass = 100, finer = 1\n",
      "Step   700, estim_aver_bat_size = 6.27, b = 19, bat_lim =    101, error = -13, sm_append = -0.27492, lets_finer =0.27492, max_a_sm_err = 0.5467207, low_pass = 100, finer = 1\n",
      "Step   701, estim_aver_bat_size = 6.22, b =  1, bat_lim =    601, error =  5, sm_append = -0.22218, lets_finer =0.22218, max_a_sm_err = 0.4712535, low_pass = 100, finer = 1\n",
      "Step   702, estim_aver_bat_size = 6.17, b =  1, bat_lim =   1101, error =  5, sm_append = -0.16995, lets_finer =0.16995, max_a_sm_err = 0.3965410, low_pass = 100, finer = 1\n",
      "Step   703, estim_aver_bat_size = 6.12, b =  1, bat_lim =   1601, error =  5, sm_append = -0.11825, lets_finer =0.11825, max_a_sm_err = 0.3425756, low_pass = 100, finer = 1\n",
      "Step   704, estim_aver_bat_size = 6.07, b =  1, bat_lim =   2101, error =  5, sm_append = -0.06707, lets_finer =0.06707, max_a_sm_err = 0.2749248, low_pass = 100, finer = 1\n",
      "Step   705, estim_aver_bat_size = 6.02, b =  1, bat_lim =   2601, error =  5, sm_append = -0.01640, lets_finer =0.01640, max_a_sm_err = 0.2749248, low_pass = 100, finer = 1\n",
      "Step   706, estim_aver_bat_size = 5.97, b =  1, bat_lim =   3101, error =  5, sm_append = 0.03376, lets_finer =0.03376, max_a_sm_err = 0.2749248, low_pass = 100, finer = 1\n",
      "Step   707, estim_aver_bat_size = 5.92, b =  1, bat_lim =   3601, error =  5, sm_append = 0.08343, lets_finer =0.08343, max_a_sm_err = 0.2749248, low_pass = 100, finer = 1\n",
      "Step   708, estim_aver_bat_size = 5.87, b =  1, bat_lim =   4101, error =  5, sm_append = 0.13259, lets_finer =0.13259, max_a_sm_err = 0.2749248, low_pass = 100, finer = 1\n",
      "Step   709, estim_aver_bat_size = 5.82, b =  1, bat_lim =   4601, error =  5, sm_append = 0.18127, lets_finer =0.18127, max_a_sm_err = 0.2749248, low_pass = 100, finer = 1\n",
      "Step   710, estim_aver_bat_size = 5.77, b =  1, bat_lim =   5101, error =  5, sm_append = 0.22945, lets_finer =0.22945, max_a_sm_err = 0.2294526, low_pass = 100, finer = 1\n",
      "Step   711, estim_aver_bat_size = 5.72, b =  1, bat_lim =   5601, error =  5, sm_append = 0.27716, lets_finer =0.27716, max_a_sm_err = 0.2771581, low_pass = 100, finer = 1\n",
      "Step   712, estim_aver_bat_size = 5.68, b =  1, bat_lim =   6101, error =  5, sm_append = 0.32439, lets_finer =0.32439, max_a_sm_err = 0.3243865, low_pass = 100, finer = 1\n",
      "Step   713, estim_aver_bat_size = 5.63, b =  1, bat_lim =   6601, error =  5, sm_append = 0.37114, lets_finer =0.37114, max_a_sm_err = 0.3711426, low_pass = 100, finer = 1\n",
      "Step   714, estim_aver_bat_size = 5.58, b =  1, bat_lim =   7101, error =  5, sm_append = 0.41743, lets_finer =0.41743, max_a_sm_err = 0.4174312, low_pass = 100, finer = 1\n",
      "Step   715, estim_aver_bat_size = 5.55, b =  2, bat_lim =   7501, error =  4, sm_append = 0.45326, lets_finer =0.45326, max_a_sm_err = 0.4532569, low_pass = 100, finer = 1\n",
      "Step   716, estim_aver_bat_size = 5.50, b =  1, bat_lim =   8001, error =  5, sm_append = 0.49872, lets_finer =0.49872, max_a_sm_err = 0.4987243, low_pass = 100, finer = 1\n",
      "Step   717, estim_aver_bat_size = 5.46, b =  1, bat_lim =   8501, error =  5, sm_append = 0.54374, lets_finer =0.54374, max_a_sm_err = 0.5437371, low_pass = 100, finer = 1\n",
      "Step   718, estim_aver_bat_size = 5.41, b =  1, bat_lim =   9001, error =  5, sm_append = 0.58830, lets_finer =0.58830, max_a_sm_err = 0.5882997, low_pass = 100, finer = 1\n",
      "Step   719, estim_aver_bat_size = 5.37, b =  1, bat_lim =   9501, error =  5, sm_append = 0.63242, lets_finer =0.63242, max_a_sm_err = 0.6324167, low_pass = 100, finer = 1\n",
      "Step   720, estim_aver_bat_size = 5.32, b =  1, bat_lim =  10001, error =  5, sm_append = 0.67609, lets_finer =0.67609, max_a_sm_err = 0.6760925, low_pass = 100, finer = 1\n",
      "Step   721, estim_aver_bat_size = 5.46, b = 19, bat_lim =   8701, error = -13, sm_append = 0.53933, lets_finer =0.53933, max_a_sm_err = 0.6760925, low_pass = 100, finer = 1\n",
      "Step   722, estim_aver_bat_size = 5.57, b = 16, bat_lim =   7701, error = -10, sm_append = 0.43394, lets_finer =0.43394, max_a_sm_err = 0.6760925, low_pass = 100, finer = 1\n",
      "Step   723, estim_aver_bat_size = 5.68, b = 17, bat_lim =   6601, error = -11, sm_append = 0.31960, lets_finer =0.31960, max_a_sm_err = 0.6760925, low_pass = 100, finer = 1\n",
      "Step   724, estim_aver_bat_size = 5.82, b = 20, bat_lim =   5201, error = -14, sm_append = 0.17640, lets_finer =0.17640, max_a_sm_err = 0.6760925, low_pass = 100, finer = 1\n",
      "Step   725, estim_aver_bat_size = 6.00, b = 23, bat_lim =   3501, error = -17, sm_append = 0.00464, lets_finer =0.00464, max_a_sm_err = 0.6760925, low_pass = 100, finer = 1\n",
      "Step   726, estim_aver_bat_size = 6.12, b = 18, bat_lim =   2301, error = -12, sm_append = -0.11541, lets_finer =0.11541, max_a_sm_err = 0.6760925, low_pass = 100, finer = 1\n",
      "Step   727, estim_aver_bat_size = 6.25, b = 20, bat_lim =    901, error = -14, sm_append = -0.25425, lets_finer =0.25425, max_a_sm_err = 0.6760925, low_pass = 100, finer = 1\n",
      "Step   728, estim_aver_bat_size = 6.39, b = 20, bat_lim =   -499, error = -14, sm_append = -0.39171, lets_finer =0.39171, max_a_sm_err = 0.6760925, low_pass = 100, finer = 1\n",
      "Step   729, estim_aver_bat_size = 6.50, b = 17, bat_lim =  -1599, error = -11, sm_append = -0.49779, lets_finer =0.49779, max_a_sm_err = 0.6760925, low_pass = 100, finer = 1\n",
      "Step   730, estim_aver_bat_size = 6.61, b = 18, bat_lim =  -2799, error = -12, sm_append = -0.61282, lets_finer =0.61282, max_a_sm_err = 0.6128158, low_pass = 100, finer = 1\n",
      "Step   731, estim_aver_bat_size = 6.69, b = 14, bat_lim =  -3599, error = -8, sm_append = -0.68669, lets_finer =0.68669, max_a_sm_err = 0.6866877, low_pass = 100, finer = 1\n",
      "Step   732, estim_aver_bat_size = 6.72, b = 10, bat_lim =  -3999, error = -4, sm_append = -0.71982, lets_finer =0.71982, max_a_sm_err = 0.7198208, low_pass = 100, finer = 1\n",
      "Step   733, estim_aver_bat_size = 6.75, b = 10, bat_lim =  -4399, error = -4, sm_append = -0.75262, lets_finer =0.75262, max_a_sm_err = 0.7526226, low_pass = 100, finer = 1\n",
      "Step   734, estim_aver_bat_size = 6.84, b = 15, bat_lim =  -5299, error = -9, sm_append = -0.83510, lets_finer =0.83510, max_a_sm_err = 0.8350964, low_pass = 100, finer = 1\n",
      "Step   735, estim_aver_bat_size = 6.96, b = 19, bat_lim =  -6599, error = -13, sm_append = -0.95675, lets_finer =0.95675, max_a_sm_err = 0.9567454, low_pass = 100, finer = 1\n",
      "Step   736, estim_aver_bat_size = 6.99, b = 10, bat_lim =  -6999, error = -4, sm_append = -0.98718, lets_finer =0.98718, max_a_sm_err = 0.9871780, low_pass = 100, finer = 1\n",
      "Step   737, estim_aver_bat_size = 7.06, b = 14, bat_lim =  -7799, error = -8, sm_append = -1.05731, lets_finer =1.05731, max_a_sm_err = 1.0573062, low_pass = 100, finer = 1\n",
      "Step   738, estim_aver_bat_size = 7.12, b = 13, bat_lim =  -8499, error = -7, sm_append = -1.11673, lets_finer =1.11673, max_a_sm_err = 1.1167331, low_pass = 100, finer = 1\n",
      "Step   739, estim_aver_bat_size = 7.13, b =  8, bat_lim =  -8699, error = -2, sm_append = -1.12557, lets_finer =1.12557, max_a_sm_err = 1.1255658, low_pass = 100, finer = 1\n",
      "Step   740, estim_aver_bat_size = 7.18, b = 13, bat_lim =  -9399, error = -7, sm_append = -1.18431, lets_finer =1.18431, max_a_sm_err = 1.1843101, low_pass = 100, finer = 1\n",
      "Step   741, estim_aver_bat_size = 7.12, b =  1, bat_lim =  -8899, error =  5, sm_append = -1.12247, lets_finer =1.12247, max_a_sm_err = 1.1843101, low_pass = 100, finer = 1\n",
      "Step   742, estim_aver_bat_size = 7.06, b =  1, bat_lim =  -8399, error =  5, sm_append = -1.06124, lets_finer =1.06124, max_a_sm_err = 1.1843101, low_pass = 100, finer = 1\n",
      "Step   743, estim_aver_bat_size = 7.00, b =  1, bat_lim =  -7899, error =  5, sm_append = -1.00063, lets_finer =1.00063, max_a_sm_err = 1.1843101, low_pass = 100, finer = 1\n",
      "Step   744, estim_aver_bat_size = 6.94, b =  1, bat_lim =  -7399, error =  5, sm_append = -0.94062, lets_finer =0.94062, max_a_sm_err = 1.1843101, low_pass = 100, finer = 1\n",
      "Step   745, estim_aver_bat_size = 6.88, b =  1, bat_lim =  -6899, error =  5, sm_append = -0.88122, lets_finer =0.88122, max_a_sm_err = 1.1843101, low_pass = 100, finer = 1\n",
      "Step   746, estim_aver_bat_size = 6.82, b =  1, bat_lim =  -6399, error =  5, sm_append = -0.82241, lets_finer =0.82241, max_a_sm_err = 1.1843101, low_pass = 100, finer = 1\n",
      "Step   747, estim_aver_bat_size = 6.76, b =  1, bat_lim =  -5899, error =  5, sm_append = -0.76418, lets_finer =0.76418, max_a_sm_err = 1.1843101, low_pass = 100, finer = 1\n",
      "Step   748, estim_aver_bat_size = 6.71, b =  1, bat_lim =  -5399, error =  5, sm_append = -0.70654, lets_finer =0.70654, max_a_sm_err = 1.1843101, low_pass = 100, finer = 1\n",
      "Step   749, estim_aver_bat_size = 6.65, b =  1, bat_lim =  -4899, error =  5, sm_append = -0.64947, lets_finer =0.64947, max_a_sm_err = 1.1843101, low_pass = 100, finer = 1\n",
      "Step   750, estim_aver_bat_size = 6.59, b =  1, bat_lim =  -4399, error =  5, sm_append = -0.59298, lets_finer =0.59298, max_a_sm_err = 1.1224670, low_pass = 100, finer = 1\n",
      "Step   751, estim_aver_bat_size = 6.54, b =  1, bat_lim =  -3899, error =  5, sm_append = -0.53705, lets_finer =0.53705, max_a_sm_err = 1.0612424, low_pass = 100, finer = 1\n",
      "Step   752, estim_aver_bat_size = 6.48, b =  1, bat_lim =  -3399, error =  5, sm_append = -0.48168, lets_finer =0.48168, max_a_sm_err = 1.0006299, low_pass = 100, finer = 1\n",
      "Step   753, estim_aver_bat_size = 6.43, b =  1, bat_lim =  -2899, error =  5, sm_append = -0.42686, lets_finer =0.42686, max_a_sm_err = 0.9406236, low_pass = 100, finer = 1\n",
      "Step   754, estim_aver_bat_size = 6.37, b =  1, bat_lim =  -2399, error =  5, sm_append = -0.37259, lets_finer =0.37259, max_a_sm_err = 0.8812174, low_pass = 100, finer = 1\n",
      "Step   755, estim_aver_bat_size = 6.32, b =  1, bat_lim =  -1899, error =  5, sm_append = -0.31887, lets_finer =0.31887, max_a_sm_err = 0.8224052, low_pass = 100, finer = 1\n",
      "Step   756, estim_aver_bat_size = 6.27, b =  1, bat_lim =  -1399, error =  5, sm_append = -0.26568, lets_finer =0.26568, max_a_sm_err = 0.7641812, low_pass = 100, finer = 1\n",
      "Step   757, estim_aver_bat_size = 6.21, b =  1, bat_lim =   -899, error =  5, sm_append = -0.21302, lets_finer =0.21302, max_a_sm_err = 0.7065394, low_pass = 100, finer = 1\n",
      "Step   758, estim_aver_bat_size = 6.16, b =  1, bat_lim =   -399, error =  5, sm_append = -0.16089, lets_finer =0.16089, max_a_sm_err = 0.6494740, low_pass = 100, finer = 1\n",
      "Step   759, estim_aver_bat_size = 6.11, b =  1, bat_lim =    101, error =  5, sm_append = -0.10928, lets_finer =0.10928, max_a_sm_err = 0.5929792, low_pass = 100, finer = 1\n",
      "Step   760, estim_aver_bat_size = 6.06, b =  1, bat_lim =    601, error =  5, sm_append = -0.05819, lets_finer =0.05819, max_a_sm_err = 0.5370494, low_pass = 100, finer = 1\n",
      "Step   761, estim_aver_bat_size = 6.01, b =  1, bat_lim =   1101, error =  5, sm_append = -0.00761, lets_finer =0.00761, max_a_sm_err = 0.4816789, low_pass = 100, finer = 1\n",
      "Step   762, estim_aver_bat_size = 5.96, b =  1, bat_lim =   1601, error =  5, sm_append = 0.04247, lets_finer =0.04247, max_a_sm_err = 0.4268622, low_pass = 100, finer = 1\n",
      "Step   763, estim_aver_bat_size = 5.91, b =  1, bat_lim =   2101, error =  5, sm_append = 0.09204, lets_finer =0.09204, max_a_sm_err = 0.3725935, low_pass = 100, finer = 1\n",
      "Step   764, estim_aver_bat_size = 5.86, b =  1, bat_lim =   2601, error =  5, sm_append = 0.14112, lets_finer =0.14112, max_a_sm_err = 0.3188676, low_pass = 100, finer = 1\n",
      "Step   765, estim_aver_bat_size = 5.81, b =  1, bat_lim =   3101, error =  5, sm_append = 0.18971, lets_finer =0.18971, max_a_sm_err = 0.2656789, low_pass = 100, finer = 1\n",
      "Step   766, estim_aver_bat_size = 5.76, b =  1, bat_lim =   3601, error =  5, sm_append = 0.23781, lets_finer =0.23781, max_a_sm_err = 0.2378144, low_pass = 100, finer = 1\n",
      "Step   767, estim_aver_bat_size = 5.71, b =  1, bat_lim =   4101, error =  5, sm_append = 0.28544, lets_finer =0.28544, max_a_sm_err = 0.2854362, low_pass = 100, finer = 1\n",
      "Step   768, estim_aver_bat_size = 5.67, b =  1, bat_lim =   4601, error =  5, sm_append = 0.33258, lets_finer =0.33258, max_a_sm_err = 0.3325819, low_pass = 100, finer = 1\n",
      "Step   769, estim_aver_bat_size = 5.62, b =  1, bat_lim =   5101, error =  5, sm_append = 0.37926, lets_finer =0.37926, max_a_sm_err = 0.3792560, low_pass = 100, finer = 1\n",
      "Step   770, estim_aver_bat_size = 5.57, b =  1, bat_lim =   5601, error =  5, sm_append = 0.42546, lets_finer =0.42546, max_a_sm_err = 0.4254635, low_pass = 100, finer = 1\n",
      "Step   771, estim_aver_bat_size = 5.53, b =  1, bat_lim =   6101, error =  5, sm_append = 0.47121, lets_finer =0.47121, max_a_sm_err = 0.4712089, low_pass = 100, finer = 1\n",
      "Step   772, estim_aver_bat_size = 5.48, b =  1, bat_lim =   6601, error =  5, sm_append = 0.51650, lets_finer =0.51650, max_a_sm_err = 0.5164968, low_pass = 100, finer = 1\n",
      "Step   773, estim_aver_bat_size = 5.44, b =  1, bat_lim =   7101, error =  5, sm_append = 0.56133, lets_finer =0.56133, max_a_sm_err = 0.5613318, low_pass = 100, finer = 1\n",
      "Step   774, estim_aver_bat_size = 5.39, b =  1, bat_lim =   7601, error =  5, sm_append = 0.60572, lets_finer =0.60572, max_a_sm_err = 0.6057185, low_pass = 100, finer = 1\n",
      "Step   775, estim_aver_bat_size = 5.35, b =  1, bat_lim =   8101, error =  5, sm_append = 0.64966, lets_finer =0.64966, max_a_sm_err = 0.6496613, low_pass = 100, finer = 1\n",
      "Step   776, estim_aver_bat_size = 5.31, b =  1, bat_lim =   8601, error =  5, sm_append = 0.69316, lets_finer =0.69316, max_a_sm_err = 0.6931647, low_pass = 100, finer = 1\n",
      "Step   777, estim_aver_bat_size = 5.26, b =  1, bat_lim =   9101, error =  5, sm_append = 0.73623, lets_finer =0.73623, max_a_sm_err = 0.7362330, low_pass = 100, finer = 1\n",
      "Step   778, estim_aver_bat_size = 5.22, b =  1, bat_lim =   9601, error =  5, sm_append = 0.77887, lets_finer =0.77887, max_a_sm_err = 0.7788707, low_pass = 100, finer = 1\n",
      "Step   779, estim_aver_bat_size = 5.19, b =  2, bat_lim =  10001, error =  4, sm_append = 0.81108, lets_finer =0.81108, max_a_sm_err = 0.8110820, low_pass = 100, finer = 1\n",
      "Step   780, estim_aver_bat_size = 5.16, b =  2, bat_lim =  10401, error =  4, sm_append = 0.84297, lets_finer =0.84297, max_a_sm_err = 0.8429712, low_pass = 100, finer = 1\n",
      "Step   781, estim_aver_bat_size = 5.32, b = 21, bat_lim =   8901, error = -15, sm_append = 0.68454, lets_finer =0.68454, max_a_sm_err = 0.8429712, low_pass = 100, finer = 1\n",
      "Step   782, estim_aver_bat_size = 5.46, b = 20, bat_lim =   7501, error = -14, sm_append = 0.53770, lets_finer =0.53770, max_a_sm_err = 0.8429712, low_pass = 100, finer = 1\n",
      "Step   783, estim_aver_bat_size = 5.65, b = 24, bat_lim =   5701, error = -18, sm_append = 0.35232, lets_finer =0.35232, max_a_sm_err = 0.8429712, low_pass = 100, finer = 1\n",
      "Step   784, estim_aver_bat_size = 5.78, b = 19, bat_lim =   4401, error = -13, sm_append = 0.21880, lets_finer =0.21880, max_a_sm_err = 0.8429712, low_pass = 100, finer = 1\n",
      "Step   785, estim_aver_bat_size = 5.92, b = 20, bat_lim =   3001, error = -14, sm_append = 0.07661, lets_finer =0.07661, max_a_sm_err = 0.8429712, low_pass = 100, finer = 1\n",
      "Step   786, estim_aver_bat_size = 6.10, b = 24, bat_lim =   1201, error = -18, sm_append = -0.10416, lets_finer =0.10416, max_a_sm_err = 0.8429712, low_pass = 100, finer = 1\n",
      "Step   787, estim_aver_bat_size = 6.21, b = 17, bat_lim =    101, error = -11, sm_append = -0.21312, lets_finer =0.21312, max_a_sm_err = 0.8429712, low_pass = 100, finer = 1\n",
      "Step   788, estim_aver_bat_size = 6.35, b = 20, bat_lim =  -1299, error = -14, sm_append = -0.35099, lets_finer =0.35099, max_a_sm_err = 0.8429712, low_pass = 100, finer = 1\n",
      "Step   789, estim_aver_bat_size = 6.51, b = 22, bat_lim =  -2899, error = -16, sm_append = -0.50748, lets_finer =0.50748, max_a_sm_err = 0.8429712, low_pass = 100, finer = 1\n",
      "Step   790, estim_aver_bat_size = 6.64, b = 20, bat_lim =  -4299, error = -14, sm_append = -0.64240, lets_finer =0.64240, max_a_sm_err = 0.6845415, low_pass = 100, finer = 1\n",
      "Step   791, estim_aver_bat_size = 6.66, b =  8, bat_lim =  -4499, error = -2, sm_append = -0.65598, lets_finer =0.65598, max_a_sm_err = 0.6559768, low_pass = 100, finer = 1\n",
      "Step   792, estim_aver_bat_size = 6.69, b = 10, bat_lim =  -4899, error = -4, sm_append = -0.68942, lets_finer =0.68942, max_a_sm_err = 0.6894170, low_pass = 100, finer = 1\n",
      "Step   793, estim_aver_bat_size = 6.75, b = 13, bat_lim =  -5599, error = -7, sm_append = -0.75252, lets_finer =0.75252, max_a_sm_err = 0.7525228, low_pass = 100, finer = 1\n",
      "Step   794, estim_aver_bat_size = 6.78, b = 10, bat_lim =  -5999, error = -4, sm_append = -0.78500, lets_finer =0.78500, max_a_sm_err = 0.7849976, low_pass = 100, finer = 1\n",
      "Step   795, estim_aver_bat_size = 6.90, b = 18, bat_lim =  -7199, error = -12, sm_append = -0.89715, lets_finer =0.89715, max_a_sm_err = 0.8971476, low_pass = 100, finer = 1\n",
      "Step   796, estim_aver_bat_size = 6.96, b = 13, bat_lim =  -7899, error = -7, sm_append = -0.95818, lets_finer =0.95818, max_a_sm_err = 0.9581762, low_pass = 100, finer = 1\n",
      "Step   797, estim_aver_bat_size = 6.93, b =  4, bat_lim =  -7699, error =  2, sm_append = -0.92859, lets_finer =0.92859, max_a_sm_err = 0.9581762, low_pass = 100, finer = 1\n",
      "Step   798, estim_aver_bat_size = 6.94, b =  8, bat_lim =  -7899, error = -2, sm_append = -0.93931, lets_finer =0.93931, max_a_sm_err = 0.9581762, low_pass = 100, finer = 1\n",
      "Step   799, estim_aver_bat_size = 6.94, b =  7, bat_lim =  -7999, error = -1, sm_append = -0.93992, lets_finer =0.93992, max_a_sm_err = 0.9581762, low_pass = 100, finer = 1\n",
      "Step   800, estim_aver_bat_size = 6.92, b =  5, bat_lim =  -7899, error =  1, sm_append = -0.92052, lets_finer =0.92052, max_a_sm_err = 0.9581762, low_pass = 100, finer = 1\n",
      "Step   801, estim_aver_bat_size = 6.86, b =  1, bat_lim =  -7399, error =  5, sm_append = -0.86131, lets_finer =0.86131, max_a_sm_err = 0.9581762, low_pass = 100, finer = 1\n",
      "Step   802, estim_aver_bat_size = 6.80, b =  1, bat_lim =  -6899, error =  5, sm_append = -0.80270, lets_finer =0.80270, max_a_sm_err = 0.9581762, low_pass = 100, finer = 1\n",
      "Step   803, estim_aver_bat_size = 6.74, b =  1, bat_lim =  -6399, error =  5, sm_append = -0.74467, lets_finer =0.74467, max_a_sm_err = 0.9581762, low_pass = 100, finer = 1\n",
      "Step   804, estim_aver_bat_size = 6.69, b =  1, bat_lim =  -5899, error =  5, sm_append = -0.68722, lets_finer =0.68722, max_a_sm_err = 0.9581762, low_pass = 100, finer = 1\n",
      "Step   805, estim_aver_bat_size = 6.63, b =  1, bat_lim =  -5399, error =  5, sm_append = -0.63035, lets_finer =0.63035, max_a_sm_err = 0.9581762, low_pass = 100, finer = 1\n",
      "Step   806, estim_aver_bat_size = 6.57, b =  1, bat_lim =  -4899, error =  5, sm_append = -0.57405, lets_finer =0.57405, max_a_sm_err = 0.9399154, low_pass = 100, finer = 1\n",
      "Step   807, estim_aver_bat_size = 6.52, b =  1, bat_lim =  -4399, error =  5, sm_append = -0.51831, lets_finer =0.51831, max_a_sm_err = 0.9399154, low_pass = 100, finer = 1\n",
      "Step   808, estim_aver_bat_size = 6.46, b =  1, bat_lim =  -3899, error =  5, sm_append = -0.46312, lets_finer =0.46312, max_a_sm_err = 0.9399154, low_pass = 100, finer = 1\n",
      "Step   809, estim_aver_bat_size = 6.41, b =  1, bat_lim =  -3399, error =  5, sm_append = -0.40849, lets_finer =0.40849, max_a_sm_err = 0.9205162, low_pass = 100, finer = 1\n",
      "Step   810, estim_aver_bat_size = 6.35, b =  1, bat_lim =  -2899, error =  5, sm_append = -0.35441, lets_finer =0.35441, max_a_sm_err = 0.8613111, low_pass = 100, finer = 1\n",
      "Step   811, estim_aver_bat_size = 6.30, b =  1, bat_lim =  -2399, error =  5, sm_append = -0.30086, lets_finer =0.30086, max_a_sm_err = 0.8026979, low_pass = 100, finer = 1\n",
      "Step   812, estim_aver_bat_size = 6.25, b =  1, bat_lim =  -1899, error =  5, sm_append = -0.24786, lets_finer =0.24786, max_a_sm_err = 0.7446710, low_pass = 100, finer = 1\n",
      "Step   813, estim_aver_bat_size = 6.20, b =  1, bat_lim =  -1399, error =  5, sm_append = -0.19538, lets_finer =0.19538, max_a_sm_err = 0.6872243, low_pass = 100, finer = 1\n",
      "Step   814, estim_aver_bat_size = 6.14, b =  1, bat_lim =   -899, error =  5, sm_append = -0.14342, lets_finer =0.14342, max_a_sm_err = 0.6303520, low_pass = 100, finer = 1\n",
      "Step   815, estim_aver_bat_size = 6.09, b =  1, bat_lim =   -399, error =  5, sm_append = -0.09199, lets_finer =0.09199, max_a_sm_err = 0.5740485, low_pass = 100, finer = 1\n",
      "Step   816, estim_aver_bat_size = 6.04, b =  1, bat_lim =    101, error =  5, sm_append = -0.04107, lets_finer =0.04107, max_a_sm_err = 0.5183080, low_pass = 100, finer = 1\n",
      "Step   817, estim_aver_bat_size = 5.99, b =  1, bat_lim =    601, error =  5, sm_append = 0.00934, lets_finer =0.00934, max_a_sm_err = 0.4631249, low_pass = 100, finer = 1\n",
      "Step   818, estim_aver_bat_size = 5.94, b =  1, bat_lim =   1101, error =  5, sm_append = 0.05925, lets_finer =0.05925, max_a_sm_err = 0.4084937, low_pass = 100, finer = 1\n",
      "Step   819, estim_aver_bat_size = 5.89, b =  1, bat_lim =   1601, error =  5, sm_append = 0.10866, lets_finer =0.10866, max_a_sm_err = 0.3544087, low_pass = 100, finer = 1\n",
      "Step   820, estim_aver_bat_size = 5.84, b =  1, bat_lim =   2101, error =  5, sm_append = 0.15757, lets_finer =0.15757, max_a_sm_err = 0.3008646, low_pass = 100, finer = 1\n",
      "Step   821, estim_aver_bat_size = 5.79, b =  1, bat_lim =   2601, error =  5, sm_append = 0.20599, lets_finer =0.20599, max_a_sm_err = 0.2478560, low_pass = 100, finer = 1\n",
      "Step   822, estim_aver_bat_size = 5.75, b =  1, bat_lim =   3101, error =  5, sm_append = 0.25393, lets_finer =0.25393, max_a_sm_err = 0.2539331, low_pass = 100, finer = 1\n",
      "Step   823, estim_aver_bat_size = 5.70, b =  1, bat_lim =   3601, error =  5, sm_append = 0.30139, lets_finer =0.30139, max_a_sm_err = 0.3013938, low_pass = 100, finer = 1\n",
      "Step   824, estim_aver_bat_size = 5.65, b =  1, bat_lim =   4101, error =  5, sm_append = 0.34838, lets_finer =0.34838, max_a_sm_err = 0.3483798, low_pass = 100, finer = 1\n",
      "Step   825, estim_aver_bat_size = 5.61, b =  1, bat_lim =   4601, error =  5, sm_append = 0.39490, lets_finer =0.39490, max_a_sm_err = 0.3948960, low_pass = 100, finer = 1\n",
      "Step   826, estim_aver_bat_size = 5.56, b =  1, bat_lim =   5101, error =  5, sm_append = 0.44095, lets_finer =0.44095, max_a_sm_err = 0.4409471, low_pass = 100, finer = 1\n",
      "Step   827, estim_aver_bat_size = 5.51, b =  1, bat_lim =   5601, error =  5, sm_append = 0.48654, lets_finer =0.48654, max_a_sm_err = 0.4865376, low_pass = 100, finer = 1\n",
      "Step   828, estim_aver_bat_size = 5.47, b =  1, bat_lim =   6101, error =  5, sm_append = 0.53167, lets_finer =0.53167, max_a_sm_err = 0.5316722, low_pass = 100, finer = 1\n",
      "Step   829, estim_aver_bat_size = 5.42, b =  1, bat_lim =   6601, error =  5, sm_append = 0.57636, lets_finer =0.57636, max_a_sm_err = 0.5763555, low_pass = 100, finer = 1\n",
      "Step   830, estim_aver_bat_size = 5.38, b =  1, bat_lim =   7101, error =  5, sm_append = 0.62059, lets_finer =0.62059, max_a_sm_err = 0.6205919, low_pass = 100, finer = 1\n",
      "Step   831, estim_aver_bat_size = 5.34, b =  1, bat_lim =   7601, error =  5, sm_append = 0.66439, lets_finer =0.66439, max_a_sm_err = 0.6643860, low_pass = 100, finer = 1\n",
      "Step   832, estim_aver_bat_size = 5.29, b =  1, bat_lim =   8101, error =  5, sm_append = 0.70774, lets_finer =0.70774, max_a_sm_err = 0.7077422, low_pass = 100, finer = 1\n",
      "Step   833, estim_aver_bat_size = 5.25, b =  1, bat_lim =   8601, error =  5, sm_append = 0.75066, lets_finer =0.75066, max_a_sm_err = 0.7506647, low_pass = 100, finer = 1\n",
      "Step   834, estim_aver_bat_size = 5.25, b =  5, bat_lim =   8701, error =  1, sm_append = 0.75316, lets_finer =0.75316, max_a_sm_err = 0.7531581, low_pass = 100, finer = 1\n",
      "Step   835, estim_aver_bat_size = 5.30, b = 11, bat_lim =   8201, error = -5, sm_append = 0.69563, lets_finer =0.69563, max_a_sm_err = 0.7531581, low_pass = 100, finer = 1\n",
      "Step   836, estim_aver_bat_size = 5.34, b =  9, bat_lim =   7901, error = -3, sm_append = 0.65867, lets_finer =0.65867, max_a_sm_err = 0.7531581, low_pass = 100, finer = 1\n",
      "Step   837, estim_aver_bat_size = 5.40, b = 11, bat_lim =   7401, error = -5, sm_append = 0.60208, lets_finer =0.60208, max_a_sm_err = 0.7531581, low_pass = 100, finer = 1\n",
      "Step   838, estim_aver_bat_size = 5.38, b =  4, bat_lim =   7601, error =  2, sm_append = 0.61606, lets_finer =0.61606, max_a_sm_err = 0.7531581, low_pass = 100, finer = 1\n",
      "Step   839, estim_aver_bat_size = 5.38, b =  5, bat_lim =   7701, error =  1, sm_append = 0.61990, lets_finer =0.61990, max_a_sm_err = 0.7531581, low_pass = 100, finer = 1\n",
      "Step   840, estim_aver_bat_size = 5.44, b = 11, bat_lim =   7201, error = -5, sm_append = 0.56370, lets_finer =0.56370, max_a_sm_err = 0.7531581, low_pass = 100, finer = 1\n",
      "Step   841, estim_aver_bat_size = 5.48, b = 10, bat_lim =   6801, error = -4, sm_append = 0.51807, lets_finer =0.51807, max_a_sm_err = 0.7531581, low_pass = 100, finer = 1\n",
      "Step   842, estim_aver_bat_size = 5.53, b = 10, bat_lim =   6401, error = -4, sm_append = 0.47289, lets_finer =0.47289, max_a_sm_err = 0.7531581, low_pass = 100, finer = 1\n",
      "Step   843, estim_aver_bat_size = 5.56, b =  9, bat_lim =   6101, error = -3, sm_append = 0.43816, lets_finer =0.43816, max_a_sm_err = 0.7531581, low_pass = 100, finer = 1\n",
      "Step   844, estim_aver_bat_size = 5.62, b = 11, bat_lim =   5601, error = -5, sm_append = 0.38377, lets_finer =0.38377, max_a_sm_err = 0.6956265, low_pass = 100, finer = 1\n",
      "Step   845, estim_aver_bat_size = 5.68, b = 12, bat_lim =   5001, error = -6, sm_append = 0.31994, lets_finer =0.31994, max_a_sm_err = 0.6586703, low_pass = 100, finer = 1\n",
      "Step   846, estim_aver_bat_size = 5.76, b = 14, bat_lim =   4201, error = -8, sm_append = 0.23674, lets_finer =0.23674, max_a_sm_err = 0.6199021, low_pass = 100, finer = 1\n",
      "Step   847, estim_aver_bat_size = 5.90, b = 19, bat_lim =   2901, error = -13, sm_append = 0.10437, lets_finer =0.10437, max_a_sm_err = 0.6199021, low_pass = 100, finer = 1\n",
      "Step   848, estim_aver_bat_size = 5.97, b = 13, bat_lim =   2201, error = -7, sm_append = 0.03333, lets_finer =0.03333, max_a_sm_err = 0.6199021, low_pass = 100, finer = 1\n",
      "Step   849, estim_aver_bat_size = 6.05, b = 14, bat_lim =   1401, error = -8, sm_append = -0.04701, lets_finer =0.04701, max_a_sm_err = 0.5637031, low_pass = 100, finer = 1\n",
      "Step   850, estim_aver_bat_size = 6.14, b = 15, bat_lim =    501, error = -9, sm_append = -0.13654, lets_finer =0.13654, max_a_sm_err = 0.5180660, low_pass = 100, finer = 1\n",
      "Step   851, estim_aver_bat_size = 6.26, b = 18, bat_lim =   -699, error = -12, sm_append = -0.25517, lets_finer =0.25517, max_a_sm_err = 0.4728854, low_pass = 100, finer = 1\n",
      "Step   852, estim_aver_bat_size = 6.37, b = 18, bat_lim =  -1899, error = -12, sm_append = -0.37262, lets_finer =0.37262, max_a_sm_err = 0.4381565, low_pass = 100, finer = 1\n",
      "Step   853, estim_aver_bat_size = 6.45, b = 14, bat_lim =  -2699, error = -8, sm_append = -0.44889, lets_finer =0.44889, max_a_sm_err = 0.4488932, low_pass = 100, finer = 1\n",
      "Step   854, estim_aver_bat_size = 6.54, b = 16, bat_lim =  -3699, error = -10, sm_append = -0.54440, lets_finer =0.54440, max_a_sm_err = 0.5444042, low_pass = 100, finer = 1\n",
      "Step   855, estim_aver_bat_size = 6.63, b = 15, bat_lim =  -4599, error = -9, sm_append = -0.62896, lets_finer =0.62896, max_a_sm_err = 0.6289602, low_pass = 100, finer = 1\n",
      "Step   856, estim_aver_bat_size = 6.72, b = 16, bat_lim =  -5599, error = -10, sm_append = -0.72267, lets_finer =0.72267, max_a_sm_err = 0.7226706, low_pass = 100, finer = 1\n",
      "Step   857, estim_aver_bat_size = 6.80, b = 14, bat_lim =  -6399, error = -8, sm_append = -0.79544, lets_finer =0.79544, max_a_sm_err = 0.7954439, low_pass = 100, finer = 1\n",
      "Step   858, estim_aver_bat_size = 6.83, b = 10, bat_lim =  -6799, error = -4, sm_append = -0.82749, lets_finer =0.82749, max_a_sm_err = 0.8274895, low_pass = 100, finer = 1\n",
      "Step   859, estim_aver_bat_size = 6.89, b = 13, bat_lim =  -7499, error = -7, sm_append = -0.88921, lets_finer =0.88921, max_a_sm_err = 0.8892146, low_pass = 100, finer = 1\n",
      "Step   860, estim_aver_bat_size = 6.92, b = 10, bat_lim =  -7899, error = -4, sm_append = -0.92032, lets_finer =0.92032, max_a_sm_err = 0.9203224, low_pass = 100, finer = 1\n",
      "Step   861, estim_aver_bat_size = 6.99, b = 14, bat_lim =  -8699, error = -8, sm_append = -0.99112, lets_finer =0.99112, max_a_sm_err = 0.9911192, low_pass = 100, finer = 1\n",
      "Step   862, estim_aver_bat_size = 7.07, b = 15, bat_lim =  -9599, error = -9, sm_append = -1.07121, lets_finer =1.07121, max_a_sm_err = 1.0712080, low_pass = 100, finer = 1\n",
      "Step   863, estim_aver_bat_size = 7.11, b = 11, bat_lim = -10099, error = -5, sm_append = -1.11050, lets_finer =1.11050, max_a_sm_err = 1.1104959, low_pass = 100, finer = 1\n",
      "Step   864, estim_aver_bat_size = 7.17, b = 13, bat_lim = -10799, error = -7, sm_append = -1.16939, lets_finer =1.16939, max_a_sm_err = 1.1693910, low_pass = 100, finer = 1\n",
      "Step   865, estim_aver_bat_size = 7.18, b =  8, bat_lim = -10999, error = -2, sm_append = -1.17770, lets_finer =1.17770, max_a_sm_err = 1.1776971, low_pass = 100, finer = 1\n",
      "Step   866, estim_aver_bat_size = 7.20, b =  9, bat_lim = -11299, error = -3, sm_append = -1.19592, lets_finer =1.19592, max_a_sm_err = 1.1959201, low_pass = 100, finer = 1\n",
      "Step   867, estim_aver_bat_size = 7.16, b =  4, bat_lim = -11099, error =  2, sm_append = -1.16396, lets_finer =1.16396, max_a_sm_err = 1.1959201, low_pass = 100, finer = 1\n",
      "Step   868, estim_aver_bat_size = 7.11, b =  2, bat_lim = -10699, error =  4, sm_append = -1.11232, lets_finer =1.11232, max_a_sm_err = 1.1959201, low_pass = 100, finer = 1\n",
      "Step   869, estim_aver_bat_size = 7.06, b =  2, bat_lim = -10299, error =  4, sm_append = -1.06120, lets_finer =1.06120, max_a_sm_err = 1.1959201, low_pass = 100, finer = 1\n",
      "Step   870, estim_aver_bat_size = 7.00, b =  1, bat_lim =  -9799, error =  5, sm_append = -1.00059, lets_finer =1.00059, max_a_sm_err = 1.1959201, low_pass = 100, finer = 1\n",
      "Step   871, estim_aver_bat_size = 6.94, b =  1, bat_lim =  -9299, error =  5, sm_append = -0.94058, lets_finer =0.94058, max_a_sm_err = 1.1959201, low_pass = 100, finer = 1\n",
      "Step   872, estim_aver_bat_size = 6.88, b =  1, bat_lim =  -8799, error =  5, sm_append = -0.88117, lets_finer =0.88117, max_a_sm_err = 1.1959201, low_pass = 100, finer = 1\n",
      "Step   873, estim_aver_bat_size = 6.82, b =  1, bat_lim =  -8299, error =  5, sm_append = -0.82236, lets_finer =0.82236, max_a_sm_err = 1.1959201, low_pass = 100, finer = 1\n",
      "Step   874, estim_aver_bat_size = 6.76, b =  1, bat_lim =  -7799, error =  5, sm_append = -0.76414, lets_finer =0.76414, max_a_sm_err = 1.1959201, low_pass = 100, finer = 1\n",
      "Step   875, estim_aver_bat_size = 6.71, b =  1, bat_lim =  -7299, error =  5, sm_append = -0.70650, lets_finer =0.70650, max_a_sm_err = 1.1959201, low_pass = 100, finer = 1\n",
      "Step   876, estim_aver_bat_size = 6.65, b =  1, bat_lim =  -6799, error =  5, sm_append = -0.64943, lets_finer =0.64943, max_a_sm_err = 1.1639609, low_pass = 100, finer = 1\n",
      "Step   877, estim_aver_bat_size = 6.59, b =  1, bat_lim =  -6299, error =  5, sm_append = -0.59294, lets_finer =0.59294, max_a_sm_err = 1.1123213, low_pass = 100, finer = 1\n",
      "Step   878, estim_aver_bat_size = 6.54, b =  1, bat_lim =  -5799, error =  5, sm_append = -0.53701, lets_finer =0.53701, max_a_sm_err = 1.0611981, low_pass = 100, finer = 1\n",
      "Step   879, estim_aver_bat_size = 6.48, b =  1, bat_lim =  -5299, error =  5, sm_append = -0.48164, lets_finer =0.48164, max_a_sm_err = 1.0005861, low_pass = 100, finer = 1\n",
      "Step   880, estim_aver_bat_size = 6.43, b =  1, bat_lim =  -4799, error =  5, sm_append = -0.42682, lets_finer =0.42682, max_a_sm_err = 0.9405802, low_pass = 100, finer = 1\n",
      "Step   881, estim_aver_bat_size = 6.37, b =  1, bat_lim =  -4299, error =  5, sm_append = -0.37255, lets_finer =0.37255, max_a_sm_err = 0.8811744, low_pass = 100, finer = 1\n",
      "Step   882, estim_aver_bat_size = 6.32, b =  1, bat_lim =  -3799, error =  5, sm_append = -0.31883, lets_finer =0.31883, max_a_sm_err = 0.8223627, low_pass = 100, finer = 1\n",
      "Step   883, estim_aver_bat_size = 6.27, b =  1, bat_lim =  -3299, error =  5, sm_append = -0.26564, lets_finer =0.26564, max_a_sm_err = 0.7641390, low_pass = 100, finer = 1\n",
      "Step   884, estim_aver_bat_size = 6.21, b =  1, bat_lim =  -2799, error =  5, sm_append = -0.21298, lets_finer =0.21298, max_a_sm_err = 0.7064977, low_pass = 100, finer = 1\n",
      "Step   885, estim_aver_bat_size = 6.16, b =  1, bat_lim =  -2299, error =  5, sm_append = -0.16085, lets_finer =0.16085, max_a_sm_err = 0.6494327, low_pass = 100, finer = 1\n",
      "Step   886, estim_aver_bat_size = 6.11, b =  1, bat_lim =  -1799, error =  5, sm_append = -0.10925, lets_finer =0.10925, max_a_sm_err = 0.5929384, low_pass = 100, finer = 1\n",
      "Step   887, estim_aver_bat_size = 6.06, b =  1, bat_lim =  -1299, error =  5, sm_append = -0.05815, lets_finer =0.05815, max_a_sm_err = 0.5370090, low_pass = 100, finer = 1\n",
      "Step   888, estim_aver_bat_size = 6.01, b =  1, bat_lim =   -799, error =  5, sm_append = -0.00757, lets_finer =0.00757, max_a_sm_err = 0.4816389, low_pass = 100, finer = 1\n",
      "Step   889, estim_aver_bat_size = 5.96, b =  1, bat_lim =   -299, error =  5, sm_append = 0.04250, lets_finer =0.04250, max_a_sm_err = 0.4268225, low_pass = 100, finer = 1\n",
      "Step   890, estim_aver_bat_size = 5.91, b =  1, bat_lim =    201, error =  5, sm_append = 0.09208, lets_finer =0.09208, max_a_sm_err = 0.3725543, low_pass = 100, finer = 1\n",
      "Step   891, estim_aver_bat_size = 5.86, b =  1, bat_lim =    701, error =  5, sm_append = 0.14116, lets_finer =0.14116, max_a_sm_err = 0.3188287, low_pass = 100, finer = 1\n",
      "Step   892, estim_aver_bat_size = 5.81, b =  1, bat_lim =   1201, error =  5, sm_append = 0.18975, lets_finer =0.18975, max_a_sm_err = 0.2656404, low_pass = 100, finer = 1\n",
      "Step   893, estim_aver_bat_size = 5.76, b =  1, bat_lim =   1701, error =  5, sm_append = 0.23785, lets_finer =0.23785, max_a_sm_err = 0.2378492, low_pass = 100, finer = 1\n",
      "Step   894, estim_aver_bat_size = 5.71, b =  1, bat_lim =   2201, error =  5, sm_append = 0.28547, lets_finer =0.28547, max_a_sm_err = 0.2854707, low_pass = 100, finer = 1\n",
      "Step   895, estim_aver_bat_size = 5.67, b =  1, bat_lim =   2701, error =  5, sm_append = 0.33262, lets_finer =0.33262, max_a_sm_err = 0.3326160, low_pass = 100, finer = 1\n",
      "Step   896, estim_aver_bat_size = 5.62, b =  1, bat_lim =   3201, error =  5, sm_append = 0.37929, lets_finer =0.37929, max_a_sm_err = 0.3792898, low_pass = 100, finer = 1\n",
      "Step   897, estim_aver_bat_size = 5.57, b =  1, bat_lim =   3701, error =  5, sm_append = 0.42550, lets_finer =0.42550, max_a_sm_err = 0.4254969, low_pass = 100, finer = 1\n",
      "Step   898, estim_aver_bat_size = 5.53, b =  1, bat_lim =   4201, error =  5, sm_append = 0.47124, lets_finer =0.47124, max_a_sm_err = 0.4712419, low_pass = 100, finer = 1\n",
      "Step   899, estim_aver_bat_size = 5.48, b =  1, bat_lim =   4701, error =  5, sm_append = 0.51653, lets_finer =0.51653, max_a_sm_err = 0.5165295, low_pass = 100, finer = 1\n",
      "Step   900, estim_aver_bat_size = 5.44, b =  1, bat_lim =   5201, error =  5, sm_append = 0.56136, lets_finer =0.56136, max_a_sm_err = 0.5613642, low_pass = 100, finer = 1\n",
      "Step   901, estim_aver_bat_size = 5.48, b = 10, bat_lim =   4801, error = -4, sm_append = 0.51575, lets_finer =0.51575, max_a_sm_err = 0.5613642, low_pass = 100, finer = 1\n",
      "Step   902, estim_aver_bat_size = 5.53, b = 10, bat_lim =   4401, error = -4, sm_append = 0.47059, lets_finer =0.47059, max_a_sm_err = 0.5613642, low_pass = 100, finer = 1\n",
      "Step   903, estim_aver_bat_size = 5.55, b =  8, bat_lim =   4201, error = -2, sm_append = 0.44589, lets_finer =0.44589, max_a_sm_err = 0.5613642, low_pass = 100, finer = 1\n",
      "Step   904, estim_aver_bat_size = 5.61, b = 11, bat_lim =   3701, error = -5, sm_append = 0.39143, lets_finer =0.39143, max_a_sm_err = 0.5613642, low_pass = 100, finer = 1\n",
      "Step   905, estim_aver_bat_size = 5.63, b =  8, bat_lim =   3501, error = -2, sm_append = 0.36751, lets_finer =0.36751, max_a_sm_err = 0.5613642, low_pass = 100, finer = 1\n",
      "Step   906, estim_aver_bat_size = 5.71, b = 13, bat_lim =   2801, error = -7, sm_append = 0.29384, lets_finer =0.29384, max_a_sm_err = 0.5613642, low_pass = 100, finer = 1\n",
      "Step   907, estim_aver_bat_size = 5.75, b = 10, bat_lim =   2401, error = -4, sm_append = 0.25090, lets_finer =0.25090, max_a_sm_err = 0.5613642, low_pass = 100, finer = 1\n",
      "Step   908, estim_aver_bat_size = 5.79, b = 10, bat_lim =   2001, error = -4, sm_append = 0.20839, lets_finer =0.20839, max_a_sm_err = 0.5613642, low_pass = 100, finer = 1\n",
      "Step   909, estim_aver_bat_size = 5.83, b = 10, bat_lim =   1601, error = -4, sm_append = 0.16631, lets_finer =0.16631, max_a_sm_err = 0.5613642, low_pass = 100, finer = 1\n",
      "Step   910, estim_aver_bat_size = 5.89, b = 11, bat_lim =   1101, error = -5, sm_append = 0.11464, lets_finer =0.11464, max_a_sm_err = 0.5157506, low_pass = 100, finer = 1\n",
      "Step   911, estim_aver_bat_size = 5.92, b =  9, bat_lim =    801, error = -3, sm_append = 0.08350, lets_finer =0.08350, max_a_sm_err = 0.4705931, low_pass = 100, finer = 1\n",
      "Step   912, estim_aver_bat_size = 5.95, b =  9, bat_lim =    501, error = -3, sm_append = 0.05266, lets_finer =0.05266, max_a_sm_err = 0.4458872, low_pass = 100, finer = 1\n",
      "Step   913, estim_aver_bat_size = 5.95, b =  6, bat_lim =    501, error =  0, sm_append = 0.05214, lets_finer =0.05214, max_a_sm_err = 0.3914283, low_pass = 100, finer = 1\n",
      "Step   914, estim_aver_bat_size = 5.97, b =  8, bat_lim =    301, error = -2, sm_append = 0.03162, lets_finer =0.03162, max_a_sm_err = 0.3675140, low_pass = 100, finer = 1\n",
      "Step   915, estim_aver_bat_size = 5.99, b =  8, bat_lim =    101, error = -2, sm_append = 0.01130, lets_finer =0.01130, max_a_sm_err = 0.2938389, low_pass = 100, finer = 1\n",
      "Step   916, estim_aver_bat_size = 6.04, b = 11, bat_lim =   -399, error = -5, sm_append = -0.03881, lets_finer =0.03881, max_a_sm_err = 0.2509005, low_pass = 100, finer = 1\n",
      "Step   917, estim_aver_bat_size = 6.08, b = 10, bat_lim =   -799, error = -4, sm_append = -0.07843, lets_finer =0.07843, max_a_sm_err = 0.2083915, low_pass = 100, finer = 1\n",
      "Step   918, estim_aver_bat_size = 6.11, b =  9, bat_lim =  -1099, error = -3, sm_append = -0.10764, lets_finer =0.10764, max_a_sm_err = 0.1663076, low_pass = 100, finer = 1\n",
      "Step   919, estim_aver_bat_size = 6.14, b =  9, bat_lim =  -1399, error = -3, sm_append = -0.13657, lets_finer =0.13657, max_a_sm_err = 0.1365653, low_pass = 100, finer = 1\n",
      "Step   920, estim_aver_bat_size = 6.17, b =  9, bat_lim =  -1699, error = -3, sm_append = -0.16520, lets_finer =0.16520, max_a_sm_err = 0.1651996, low_pass = 100, finer = 1\n",
      "Step   921, estim_aver_bat_size = 6.13, b =  3, bat_lim =  -1399, error =  3, sm_append = -0.13355, lets_finer =0.13355, max_a_sm_err = 0.1651996, low_pass = 100, finer = 1\n",
      "Step   922, estim_aver_bat_size = 6.09, b =  2, bat_lim =   -999, error =  4, sm_append = -0.09221, lets_finer =0.09221, max_a_sm_err = 0.1651996, low_pass = 100, finer = 1\n",
      "Step   923, estim_aver_bat_size = 6.05, b =  2, bat_lim =   -599, error =  4, sm_append = -0.05129, lets_finer =0.05129, max_a_sm_err = 0.1651996, low_pass = 100, finer = 1\n",
      "Step   924, estim_aver_bat_size = 6.02, b =  3, bat_lim =   -299, error =  3, sm_append = -0.02078, lets_finer =0.02078, max_a_sm_err = 0.1651996, low_pass = 100, finer = 1\n",
      "Step   925, estim_aver_bat_size = 5.98, b =  2, bat_lim =    101, error =  4, sm_append = 0.01943, lets_finer =0.01943, max_a_sm_err = 0.1651996, low_pass = 100, finer = 1\n",
      "Step   926, estim_aver_bat_size = 5.94, b =  2, bat_lim =    501, error =  4, sm_append = 0.05924, lets_finer =0.05924, max_a_sm_err = 0.1651996, low_pass = 100, finer = 1\n",
      "Step   927, estim_aver_bat_size = 5.91, b =  3, bat_lim =    801, error =  3, sm_append = 0.08864, lets_finer =0.08864, max_a_sm_err = 0.1651996, low_pass = 100, finer = 1\n",
      "Step   928, estim_aver_bat_size = 5.87, b =  2, bat_lim =   1201, error =  4, sm_append = 0.12776, lets_finer =0.12776, max_a_sm_err = 0.1651996, low_pass = 100, finer = 1\n",
      "Step   929, estim_aver_bat_size = 5.84, b =  3, bat_lim =   1501, error =  3, sm_append = 0.15648, lets_finer =0.15648, max_a_sm_err = 0.1651996, low_pass = 100, finer = 1\n",
      "Step   930, estim_aver_bat_size = 5.81, b =  2, bat_lim =   1901, error =  4, sm_append = 0.19492, lets_finer =0.19492, max_a_sm_err = 0.1949152, low_pass = 100, finer = 1\n",
      "Step   931, estim_aver_bat_size = 5.76, b =  1, bat_lim =   2401, error =  5, sm_append = 0.24297, lets_finer =0.24297, max_a_sm_err = 0.2429660, low_pass = 100, finer = 1\n",
      "Step   932, estim_aver_bat_size = 5.72, b =  2, bat_lim =   2801, error =  4, sm_append = 0.28054, lets_finer =0.28054, max_a_sm_err = 0.2805364, low_pass = 100, finer = 1\n",
      "Step   933, estim_aver_bat_size = 5.67, b =  1, bat_lim =   3301, error =  5, sm_append = 0.32773, lets_finer =0.32773, max_a_sm_err = 0.3277310, low_pass = 100, finer = 1\n",
      "Step   934, estim_aver_bat_size = 5.63, b =  1, bat_lim =   3801, error =  5, sm_append = 0.37445, lets_finer =0.37445, max_a_sm_err = 0.3744537, low_pass = 100, finer = 1\n",
      "Step   935, estim_aver_bat_size = 5.58, b =  1, bat_lim =   4301, error =  5, sm_append = 0.42071, lets_finer =0.42071, max_a_sm_err = 0.4207091, low_pass = 100, finer = 1\n",
      "Step   936, estim_aver_bat_size = 5.53, b =  1, bat_lim =   4801, error =  5, sm_append = 0.46650, lets_finer =0.46650, max_a_sm_err = 0.4665021, low_pass = 100, finer = 1\n",
      "Step   937, estim_aver_bat_size = 5.49, b =  1, bat_lim =   5301, error =  5, sm_append = 0.51184, lets_finer =0.51184, max_a_sm_err = 0.5118370, low_pass = 100, finer = 1\n",
      "Step   938, estim_aver_bat_size = 5.44, b =  1, bat_lim =   5801, error =  5, sm_append = 0.55672, lets_finer =0.55672, max_a_sm_err = 0.5567187, low_pass = 100, finer = 1\n",
      "Step   939, estim_aver_bat_size = 5.40, b =  1, bat_lim =   6301, error =  5, sm_append = 0.60115, lets_finer =0.60115, max_a_sm_err = 0.6011515, low_pass = 100, finer = 1\n",
      "Step   940, estim_aver_bat_size = 5.35, b =  1, bat_lim =   6801, error =  5, sm_append = 0.64514, lets_finer =0.64514, max_a_sm_err = 0.6451400, low_pass = 100, finer = 1\n",
      "Step   941, estim_aver_bat_size = 5.31, b =  1, bat_lim =   7301, error =  5, sm_append = 0.68869, lets_finer =0.68869, max_a_sm_err = 0.6886886, low_pass = 100, finer = 1\n",
      "Step   942, estim_aver_bat_size = 5.27, b =  1, bat_lim =   7801, error =  5, sm_append = 0.73180, lets_finer =0.73180, max_a_sm_err = 0.7318017, low_pass = 100, finer = 1\n",
      "Step   943, estim_aver_bat_size = 5.23, b =  1, bat_lim =   8301, error =  5, sm_append = 0.77448, lets_finer =0.77448, max_a_sm_err = 0.7744837, low_pass = 100, finer = 1\n",
      "Step   944, estim_aver_bat_size = 5.18, b =  1, bat_lim =   8801, error =  5, sm_append = 0.81674, lets_finer =0.81674, max_a_sm_err = 0.8167388, low_pass = 100, finer = 1\n",
      "Step   945, estim_aver_bat_size = 5.15, b =  2, bat_lim =   9201, error =  4, sm_append = 0.84857, lets_finer =0.84857, max_a_sm_err = 0.8485714, low_pass = 100, finer = 1\n",
      "Step   946, estim_aver_bat_size = 5.11, b =  1, bat_lim =   9701, error =  5, sm_append = 0.89009, lets_finer =0.89009, max_a_sm_err = 0.8900857, low_pass = 100, finer = 1\n",
      "Step   947, estim_aver_bat_size = 5.10, b =  4, bat_lim =   9901, error =  2, sm_append = 0.90118, lets_finer =0.90118, max_a_sm_err = 0.9011849, low_pass = 100, finer = 1\n",
      "Step   948, estim_aver_bat_size = 5.09, b =  4, bat_lim =  10101, error =  2, sm_append = 0.91217, lets_finer =0.91217, max_a_sm_err = 0.9121730, low_pass = 100, finer = 1\n",
      "Step   949, estim_aver_bat_size = 5.07, b =  3, bat_lim =  10401, error =  3, sm_append = 0.93305, lets_finer =0.93305, max_a_sm_err = 0.9330513, low_pass = 100, finer = 1\n",
      "Step   950, estim_aver_bat_size = 5.09, b =  7, bat_lim =  10301, error = -1, sm_append = 0.91372, lets_finer =0.91372, max_a_sm_err = 0.9330513, low_pass = 100, finer = 1\n",
      "Step   951, estim_aver_bat_size = 5.10, b =  6, bat_lim =  10301, error =  0, sm_append = 0.90458, lets_finer =0.90458, max_a_sm_err = 0.9330513, low_pass = 100, finer = 1\n",
      "Step   952, estim_aver_bat_size = 5.11, b =  7, bat_lim =  10201, error = -1, sm_append = 0.88554, lets_finer =0.88554, max_a_sm_err = 0.9330513, low_pass = 100, finer = 1\n",
      "Step   953, estim_aver_bat_size = 5.14, b =  8, bat_lim =  10001, error = -2, sm_append = 0.85668, lets_finer =0.85668, max_a_sm_err = 0.9330513, low_pass = 100, finer = 1\n",
      "Step   954, estim_aver_bat_size = 5.18, b =  9, bat_lim =   9701, error = -3, sm_append = 0.81812, lets_finer =0.81812, max_a_sm_err = 0.9330513, low_pass = 100, finer = 1\n",
      "Step   955, estim_aver_bat_size = 5.32, b = 19, bat_lim =   8401, error = -13, sm_append = 0.67993, lets_finer =0.67993, max_a_sm_err = 0.9330513, low_pass = 100, finer = 1\n",
      "Step   956, estim_aver_bat_size = 5.44, b = 17, bat_lim =   7301, error = -11, sm_append = 0.56314, lets_finer =0.56314, max_a_sm_err = 0.9330513, low_pass = 100, finer = 1\n",
      "Step   957, estim_aver_bat_size = 5.56, b = 18, bat_lim =   6101, error = -12, sm_append = 0.43750, lets_finer =0.43750, max_a_sm_err = 0.9330513, low_pass = 100, finer = 1\n",
      "Step   958, estim_aver_bat_size = 5.69, b = 18, bat_lim =   4901, error = -12, sm_append = 0.31313, lets_finer =0.31313, max_a_sm_err = 0.9330513, low_pass = 100, finer = 1\n",
      "Step   959, estim_aver_bat_size = 5.83, b = 20, bat_lim =   3501, error = -14, sm_append = 0.17000, lets_finer =0.17000, max_a_sm_err = 0.9137208, low_pass = 100, finer = 1\n",
      "Step   960, estim_aver_bat_size = 5.95, b = 18, bat_lim =   2301, error = -12, sm_append = 0.04830, lets_finer =0.04830, max_a_sm_err = 0.9045836, low_pass = 100, finer = 1\n",
      "Step   961, estim_aver_bat_size = 6.06, b = 17, bat_lim =   1201, error = -11, sm_append = -0.06219, lets_finer =0.06219, max_a_sm_err = 0.8855377, low_pass = 100, finer = 1\n",
      "Step   962, estim_aver_bat_size = 6.17, b = 17, bat_lim =    101, error = -11, sm_append = -0.17156, lets_finer =0.17156, max_a_sm_err = 0.8566824, low_pass = 100, finer = 1\n",
      "Step   963, estim_aver_bat_size = 6.30, b = 19, bat_lim =  -1199, error = -13, sm_append = -0.29985, lets_finer =0.29985, max_a_sm_err = 0.8181155, low_pass = 100, finer = 1\n",
      "Step   964, estim_aver_bat_size = 6.43, b = 19, bat_lim =  -2499, error = -13, sm_append = -0.42685, lets_finer =0.42685, max_a_sm_err = 0.6799344, low_pass = 100, finer = 1\n",
      "Step   965, estim_aver_bat_size = 6.47, b = 11, bat_lim =  -2999, error = -5, sm_append = -0.47258, lets_finer =0.47258, max_a_sm_err = 0.5631350, low_pass = 100, finer = 1\n",
      "Step   966, estim_aver_bat_size = 6.51, b = 10, bat_lim =  -3399, error = -4, sm_append = -0.50786, lets_finer =0.50786, max_a_sm_err = 0.5078553, low_pass = 100, finer = 1\n",
      "Step   967, estim_aver_bat_size = 6.55, b = 11, bat_lim =  -3899, error = -5, sm_append = -0.55278, lets_finer =0.55278, max_a_sm_err = 0.5527768, low_pass = 100, finer = 1\n",
      "Step   968, estim_aver_bat_size = 6.57, b =  8, bat_lim =  -4099, error = -2, sm_append = -0.56725, lets_finer =0.56725, max_a_sm_err = 0.5672490, low_pass = 100, finer = 1\n",
      "Step   969, estim_aver_bat_size = 6.64, b = 14, bat_lim =  -4899, error = -8, sm_append = -0.64158, lets_finer =0.64158, max_a_sm_err = 0.6415765, low_pass = 100, finer = 1\n",
      "Step   970, estim_aver_bat_size = 6.68, b = 10, bat_lim =  -5299, error = -4, sm_append = -0.67516, lets_finer =0.67516, max_a_sm_err = 0.6751607, low_pass = 100, finer = 1\n",
      "Step   971, estim_aver_bat_size = 6.69, b =  8, bat_lim =  -5499, error = -2, sm_append = -0.68841, lets_finer =0.68841, max_a_sm_err = 0.6884091, low_pass = 100, finer = 1\n",
      "Step   972, estim_aver_bat_size = 6.70, b =  8, bat_lim =  -5699, error = -2, sm_append = -0.70153, lets_finer =0.70153, max_a_sm_err = 0.7015250, low_pass = 100, finer = 1\n",
      "Step   973, estim_aver_bat_size = 6.73, b = 10, bat_lim =  -6099, error = -4, sm_append = -0.73451, lets_finer =0.73451, max_a_sm_err = 0.7345098, low_pass = 100, finer = 1\n",
      "Step   974, estim_aver_bat_size = 6.77, b = 10, bat_lim =  -6499, error = -4, sm_append = -0.76716, lets_finer =0.76716, max_a_sm_err = 0.7671647, low_pass = 100, finer = 1\n",
      "Step   975, estim_aver_bat_size = 6.71, b =  1, bat_lim =  -5999, error =  5, sm_append = -0.70949, lets_finer =0.70949, max_a_sm_err = 0.7671647, low_pass = 100, finer = 1\n",
      "Step   976, estim_aver_bat_size = 6.65, b =  1, bat_lim =  -5499, error =  5, sm_append = -0.65240, lets_finer =0.65240, max_a_sm_err = 0.7671647, low_pass = 100, finer = 1\n",
      "Step   977, estim_aver_bat_size = 6.60, b =  1, bat_lim =  -4999, error =  5, sm_append = -0.59587, lets_finer =0.59587, max_a_sm_err = 0.7671647, low_pass = 100, finer = 1\n",
      "Step   978, estim_aver_bat_size = 6.54, b =  1, bat_lim =  -4499, error =  5, sm_append = -0.53992, lets_finer =0.53992, max_a_sm_err = 0.7671647, low_pass = 100, finer = 1\n",
      "Step   979, estim_aver_bat_size = 6.48, b =  1, bat_lim =  -3999, error =  5, sm_append = -0.48452, lets_finer =0.48452, max_a_sm_err = 0.7671647, low_pass = 100, finer = 1\n",
      "Step   980, estim_aver_bat_size = 6.43, b =  1, bat_lim =  -3499, error =  5, sm_append = -0.42967, lets_finer =0.42967, max_a_sm_err = 0.7671647, low_pass = 100, finer = 1\n",
      "Step   981, estim_aver_bat_size = 6.38, b =  1, bat_lim =  -2999, error =  5, sm_append = -0.37537, lets_finer =0.37537, max_a_sm_err = 0.7671647, low_pass = 100, finer = 1\n",
      "Step   982, estim_aver_bat_size = 6.32, b =  1, bat_lim =  -2499, error =  5, sm_append = -0.32162, lets_finer =0.32162, max_a_sm_err = 0.7671647, low_pass = 100, finer = 1\n",
      "Step   983, estim_aver_bat_size = 6.27, b =  1, bat_lim =  -1999, error =  5, sm_append = -0.26840, lets_finer =0.26840, max_a_sm_err = 0.7671647, low_pass = 100, finer = 1\n",
      "Step   984, estim_aver_bat_size = 6.22, b =  1, bat_lim =  -1499, error =  5, sm_append = -0.21572, lets_finer =0.21572, max_a_sm_err = 0.7094930, low_pass = 100, finer = 1\n",
      "Step   985, estim_aver_bat_size = 6.16, b =  1, bat_lim =   -999, error =  5, sm_append = -0.16356, lets_finer =0.16356, max_a_sm_err = 0.6523981, low_pass = 100, finer = 1\n",
      "Step   986, estim_aver_bat_size = 6.11, b =  1, bat_lim =   -499, error =  5, sm_append = -0.11193, lets_finer =0.11193, max_a_sm_err = 0.5958741, low_pass = 100, finer = 1\n",
      "Step   987, estim_aver_bat_size = 6.06, b =  1, bat_lim =      1, error =  5, sm_append = -0.06081, lets_finer =0.06081, max_a_sm_err = 0.5399154, low_pass = 100, finer = 1\n",
      "Step   988, estim_aver_bat_size = 6.01, b =  1, bat_lim =    501, error =  5, sm_append = -0.01020, lets_finer =0.01020, max_a_sm_err = 0.4845162, low_pass = 100, finer = 1\n",
      "Step   989, estim_aver_bat_size = 5.96, b =  1, bat_lim =   1001, error =  5, sm_append = 0.03990, lets_finer =0.03990, max_a_sm_err = 0.4296711, low_pass = 100, finer = 1\n",
      "Step   990, estim_aver_bat_size = 5.91, b =  1, bat_lim =   1501, error =  5, sm_append = 0.08950, lets_finer =0.08950, max_a_sm_err = 0.3753744, low_pass = 100, finer = 1\n",
      "Step   991, estim_aver_bat_size = 5.86, b =  1, bat_lim =   2001, error =  5, sm_append = 0.13861, lets_finer =0.13861, max_a_sm_err = 0.3216206, low_pass = 100, finer = 1\n",
      "Step   992, estim_aver_bat_size = 5.81, b =  1, bat_lim =   2501, error =  5, sm_append = 0.18722, lets_finer =0.18722, max_a_sm_err = 0.2684044, low_pass = 100, finer = 1\n",
      "Step   993, estim_aver_bat_size = 5.76, b =  1, bat_lim =   3001, error =  5, sm_append = 0.23535, lets_finer =0.23535, max_a_sm_err = 0.2353495, low_pass = 100, finer = 1\n",
      "Step   994, estim_aver_bat_size = 5.72, b =  1, bat_lim =   3501, error =  5, sm_append = 0.28300, lets_finer =0.28300, max_a_sm_err = 0.2829960, low_pass = 100, finer = 1\n",
      "Step   995, estim_aver_bat_size = 5.67, b =  1, bat_lim =   4001, error =  5, sm_append = 0.33017, lets_finer =0.33017, max_a_sm_err = 0.3301660, low_pass = 100, finer = 1\n",
      "Step   996, estim_aver_bat_size = 5.62, b =  1, bat_lim =   4501, error =  5, sm_append = 0.37686, lets_finer =0.37686, max_a_sm_err = 0.3768644, low_pass = 100, finer = 1\n",
      "Step   997, estim_aver_bat_size = 5.58, b =  1, bat_lim =   5001, error =  5, sm_append = 0.42310, lets_finer =0.42310, max_a_sm_err = 0.4230957, low_pass = 100, finer = 1\n",
      "Step   998, estim_aver_bat_size = 5.53, b =  1, bat_lim =   5501, error =  5, sm_append = 0.46886, lets_finer =0.46886, max_a_sm_err = 0.4688648, low_pass = 100, finer = 1\n",
      "Step   999, estim_aver_bat_size = 5.49, b =  1, bat_lim =   6001, error =  5, sm_append = 0.51418, lets_finer =0.51418, max_a_sm_err = 0.5141761, low_pass = 100, finer = 1\n",
      "Step  1000, estim_aver_bat_size = 5.44, b =  1, bat_lim =   6501, error =  5, sm_append = 0.55903, lets_finer =0.55903, max_a_sm_err = 0.5590344, low_pass = 100, finer = 1\n",
      "\n",
      "**************************************************\n",
      "\n",
      "neighbors_num |  layer  0  |  layer  1  |  layer  2  |  layer  3  |  layer  4  \n",
      "        0     |\u001b[92m         0\u001b[0m  |\u001b[92m         0\u001b[0m  |\u001b[92m         0\u001b[0m  |\u001b[92m         0\u001b[0m  |\u001b[92m         0\u001b[0m  \n",
      "        1     |\u001b[92m        85\u001b[0m  |\u001b[92m         5\u001b[0m  |\u001b[92m         0\u001b[0m  |\u001b[92m         0\u001b[0m  |\u001b[92m         6\u001b[0m  \n",
      "        2     |\u001b[92m       144\u001b[0m  |\u001b[92m         9\u001b[0m  |\u001b[92m         0\u001b[0m  |\u001b[92m        14\u001b[0m  |\u001b[92m       104\u001b[0m  \n",
      "        3     |\u001b[92m       230\u001b[0m  |\u001b[92m        19\u001b[0m  |\u001b[92m         3\u001b[0m  |\u001b[92m        36\u001b[0m  |\u001b[92m       696\u001b[0m  \n",
      "        4     |\u001b[92m       372\u001b[0m  |\u001b[92m        22\u001b[0m  |\u001b[92m         4\u001b[0m  |\u001b[92m       264\u001b[0m  |\u001b[92m      5832\u001b[0m  \n",
      "        5     |\u001b[92m       396\u001b[0m  |\u001b[92m        30\u001b[0m  |\u001b[92m        20\u001b[0m  |\u001b[92m       735\u001b[0m  |\u001b[92m      8990\u001b[0m  \n",
      "        6     |\u001b[92m       411\u001b[0m  |\u001b[92m        40\u001b[0m  |\u001b[92m        18\u001b[0m  |\u001b[92m      2106\u001b[0m  |\u001b[92m     11010\u001b[0m  \n",
      "        7     |\u001b[92m       583\u001b[0m  |\u001b[92m        57\u001b[0m  |\u001b[92m         7\u001b[0m  |\u001b[92m      2898\u001b[0m  |\u001b[92m      3255\u001b[0m  \n",
      "        8     |\u001b[92m       681\u001b[0m  |\u001b[92m        80\u001b[0m  |\u001b[92m         8\u001b[0m  |\u001b[92m      4264\u001b[0m  |\u001b[91m       712\u001b[0m  \n",
      "        9     |\u001b[92m       682\u001b[0m  |\u001b[92m       103\u001b[0m  |\u001b[92m        18\u001b[0m  |\u001b[92m      5337\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       10     |\u001b[92m       794\u001b[0m  |\u001b[92m       107\u001b[0m  |\u001b[92m        10\u001b[0m  |\u001b[92m      6090\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       11     |\u001b[92m       957\u001b[0m  |\u001b[92m       138\u001b[0m  |\u001b[92m        33\u001b[0m  |\u001b[92m      6754\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       12     |\u001b[92m      1330\u001b[0m  |\u001b[92m       165\u001b[0m  |\u001b[92m        48\u001b[0m  |\u001b[92m      7932\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       13     |\u001b[92m      2038\u001b[0m  |\u001b[92m       201\u001b[0m  |\u001b[92m       104\u001b[0m  |\u001b[92m      6370\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       14     |\u001b[92m      2887\u001b[0m  |\u001b[92m       262\u001b[0m  |\u001b[92m       182\u001b[0m  |\u001b[92m      6398\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       15     |\u001b[92m      4475\u001b[0m  |\u001b[92m       336\u001b[0m  |\u001b[92m       315\u001b[0m  |\u001b[92m      5160\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       16     |\u001b[92m      6534\u001b[0m  |\u001b[92m       435\u001b[0m  |\u001b[92m       432\u001b[0m  |\u001b[92m      3904\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       17     |\u001b[92m      9241\u001b[0m  |\u001b[92m       583\u001b[0m  |\u001b[92m       374\u001b[0m  |\u001b[92m      2856\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       18     |\u001b[92m     12832\u001b[0m  |\u001b[92m       962\u001b[0m  |\u001b[92m       576\u001b[0m  |\u001b[91m      2070\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       19     |\u001b[92m     16153\u001b[0m  |\u001b[92m      1825\u001b[0m  |\u001b[92m       665\u001b[0m  |\u001b[91m       950\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       20     |\u001b[92m     20202\u001b[0m  |\u001b[92m      3023\u001b[0m  |\u001b[92m      1060\u001b[0m  |\u001b[91m       640\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       21     |\u001b[92m     21252\u001b[0m  |\u001b[92m      4641\u001b[0m  |\u001b[92m      1029\u001b[0m  |\u001b[91m       420\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       22     |\u001b[92m     25010\u001b[0m  |\u001b[92m      6638\u001b[0m  |\u001b[92m      1650\u001b[0m  |\u001b[91m       110\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       23     |\u001b[92m     25742\u001b[0m  |\u001b[92m      9149\u001b[0m  |\u001b[92m      2231\u001b[0m  |\u001b[91m        46\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       24     |\u001b[92m     28220\u001b[0m  |\u001b[92m     11518\u001b[0m  |\u001b[92m      2664\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       25     |\u001b[92m     31205\u001b[0m  |\u001b[92m     13424\u001b[0m  |\u001b[92m      3375\u001b[0m  |\u001b[91m        25\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       26     |\u001b[92m     32650\u001b[0m  |\u001b[92m     14811\u001b[0m  |\u001b[92m      3952\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       27     |\u001b[92m     35765\u001b[0m  |\u001b[92m     15269\u001b[0m  |\u001b[92m      4401\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       28     |\u001b[92m     38342\u001b[0m  |\u001b[92m     15113\u001b[0m  |\u001b[92m      5152\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       29     |\u001b[92m     40534\u001b[0m  |\u001b[92m     15674\u001b[0m  |\u001b[92m      5974\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       30     |\u001b[92m     39639\u001b[0m  |\u001b[92m     15629\u001b[0m  |\u001b[92m      6360\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       31     |\u001b[92m     44974\u001b[0m  |\u001b[92m     15916\u001b[0m  |\u001b[92m      6758\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       32     |\u001b[92m     45448\u001b[0m  |\u001b[92m     16140\u001b[0m  |\u001b[92m      8256\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       33     |\u001b[92m     50964\u001b[0m  |\u001b[92m     16420\u001b[0m  |\u001b[92m      7194\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       34     |\u001b[92m     49650\u001b[0m  |\u001b[92m     17009\u001b[0m  |\u001b[92m      7820\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       35     |\u001b[92m     49716\u001b[0m  |\u001b[92m     17134\u001b[0m  |\u001b[92m      8120\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       36     |\u001b[92m     51787\u001b[0m  |\u001b[92m     17210\u001b[0m  |\u001b[92m      8676\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       37     |\u001b[92m     70629\u001b[0m  |\u001b[92m     17795\u001b[0m  |\u001b[92m      7918\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       38     |\u001b[92m     53891\u001b[0m  |\u001b[92m     17795\u001b[0m  |\u001b[92m      9082\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       39     |\u001b[92m     56057\u001b[0m  |\u001b[92m     17977\u001b[0m  |\u001b[92m      7839\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       40     |\u001b[92m     54119\u001b[0m  |\u001b[92m     18070\u001b[0m  |\u001b[92m      7840\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       41     |\u001b[92m     65038\u001b[0m  |\u001b[92m     17931\u001b[0m  |\u001b[92m      7011\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       42     |\u001b[92m     51810\u001b[0m  |\u001b[92m     17950\u001b[0m  |\u001b[92m      6720\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       43     |\u001b[92m     51394\u001b[0m  |\u001b[92m     17986\u001b[0m  |\u001b[92m      7181\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       44     |\u001b[92m     50925\u001b[0m  |\u001b[92m     17933\u001b[0m  |\u001b[92m      6908\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       45     |\u001b[92m     57664\u001b[0m  |\u001b[92m     18298\u001b[0m  |\u001b[92m      5625\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       46     |\u001b[92m     51225\u001b[0m  |\u001b[92m     17741\u001b[0m  |\u001b[92m      5658\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       47     |\u001b[92m     51046\u001b[0m  |\u001b[92m     17749\u001b[0m  |\u001b[92m      5264\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       48     |\u001b[92m     50385\u001b[0m  |\u001b[92m     17278\u001b[0m  |\u001b[92m      4992\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       49     |\u001b[92m     49392\u001b[0m  |\u001b[92m     16572\u001b[0m  |\u001b[92m      5047\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       50     |\u001b[92m     46214\u001b[0m  |\u001b[92m     15770\u001b[0m  |\u001b[92m      5400\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       51     |\u001b[92m     46332\u001b[0m  |\u001b[92m     14866\u001b[0m  |\u001b[92m      3927\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       52     |\u001b[92m     44949\u001b[0m  |\u001b[92m     13970\u001b[0m  |\u001b[92m      3536\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       53     |\u001b[92m     44375\u001b[0m  |\u001b[92m     13137\u001b[0m  |\u001b[92m      3551\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       54     |\u001b[92m     43484\u001b[0m  |\u001b[92m     12542\u001b[0m  |\u001b[92m      3132\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       55     |\u001b[92m     42800\u001b[0m  |\u001b[92m     12284\u001b[0m  |\u001b[92m      3355\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       56     |\u001b[92m     42058\u001b[0m  |\u001b[92m     12039\u001b[0m  |\u001b[92m      2520\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       57     |\u001b[92m     41936\u001b[0m  |\u001b[92m     11799\u001b[0m  |\u001b[92m      2736\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       58     |\u001b[92m     40812\u001b[0m  |\u001b[92m     11425\u001b[0m  |\u001b[91m      2204\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       59     |\u001b[92m     40106\u001b[0m  |\u001b[92m     11073\u001b[0m  |\u001b[91m      2419\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       60     |\u001b[92m     38351\u001b[0m  |\u001b[92m     10695\u001b[0m  |\u001b[91m      2160\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       61     |\u001b[92m     37603\u001b[0m  |\u001b[92m     10646\u001b[0m  |\u001b[91m      2196\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       62     |\u001b[92m     36196\u001b[0m  |\u001b[92m     10318\u001b[0m  |\u001b[91m      1488\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       63     |\u001b[92m     35942\u001b[0m  |\u001b[92m     10443\u001b[0m  |\u001b[91m      1449\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       64     |\u001b[92m     35214\u001b[0m  |\u001b[92m     10060\u001b[0m  |\u001b[91m      1088\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       65     |\u001b[92m     34320\u001b[0m  |\u001b[92m      9594\u001b[0m  |\u001b[91m      1430\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       66     |\u001b[92m     33294\u001b[0m  |\u001b[92m      9270\u001b[0m  |\u001b[91m       858\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       67     |\u001b[92m     32347\u001b[0m  |\u001b[92m      8940\u001b[0m  |\u001b[91m       737\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       68     |\u001b[92m     31465\u001b[0m  |\u001b[92m      8805\u001b[0m  |\u001b[91m       748\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       69     |\u001b[92m     30638\u001b[0m  |\u001b[92m      8335\u001b[0m  |\u001b[91m       483\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       70     |\u001b[92m     29708\u001b[0m  |\u001b[92m      8165\u001b[0m  |\u001b[91m       980\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       71     |\u001b[92m     29265\u001b[0m  |\u001b[92m      7836\u001b[0m  |\u001b[91m       284\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       72     |\u001b[92m     28381\u001b[0m  |\u001b[92m      7576\u001b[0m  |\u001b[91m       360\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       73     |\u001b[92m     27783\u001b[0m  |\u001b[92m      7037\u001b[0m  |\u001b[91m       219\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       74     |\u001b[92m     26776\u001b[0m  |\u001b[92m      6909\u001b[0m  |\u001b[91m       296\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       75     |\u001b[92m     26149\u001b[0m  |\u001b[92m      6459\u001b[0m  |\u001b[91m       150\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       76     |\u001b[92m     24780\u001b[0m  |\u001b[92m      6173\u001b[0m  |\u001b[91m        76\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       77     |\u001b[92m     24794\u001b[0m  |\u001b[92m      5922\u001b[0m  |\u001b[91m       154\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       78     |\u001b[92m     23986\u001b[0m  |\u001b[92m      5620\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       79     |\u001b[92m     23084\u001b[0m  |\u001b[92m      5408\u001b[0m  |\u001b[91m        79\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       80     |\u001b[92m     22558\u001b[0m  |\u001b[92m      5229\u001b[0m  |\u001b[91m        80\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       81     |\u001b[92m     21775\u001b[0m  |\u001b[92m      4845\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       82     |\u001b[92m     21755\u001b[0m  |\u001b[91m      4474\u001b[0m  |\u001b[91m        82\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       83     |\u001b[92m     20592\u001b[0m  |\u001b[91m      4427\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       84     |\u001b[92m     20403\u001b[0m  |\u001b[91m      4095\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       85     |\u001b[92m     19659\u001b[0m  |\u001b[91m      3877\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       86     |\u001b[92m     19188\u001b[0m  |\u001b[91m      3590\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       87     |\u001b[92m     18727\u001b[0m  |\u001b[91m      3491\u001b[0m  |\u001b[91m        87\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       88     |\u001b[92m     18082\u001b[0m  |\u001b[91m      3308\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       89     |\u001b[92m     17612\u001b[0m  |\u001b[91m      3094\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       90     |\u001b[92m     17103\u001b[0m  |\u001b[91m      2848\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       91     |\u001b[92m     16837\u001b[0m  |\u001b[91m      2831\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       92     |\u001b[92m     16235\u001b[0m  |\u001b[91m      2646\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       93     |\u001b[92m     15651\u001b[0m  |\u001b[91m      2551\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       94     |\u001b[92m     14960\u001b[0m  |\u001b[91m      2423\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       95     |\u001b[92m     15060\u001b[0m  |\u001b[91m      2243\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       96     |\u001b[92m     14441\u001b[0m  |\u001b[91m      2075\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       97     |\u001b[92m     14223\u001b[0m  |\u001b[91m      1937\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       98     |\u001b[92m     13907\u001b[0m  |\u001b[91m      1912\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "       99     |\u001b[92m     13355\u001b[0m  |\u001b[91m      1768\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      100     |\u001b[92m     13124\u001b[0m  |\u001b[91m      1668\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      101     |\u001b[92m     12753\u001b[0m  |\u001b[91m      1625\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      102     |\u001b[92m     12390\u001b[0m  |\u001b[91m      1548\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      103     |\u001b[92m     12186\u001b[0m  |\u001b[91m      1422\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      104     |\u001b[92m     11703\u001b[0m  |\u001b[91m      1294\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      105     |\u001b[92m     11441\u001b[0m  |\u001b[91m      1200\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      106     |\u001b[92m     11010\u001b[0m  |\u001b[91m      1190\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      107     |\u001b[92m     10862\u001b[0m  |\u001b[91m      1138\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      108     |\u001b[92m     10559\u001b[0m  |\u001b[91m      1104\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      109     |\u001b[92m     10297\u001b[0m  |\u001b[91m       972\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      110     |\u001b[91m     10103\u001b[0m  |\u001b[91m       936\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      111     |\u001b[91m      9596\u001b[0m  |\u001b[91m       859\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      112     |\u001b[91m      9454\u001b[0m  |\u001b[91m       811\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      113     |\u001b[91m      9201\u001b[0m  |\u001b[91m       725\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      114     |\u001b[91m      8957\u001b[0m  |\u001b[91m       690\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      115     |\u001b[91m      8725\u001b[0m  |\u001b[91m       705\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      116     |\u001b[91m      8614\u001b[0m  |\u001b[91m       615\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      117     |\u001b[91m      8366\u001b[0m  |\u001b[91m       626\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      118     |\u001b[91m      8183\u001b[0m  |\u001b[91m       547\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      119     |\u001b[91m      7661\u001b[0m  |\u001b[91m       518\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      120     |\u001b[91m      7602\u001b[0m  |\u001b[91m       472\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      121     |\u001b[91m      7337\u001b[0m  |\u001b[91m       416\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      122     |\u001b[91m      7092\u001b[0m  |\u001b[91m       393\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      123     |\u001b[91m      6960\u001b[0m  |\u001b[91m       392\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      124     |\u001b[91m      6915\u001b[0m  |\u001b[91m       363\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      125     |\u001b[91m      6513\u001b[0m  |\u001b[91m       322\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      126     |\u001b[91m      6469\u001b[0m  |\u001b[91m       300\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      127     |\u001b[91m      6176\u001b[0m  |\u001b[91m       319\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      128     |\u001b[91m      5984\u001b[0m  |\u001b[91m       285\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      129     |\u001b[91m      5897\u001b[0m  |\u001b[91m       237\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      130     |\u001b[91m      5680\u001b[0m  |\u001b[91m       264\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      131     |\u001b[91m      5551\u001b[0m  |\u001b[91m       244\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      132     |\u001b[91m      5150\u001b[0m  |\u001b[91m       198\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      133     |\u001b[91m      5228\u001b[0m  |\u001b[91m       207\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      134     |\u001b[91m      5017\u001b[0m  |\u001b[91m       182\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      135     |\u001b[91m      4866\u001b[0m  |\u001b[91m       142\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      136     |\u001b[91m      4709\u001b[0m  |\u001b[91m       146\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      137     |\u001b[91m      4579\u001b[0m  |\u001b[91m       133\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      138     |\u001b[91m      4608\u001b[0m  |\u001b[91m       129\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      139     |\u001b[91m      4371\u001b[0m  |\u001b[91m       129\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      140     |\u001b[91m      4163\u001b[0m  |\u001b[91m       104\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      141     |\u001b[91m      4056\u001b[0m  |\u001b[91m       102\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      142     |\u001b[91m      3869\u001b[0m  |\u001b[91m        72\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      143     |\u001b[91m      3793\u001b[0m  |\u001b[91m       108\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      144     |\u001b[91m      3764\u001b[0m  |\u001b[91m        83\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      145     |\u001b[91m      3525\u001b[0m  |\u001b[91m        61\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      146     |\u001b[91m      3469\u001b[0m  |\u001b[91m        54\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      147     |\u001b[91m      3378\u001b[0m  |\u001b[91m        53\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      148     |\u001b[91m      3227\u001b[0m  |\u001b[91m        56\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      149     |\u001b[91m      3057\u001b[0m  |\u001b[91m        50\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      150     |\u001b[91m      2982\u001b[0m  |\u001b[91m        42\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      151     |\u001b[91m      2888\u001b[0m  |\u001b[91m        37\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      152     |\u001b[91m      2818\u001b[0m  |\u001b[91m        45\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      153     |\u001b[91m      2667\u001b[0m  |\u001b[91m        32\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      154     |\u001b[91m      2467\u001b[0m  |\u001b[91m        27\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      155     |\u001b[91m      2383\u001b[0m  |\u001b[91m        30\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      156     |\u001b[91m      2360\u001b[0m  |\u001b[91m        24\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      157     |\u001b[91m      2360\u001b[0m  |\u001b[91m        22\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      158     |\u001b[91m      2209\u001b[0m  |\u001b[91m        20\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      159     |\u001b[91m      2029\u001b[0m  |\u001b[91m        16\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      160     |\u001b[91m      2102\u001b[0m  |\u001b[91m        17\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      161     |\u001b[91m      2019\u001b[0m  |\u001b[91m        11\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      162     |\u001b[91m      1863\u001b[0m  |\u001b[91m        12\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      163     |\u001b[91m      1831\u001b[0m  |\u001b[91m         5\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      164     |\u001b[91m      1760\u001b[0m  |\u001b[91m         7\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      165     |\u001b[91m      1634\u001b[0m  |\u001b[91m        10\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      166     |\u001b[91m      1600\u001b[0m  |\u001b[91m         9\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      167     |\u001b[91m      1540\u001b[0m  |\u001b[91m         6\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      168     |\u001b[91m      1431\u001b[0m  |\u001b[91m         6\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      169     |\u001b[91m      1492\u001b[0m  |\u001b[91m         2\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      170     |\u001b[91m      1435\u001b[0m  |\u001b[91m         4\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      171     |\u001b[91m      1301\u001b[0m  |\u001b[91m         4\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      172     |\u001b[91m      1199\u001b[0m  |\u001b[91m         3\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      173     |\u001b[91m      1205\u001b[0m  |\u001b[91m         2\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      174     |\u001b[91m      1132\u001b[0m  |\u001b[91m         1\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      175     |\u001b[91m      1093\u001b[0m  |\u001b[91m         1\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      176     |\u001b[91m      1062\u001b[0m  |\u001b[91m         1\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      177     |\u001b[91m      1038\u001b[0m  |\u001b[91m         1\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      178     |\u001b[91m      1023\u001b[0m  |\u001b[91m         1\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      179     |\u001b[91m       943\u001b[0m  |\u001b[91m         1\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      180     |\u001b[91m       961\u001b[0m  |\u001b[91m         1\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      181     |\u001b[91m       907\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      182     |\u001b[91m       842\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      183     |\u001b[91m       794\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      184     |\u001b[91m       769\u001b[0m  |\u001b[91m         1\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      185     |\u001b[91m       737\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      186     |\u001b[91m       690\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      187     |\u001b[91m       700\u001b[0m  |\u001b[91m         1\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      188     |\u001b[91m       617\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      189     |\u001b[91m       612\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      190     |\u001b[91m       595\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      191     |\u001b[91m       551\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      192     |\u001b[91m       516\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      193     |\u001b[91m       520\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      194     |\u001b[91m       483\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      195     |\u001b[91m       444\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      196     |\u001b[91m       464\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      197     |\u001b[91m       383\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      198     |\u001b[91m       374\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      199     |\u001b[91m       379\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      200     |\u001b[91m       352\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      201     |\u001b[91m       326\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      202     |\u001b[91m       280\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      203     |\u001b[91m       279\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      204     |\u001b[91m       254\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      205     |\u001b[91m       262\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      206     |\u001b[91m       244\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      207     |\u001b[91m       230\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      208     |\u001b[91m       223\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      209     |\u001b[91m       196\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      210     |\u001b[91m       186\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      211     |\u001b[91m       204\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      212     |\u001b[91m       162\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      213     |\u001b[91m       172\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      214     |\u001b[91m       174\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      215     |\u001b[91m       141\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      216     |\u001b[91m       133\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      217     |\u001b[91m       135\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      218     |\u001b[91m       129\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      219     |\u001b[91m       133\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      220     |\u001b[91m       108\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      221     |\u001b[91m       115\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      222     |\u001b[91m       107\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      223     |\u001b[91m        89\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      224     |\u001b[91m        95\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      225     |\u001b[91m        83\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      226     |\u001b[91m        89\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      227     |\u001b[91m        78\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      228     |\u001b[91m        70\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      229     |\u001b[91m        64\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      230     |\u001b[91m        63\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      231     |\u001b[91m        56\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      232     |\u001b[91m        51\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      233     |\u001b[91m        65\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      234     |\u001b[91m        56\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      235     |\u001b[91m        54\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      236     |\u001b[91m        34\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      237     |\u001b[91m        43\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      238     |\u001b[91m        46\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      239     |\u001b[91m        33\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      240     |\u001b[91m        50\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      241     |\u001b[91m        29\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      242     |\u001b[91m        41\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      243     |\u001b[91m        32\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      244     |\u001b[91m        29\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      245     |\u001b[91m        31\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      246     |\u001b[91m        24\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      247     |\u001b[91m        19\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      248     |\u001b[91m        13\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      249     |\u001b[91m        18\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      250     |\u001b[91m        14\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      251     |\u001b[91m        19\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      252     |\u001b[91m        11\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      253     |\u001b[91m        13\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      254     |\u001b[91m         8\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      255     |\u001b[91m        13\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      256     |\u001b[91m        11\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      257     |\u001b[91m        12\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      258     |\u001b[91m         2\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      259     |\u001b[91m         4\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      260     |\u001b[91m        10\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      261     |\u001b[91m        14\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      262     |\u001b[91m         6\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      263     |\u001b[91m         3\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      264     |\u001b[91m         1\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      265     |\u001b[91m         5\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      266     |\u001b[91m         4\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      267     |\u001b[91m         4\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      268     |\u001b[91m         5\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      269     |\u001b[91m         2\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      270     |\u001b[91m         7\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      271     |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      272     |\u001b[91m         1\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      273     |\u001b[91m         1\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      274     |\u001b[91m         2\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      275     |\u001b[91m         1\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      276     |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      277     |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      278     |\u001b[91m         1\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      279     |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      280     |\u001b[91m         1\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "      281     |\u001b[91m         1\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  |\u001b[91m         0\u001b[0m  \n",
      "\n",
      "**************************************************\n",
      "\n",
      "\n",
      "chosen neighbors limits:  [109  81  57  17   7]\n",
      "\n",
      "Calibration done in 33.0s\n",
      "\n",
      "\n",
      "Starting Calibration (use verbose=True for more details)\n",
      "\n",
      "Previous calibration found:\n",
      "Check batch limit dictionary\n",
      "\u001b[92m\"potentials_15.000_1.500_6\": 6501\u001b[0m\n",
      "Check neighbors limit dictionary\n",
      "\u001b[92m\"1.500_5.250\": 109\u001b[0m\n",
      "\u001b[92m\"3.000_10.500\": 81\u001b[0m\n",
      "\u001b[92m\"6.000_48.000\": 57\u001b[0m\n",
      "\u001b[92m\"12.000_96.000\": 17\u001b[0m\n",
      "\u001b[92m\"24.000_192.000\": 7\u001b[0m\n",
      "Calibration done in 0.0s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calibrate samplers\n",
    "training_sampler.calibration(training_loader, verbose=True)\n",
    "test_sampler.calibration(test_loader, verbose=True)\n",
    "\n",
    "# Optional debug functions\n",
    "# debug_timing(training_dataset, training_loader)\n",
    "# debug_timing(test_dataset, test_loader)\n",
    "# debug_upsampling(training_dataset, training_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Preparation\n",
      "*****************\n",
      "encoder_blocks is calculated as ModuleList(\n",
      "  (0): SimpleBlock(\n",
      "    (KPConv): KPConv(radius: 5.25, in_feat: 5, out_feat: 64)\n",
      "    (batch_norm): BatchNormBlock(in_feat: 64, momentum: 0.020, only_bias: False)\n",
      "    (leaky_relu): LeakyReLU(negative_slope=0.1)\n",
      "  )\n",
      "  (1): ResnetBottleneckBlock(\n",
      "    (unary1): UnaryBlock(in_feat: 64, out_feat: 32, BN: True, ReLU: True)\n",
      "    (KPConv): KPConv(radius: 5.25, in_feat: 32, out_feat: 32)\n",
      "    (batch_norm_conv): BatchNormBlock(in_feat: 32, momentum: 0.020, only_bias: False)\n",
      "    (unary2): UnaryBlock(in_feat: 32, out_feat: 128, BN: True, ReLU: False)\n",
      "    (unary_shortcut): UnaryBlock(in_feat: 64, out_feat: 128, BN: True, ReLU: False)\n",
      "    (leaky_relu): LeakyReLU(negative_slope=0.1)\n",
      "  )\n",
      "  (2): ResnetBottleneckBlock(\n",
      "    (unary1): UnaryBlock(in_feat: 128, out_feat: 32, BN: True, ReLU: True)\n",
      "    (KPConv): KPConv(radius: 5.25, in_feat: 32, out_feat: 32)\n",
      "    (batch_norm_conv): BatchNormBlock(in_feat: 32, momentum: 0.020, only_bias: False)\n",
      "    (unary2): UnaryBlock(in_feat: 32, out_feat: 128, BN: True, ReLU: False)\n",
      "    (unary_shortcut): Identity()\n",
      "    (leaky_relu): LeakyReLU(negative_slope=0.1)\n",
      "  )\n",
      "  (3): ResnetBottleneckBlock(\n",
      "    (unary1): UnaryBlock(in_feat: 128, out_feat: 64, BN: True, ReLU: True)\n",
      "    (KPConv): KPConv(radius: 10.50, in_feat: 64, out_feat: 64)\n",
      "    (batch_norm_conv): BatchNormBlock(in_feat: 64, momentum: 0.020, only_bias: False)\n",
      "    (unary2): UnaryBlock(in_feat: 64, out_feat: 256, BN: True, ReLU: False)\n",
      "    (unary_shortcut): UnaryBlock(in_feat: 128, out_feat: 256, BN: True, ReLU: False)\n",
      "    (leaky_relu): LeakyReLU(negative_slope=0.1)\n",
      "  )\n",
      "  (4): ResnetBottleneckBlock(\n",
      "    (unary1): UnaryBlock(in_feat: 256, out_feat: 64, BN: True, ReLU: True)\n",
      "    (KPConv): KPConv(radius: 10.50, in_feat: 64, out_feat: 64)\n",
      "    (batch_norm_conv): BatchNormBlock(in_feat: 64, momentum: 0.020, only_bias: False)\n",
      "    (unary2): UnaryBlock(in_feat: 64, out_feat: 256, BN: True, ReLU: False)\n",
      "    (unary_shortcut): Identity()\n",
      "    (leaky_relu): LeakyReLU(negative_slope=0.1)\n",
      "  )\n",
      "  (5): ResnetBottleneckBlock(\n",
      "    (unary1): UnaryBlock(in_feat: 256, out_feat: 64, BN: True, ReLU: True)\n",
      "    (KPConv): KPConv(radius: 10.50, in_feat: 64, out_feat: 64)\n",
      "    (batch_norm_conv): BatchNormBlock(in_feat: 64, momentum: 0.020, only_bias: False)\n",
      "    (unary2): UnaryBlock(in_feat: 64, out_feat: 256, BN: True, ReLU: False)\n",
      "    (unary_shortcut): Identity()\n",
      "    (leaky_relu): LeakyReLU(negative_slope=0.1)\n",
      "  )\n",
      "  (6): ResnetBottleneckBlock(\n",
      "    (unary1): UnaryBlock(in_feat: 256, out_feat: 128, BN: True, ReLU: True)\n",
      "    (KPConv): KPConv(radius: 21.00, in_feat: 128, out_feat: 128)\n",
      "    (batch_norm_conv): BatchNormBlock(in_feat: 128, momentum: 0.020, only_bias: False)\n",
      "    (unary2): UnaryBlock(in_feat: 128, out_feat: 512, BN: True, ReLU: False)\n",
      "    (unary_shortcut): UnaryBlock(in_feat: 256, out_feat: 512, BN: True, ReLU: False)\n",
      "    (leaky_relu): LeakyReLU(negative_slope=0.1)\n",
      "  )\n",
      "  (7): ResnetBottleneckBlock(\n",
      "    (unary1): UnaryBlock(in_feat: 512, out_feat: 128, BN: True, ReLU: True)\n",
      "    (KPConv): KPConv(radius: 21.00, in_feat: 128, out_feat: 128)\n",
      "    (batch_norm_conv): BatchNormBlock(in_feat: 128, momentum: 0.020, only_bias: False)\n",
      "    (unary2): UnaryBlock(in_feat: 128, out_feat: 512, BN: True, ReLU: False)\n",
      "    (unary_shortcut): Identity()\n",
      "    (leaky_relu): LeakyReLU(negative_slope=0.1)\n",
      "  )\n",
      "  (8): ResnetBottleneckBlock(\n",
      "    (unary1): UnaryBlock(in_feat: 512, out_feat: 128, BN: True, ReLU: True)\n",
      "    (KPConv): KPConv(radius: 21.00, in_feat: 128, out_feat: 128)\n",
      "    (batch_norm_conv): BatchNormBlock(in_feat: 128, momentum: 0.020, only_bias: False)\n",
      "    (unary2): UnaryBlock(in_feat: 128, out_feat: 512, BN: True, ReLU: False)\n",
      "    (unary_shortcut): Identity()\n",
      "    (leaky_relu): LeakyReLU(negative_slope=0.1)\n",
      "  )\n",
      "  (9): ResnetBottleneckBlock(\n",
      "    (unary1): UnaryBlock(in_feat: 512, out_feat: 256, BN: True, ReLU: True)\n",
      "    (KPConv): KPConv(radius: 42.00, in_feat: 256, out_feat: 256)\n",
      "    (batch_norm_conv): BatchNormBlock(in_feat: 256, momentum: 0.020, only_bias: False)\n",
      "    (unary2): UnaryBlock(in_feat: 256, out_feat: 1024, BN: True, ReLU: False)\n",
      "    (unary_shortcut): UnaryBlock(in_feat: 512, out_feat: 1024, BN: True, ReLU: False)\n",
      "    (leaky_relu): LeakyReLU(negative_slope=0.1)\n",
      "  )\n",
      "  (10): ResnetBottleneckBlock(\n",
      "    (unary1): UnaryBlock(in_feat: 1024, out_feat: 256, BN: True, ReLU: True)\n",
      "    (KPConv): KPConv(radius: 42.00, in_feat: 256, out_feat: 256)\n",
      "    (batch_norm_conv): BatchNormBlock(in_feat: 256, momentum: 0.020, only_bias: False)\n",
      "    (unary2): UnaryBlock(in_feat: 256, out_feat: 1024, BN: True, ReLU: False)\n",
      "    (unary_shortcut): Identity()\n",
      "    (leaky_relu): LeakyReLU(negative_slope=0.1)\n",
      "  )\n",
      "  (11): ResnetBottleneckBlock(\n",
      "    (unary1): UnaryBlock(in_feat: 1024, out_feat: 256, BN: True, ReLU: True)\n",
      "    (KPConv): KPConv(radius: 42.00, in_feat: 256, out_feat: 256)\n",
      "    (batch_norm_conv): BatchNormBlock(in_feat: 256, momentum: 0.020, only_bias: False)\n",
      "    (unary2): UnaryBlock(in_feat: 256, out_feat: 1024, BN: True, ReLU: False)\n",
      "    (unary_shortcut): Identity()\n",
      "    (leaky_relu): LeakyReLU(negative_slope=0.1)\n",
      "  )\n",
      "  (12): ResnetBottleneckBlock(\n",
      "    (unary1): UnaryBlock(in_feat: 1024, out_feat: 512, BN: True, ReLU: True)\n",
      "    (KPConv): KPConv(radius: 84.00, in_feat: 512, out_feat: 512)\n",
      "    (batch_norm_conv): BatchNormBlock(in_feat: 512, momentum: 0.020, only_bias: False)\n",
      "    (unary2): UnaryBlock(in_feat: 512, out_feat: 2048, BN: True, ReLU: False)\n",
      "    (unary_shortcut): UnaryBlock(in_feat: 1024, out_feat: 2048, BN: True, ReLU: False)\n",
      "    (leaky_relu): LeakyReLU(negative_slope=0.1)\n",
      "  )\n",
      "  (13): ResnetBottleneckBlock(\n",
      "    (unary1): UnaryBlock(in_feat: 2048, out_feat: 512, BN: True, ReLU: True)\n",
      "    (KPConv): KPConv(radius: 84.00, in_feat: 512, out_feat: 512)\n",
      "    (batch_norm_conv): BatchNormBlock(in_feat: 512, momentum: 0.020, only_bias: False)\n",
      "    (unary2): UnaryBlock(in_feat: 512, out_feat: 2048, BN: True, ReLU: False)\n",
      "    (unary_shortcut): Identity()\n",
      "    (leaky_relu): LeakyReLU(negative_slope=0.1)\n",
      "  )\n",
      ")\n",
      "layer after encoder is 4\n",
      "r after encoder is 84.0\n",
      "out_dim after encoder is 2048\n",
      "decoder.blocks is ModuleList(\n",
      "  (0): NearestUpsampleBlock(layer: 4 -> 3)\n",
      "  (1): UnaryBlock(in_feat: 3072, out_feat: 1024, BN: True, ReLU: True)\n",
      "  (2): NearestUpsampleBlock(layer: 3 -> 2)\n",
      "  (3): UnaryBlock(in_feat: 1536, out_feat: 512, BN: True, ReLU: True)\n",
      "  (4): NearestUpsampleBlock(layer: 2 -> 1)\n",
      "  (5): UnaryBlock(in_feat: 768, out_feat: 256, BN: True, ReLU: True)\n",
      "  (6): NearestUpsampleBlock(layer: 1 -> 0)\n",
      "  (7): UnaryBlock(in_feat: 384, out_feat: 128, BN: True, ReLU: True)\n",
      ")\n",
      "layer after decoder is 0\n",
      "r after decoder is 5.25\n",
      "out_dim after decoder is 128\n",
      "Initialized the following KPFCNN architecture KPFCNN(\n",
      "  (encoder_blocks): ModuleList(\n",
      "    (0): SimpleBlock(\n",
      "      (KPConv): KPConv(radius: 5.25, in_feat: 5, out_feat: 64)\n",
      "      (batch_norm): BatchNormBlock(in_feat: 64, momentum: 0.020, only_bias: False)\n",
      "      (leaky_relu): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (1): ResnetBottleneckBlock(\n",
      "      (unary1): UnaryBlock(in_feat: 64, out_feat: 32, BN: True, ReLU: True)\n",
      "      (KPConv): KPConv(radius: 5.25, in_feat: 32, out_feat: 32)\n",
      "      (batch_norm_conv): BatchNormBlock(in_feat: 32, momentum: 0.020, only_bias: False)\n",
      "      (unary2): UnaryBlock(in_feat: 32, out_feat: 128, BN: True, ReLU: False)\n",
      "      (unary_shortcut): UnaryBlock(in_feat: 64, out_feat: 128, BN: True, ReLU: False)\n",
      "      (leaky_relu): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (2): ResnetBottleneckBlock(\n",
      "      (unary1): UnaryBlock(in_feat: 128, out_feat: 32, BN: True, ReLU: True)\n",
      "      (KPConv): KPConv(radius: 5.25, in_feat: 32, out_feat: 32)\n",
      "      (batch_norm_conv): BatchNormBlock(in_feat: 32, momentum: 0.020, only_bias: False)\n",
      "      (unary2): UnaryBlock(in_feat: 32, out_feat: 128, BN: True, ReLU: False)\n",
      "      (unary_shortcut): Identity()\n",
      "      (leaky_relu): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (3): ResnetBottleneckBlock(\n",
      "      (unary1): UnaryBlock(in_feat: 128, out_feat: 64, BN: True, ReLU: True)\n",
      "      (KPConv): KPConv(radius: 10.50, in_feat: 64, out_feat: 64)\n",
      "      (batch_norm_conv): BatchNormBlock(in_feat: 64, momentum: 0.020, only_bias: False)\n",
      "      (unary2): UnaryBlock(in_feat: 64, out_feat: 256, BN: True, ReLU: False)\n",
      "      (unary_shortcut): UnaryBlock(in_feat: 128, out_feat: 256, BN: True, ReLU: False)\n",
      "      (leaky_relu): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (4): ResnetBottleneckBlock(\n",
      "      (unary1): UnaryBlock(in_feat: 256, out_feat: 64, BN: True, ReLU: True)\n",
      "      (KPConv): KPConv(radius: 10.50, in_feat: 64, out_feat: 64)\n",
      "      (batch_norm_conv): BatchNormBlock(in_feat: 64, momentum: 0.020, only_bias: False)\n",
      "      (unary2): UnaryBlock(in_feat: 64, out_feat: 256, BN: True, ReLU: False)\n",
      "      (unary_shortcut): Identity()\n",
      "      (leaky_relu): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (5): ResnetBottleneckBlock(\n",
      "      (unary1): UnaryBlock(in_feat: 256, out_feat: 64, BN: True, ReLU: True)\n",
      "      (KPConv): KPConv(radius: 10.50, in_feat: 64, out_feat: 64)\n",
      "      (batch_norm_conv): BatchNormBlock(in_feat: 64, momentum: 0.020, only_bias: False)\n",
      "      (unary2): UnaryBlock(in_feat: 64, out_feat: 256, BN: True, ReLU: False)\n",
      "      (unary_shortcut): Identity()\n",
      "      (leaky_relu): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (6): ResnetBottleneckBlock(\n",
      "      (unary1): UnaryBlock(in_feat: 256, out_feat: 128, BN: True, ReLU: True)\n",
      "      (KPConv): KPConv(radius: 21.00, in_feat: 128, out_feat: 128)\n",
      "      (batch_norm_conv): BatchNormBlock(in_feat: 128, momentum: 0.020, only_bias: False)\n",
      "      (unary2): UnaryBlock(in_feat: 128, out_feat: 512, BN: True, ReLU: False)\n",
      "      (unary_shortcut): UnaryBlock(in_feat: 256, out_feat: 512, BN: True, ReLU: False)\n",
      "      (leaky_relu): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (7): ResnetBottleneckBlock(\n",
      "      (unary1): UnaryBlock(in_feat: 512, out_feat: 128, BN: True, ReLU: True)\n",
      "      (KPConv): KPConv(radius: 21.00, in_feat: 128, out_feat: 128)\n",
      "      (batch_norm_conv): BatchNormBlock(in_feat: 128, momentum: 0.020, only_bias: False)\n",
      "      (unary2): UnaryBlock(in_feat: 128, out_feat: 512, BN: True, ReLU: False)\n",
      "      (unary_shortcut): Identity()\n",
      "      (leaky_relu): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (8): ResnetBottleneckBlock(\n",
      "      (unary1): UnaryBlock(in_feat: 512, out_feat: 128, BN: True, ReLU: True)\n",
      "      (KPConv): KPConv(radius: 21.00, in_feat: 128, out_feat: 128)\n",
      "      (batch_norm_conv): BatchNormBlock(in_feat: 128, momentum: 0.020, only_bias: False)\n",
      "      (unary2): UnaryBlock(in_feat: 128, out_feat: 512, BN: True, ReLU: False)\n",
      "      (unary_shortcut): Identity()\n",
      "      (leaky_relu): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (9): ResnetBottleneckBlock(\n",
      "      (unary1): UnaryBlock(in_feat: 512, out_feat: 256, BN: True, ReLU: True)\n",
      "      (KPConv): KPConv(radius: 42.00, in_feat: 256, out_feat: 256)\n",
      "      (batch_norm_conv): BatchNormBlock(in_feat: 256, momentum: 0.020, only_bias: False)\n",
      "      (unary2): UnaryBlock(in_feat: 256, out_feat: 1024, BN: True, ReLU: False)\n",
      "      (unary_shortcut): UnaryBlock(in_feat: 512, out_feat: 1024, BN: True, ReLU: False)\n",
      "      (leaky_relu): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (10): ResnetBottleneckBlock(\n",
      "      (unary1): UnaryBlock(in_feat: 1024, out_feat: 256, BN: True, ReLU: True)\n",
      "      (KPConv): KPConv(radius: 42.00, in_feat: 256, out_feat: 256)\n",
      "      (batch_norm_conv): BatchNormBlock(in_feat: 256, momentum: 0.020, only_bias: False)\n",
      "      (unary2): UnaryBlock(in_feat: 256, out_feat: 1024, BN: True, ReLU: False)\n",
      "      (unary_shortcut): Identity()\n",
      "      (leaky_relu): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (11): ResnetBottleneckBlock(\n",
      "      (unary1): UnaryBlock(in_feat: 1024, out_feat: 256, BN: True, ReLU: True)\n",
      "      (KPConv): KPConv(radius: 42.00, in_feat: 256, out_feat: 256)\n",
      "      (batch_norm_conv): BatchNormBlock(in_feat: 256, momentum: 0.020, only_bias: False)\n",
      "      (unary2): UnaryBlock(in_feat: 256, out_feat: 1024, BN: True, ReLU: False)\n",
      "      (unary_shortcut): Identity()\n",
      "      (leaky_relu): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (12): ResnetBottleneckBlock(\n",
      "      (unary1): UnaryBlock(in_feat: 1024, out_feat: 512, BN: True, ReLU: True)\n",
      "      (KPConv): KPConv(radius: 84.00, in_feat: 512, out_feat: 512)\n",
      "      (batch_norm_conv): BatchNormBlock(in_feat: 512, momentum: 0.020, only_bias: False)\n",
      "      (unary2): UnaryBlock(in_feat: 512, out_feat: 2048, BN: True, ReLU: False)\n",
      "      (unary_shortcut): UnaryBlock(in_feat: 1024, out_feat: 2048, BN: True, ReLU: False)\n",
      "      (leaky_relu): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (13): ResnetBottleneckBlock(\n",
      "      (unary1): UnaryBlock(in_feat: 2048, out_feat: 512, BN: True, ReLU: True)\n",
      "      (KPConv): KPConv(radius: 84.00, in_feat: 512, out_feat: 512)\n",
      "      (batch_norm_conv): BatchNormBlock(in_feat: 512, momentum: 0.020, only_bias: False)\n",
      "      (unary2): UnaryBlock(in_feat: 512, out_feat: 2048, BN: True, ReLU: False)\n",
      "      (unary_shortcut): Identity()\n",
      "      (leaky_relu): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "  )\n",
      "  (decoder_blocks): ModuleList(\n",
      "    (0): NearestUpsampleBlock(layer: 4 -> 3)\n",
      "    (1): UnaryBlock(in_feat: 3072, out_feat: 1024, BN: True, ReLU: True)\n",
      "    (2): NearestUpsampleBlock(layer: 3 -> 2)\n",
      "    (3): UnaryBlock(in_feat: 1536, out_feat: 512, BN: True, ReLU: True)\n",
      "    (4): NearestUpsampleBlock(layer: 2 -> 1)\n",
      "    (5): UnaryBlock(in_feat: 768, out_feat: 256, BN: True, ReLU: True)\n",
      "    (6): NearestUpsampleBlock(layer: 1 -> 0)\n",
      "    (7): UnaryBlock(in_feat: 384, out_feat: 128, BN: True, ReLU: True)\n",
      "  )\n",
      "  (head_mlp): UnaryBlock(in_feat: 128, out_feat: 128, BN: False, ReLU: True)\n",
      "  (head_softmax): UnaryBlock(in_feat: 128, out_feat: 9, BN: False, ReLU: True)\n",
      "  (criterion): CrossEntropyLoss()\n",
      "  (l1): L1Loss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print('\\nModel Preparation')\n",
    "print('*****************')\n",
    "\n",
    "# Define network model\n",
    "t1 = time.time()\n",
    "net = KPFCNN(config, training_dataset.label_values, training_dataset.ignored_labels)\n",
    "\n",
    "# debug = False\n",
    "# if debug:\n",
    "#     print('\\n*************************************\\n')\n",
    "#     print(net)\n",
    "#     print('\\n*************************************\\n')\n",
    "#     for param in net.parameters():\n",
    "#         if param.requires_grad:\n",
    "#             print(param.shape)\n",
    "#     print('\\n*************************************\\n')\n",
    "#     print(\"Model size %i\" % sum(param.numel() for param in net.parameters() if param.requires_grad))\n",
    "#     print('\\n*************************************\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done in 0.2s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define a trainer class\n",
    "trainer = ModelTrainer(net, config, chkp_path=chosen_chkp)\n",
    "print('Done in {:.1f}s\\n'.format(time.time() - t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start training\n",
      "**************\n",
      "self.output_loss= tensor(2.1841, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(33.6712, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e000-i0000 => L=35.855 acc=  7% / t(ms): 890.4 105.4 469.1)\n",
      "self.output_loss= tensor(2.1558, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(30.5097, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(2.0983, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(26.0375, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e000-i0002 => L=28.136 acc= 38% / t(ms):  13.4  86.6 403.0)\n",
      "self.output_loss= tensor(2.0316, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(23.1653, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(1.9633, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(22.8022, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(1.8431, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(21.5865, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e000-i0005 => L=23.430 acc= 53% / t(ms):  11.1  82.7 410.0)\n",
      "self.output_loss= tensor(1.6207, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(20.8731, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(1.5648, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(20.5913, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(1.0934, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(21.2828, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e000-i0008 => L=22.376 acc= 34% / t(ms):   9.5  82.6 401.1)\n",
      "self.output_loss= tensor(1.1711, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(20.9667, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(1.1337, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(21.6065, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e000-i0010 => L=22.740 acc= 40% / t(ms):  10.0  85.3 404.3)\n",
      "self.output_loss= tensor(0.9706, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(19.0456, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.7008, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(22.2748, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.6840, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(21.4011, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e000-i0013 => L=22.085 acc= 52% / t(ms):   8.6  81.7 403.4)\n",
      "self.output_loss= tensor(1.0318, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(24.6767, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.5850, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(23.1907, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.8298, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(23.4604, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e000-i0016 => L=24.290 acc= 45% / t(ms):   8.0  78.8 397.1)\n",
      "self.output_loss= tensor(1.1480, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(21.1046, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.9008, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(22.4065, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.3955, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(22.3794, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e000-i0019 => L=22.775 acc= 55% / t(ms):   7.2  76.8 392.0)\n",
      "self.output_loss= tensor(0.3872, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(20.3785, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(1.2434, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(18.6468, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.4554, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(19.6775, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e000-i0022 => L=20.133 acc= 34% / t(ms):   6.6  75.2 376.7)\n",
      "self.output_loss= tensor(0.8733, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(21.8326, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.4423, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(17.3743, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.3340, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(18.8658, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e000-i0025 => L=19.200 acc= 59% / t(ms):   6.0  74.2 365.5)\n",
      "self.output_loss= tensor(0.4470, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(23.3702, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.4244, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(21.9865, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e000-i0027 => L=22.411 acc= 59% / t(ms):   5.8  73.8 377.4)\n",
      "self.output_loss= tensor(0.5557, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(23.4678, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.5409, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(24.0318, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.4487, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(29.8921, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e000-i0030 => L=30.341 acc= 41% / t(ms):   5.7  73.0 368.5)\n",
      "self.output_loss= tensor(0.3407, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(28.8446, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2289, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(26.1291, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2889, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(26.0722, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e000-i0033 => L=26.361 acc= 60% / t(ms):   5.5  72.5 366.7)\n",
      "self.output_loss= tensor(0.3166, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(25.5581, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2590, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(25.2974, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.4120, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(24.2702, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e000-i0036 => L=24.682 acc= 46% / t(ms):   5.2  72.1 374.9)\n",
      "self.output_loss= tensor(0.2602, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(24.7732, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1110, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(23.6705, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2629, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(25.4293, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e000-i0039 => L=25.692 acc= 45% / t(ms):   5.4  71.8 374.2)\n",
      "self.output_loss= tensor(0.1576, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(22.4441, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.7134, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(22.2582, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.4474, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(22.6931, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e000-i0042 => L=23.141 acc= 47% / t(ms):   5.3  71.6 376.6)\n",
      "self.output_loss= tensor(0.2591, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(21.5058, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.4676, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(23.6345, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1292, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(22.7449, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e000-i0045 => L=22.874 acc= 66% / t(ms):   5.0  71.4 374.4)\n",
      "self.output_loss= tensor(0.1257, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(21.8630, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.3892, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(21.0358, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.3438, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(19.2134, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e000-i0048 => L=19.557 acc= 39% / t(ms):   5.0  71.2 361.9)\n",
      "self.output_loss= tensor(0.1772, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(19.0168, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1854, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(19.6419, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1602, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(20.4777, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e000-i0051 => L=20.638 acc= 61% / t(ms):   4.9  71.4 374.6)\n",
      "self.output_loss= tensor(0.5244, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(19.9979, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2879, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(19.4728, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e000-i0053 => L=19.761 acc= 66% / t(ms):   5.1  71.4 389.0)\n",
      "self.output_loss= tensor(0.1512, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(21.7134, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.6999, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(19.6859, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e000-i0055 => L=20.386 acc= 59% / t(ms):   5.0  71.4 400.6)\n",
      "self.output_loss= tensor(0.1851, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(17.0149, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1267, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(17.2407, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0792, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(16.9662, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e000-i0058 => L=17.045 acc= 65% / t(ms):   5.3  71.1 402.6)\n",
      "self.output_loss= tensor(0.1354, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(17.1667, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2011, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(17.3668, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e000-i0060 => L=17.568 acc= 46% / t(ms):   5.2  71.2 407.5)\n",
      "self.output_loss= tensor(0.1405, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(18.4696, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2702, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(18.2309, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.6068, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(17.1868, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e000-i0063 => L=17.794 acc= 40% / t(ms):   5.4  71.3 392.5)\n",
      "self.output_loss= tensor(0.2560, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(16.6576, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1887, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(17.9290, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2580, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(17.5973, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e000-i0066 => L=17.855 acc= 48% / t(ms):   5.5  71.4 391.3)\n",
      "self.output_loss= tensor(0.2627, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(17.4423, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2026, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(19.0197, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1551, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(17.8687, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e000-i0069 => L=18.024 acc= 57% / t(ms):   5.4  71.7 394.7)\n",
      "self.output_loss= tensor(0.2819, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(17.1080, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1713, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(16.6211, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2289, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(16.3256, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e000-i0072 => L=16.555 acc= 61% / t(ms):   5.3  71.5 407.3)\n",
      "self.output_loss= tensor(0.1288, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(16.9965, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2079, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(15.8698, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e000-i0074 => L=16.078 acc= 62% / t(ms):   5.2  71.2 416.5)\n",
      "self.output_loss= tensor(0.1819, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(16.5402, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1833, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(16.6390, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e000-i0076 => L=16.822 acc= 62% / t(ms):   5.1  72.6 417.1)\n",
      "self.output_loss= tensor(0.1525, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(16.7873, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1942, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(15.5940, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.3258, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(16.6640, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e000-i0079 => L=16.990 acc= 60% / t(ms):   5.1  72.2 414.4)\n",
      "self.output_loss= tensor(0.1336, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(16.2038, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1671, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(15.7869, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e000-i0081 => L=15.954 acc= 63% / t(ms):   5.0  71.2 417.2)\n",
      "self.output_loss= tensor(0.2292, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(15.7915, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1329, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(15.4123, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.3309, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(14.9622, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e000-i0084 => L=15.293 acc= 56% / t(ms):   5.0  69.5 416.0)\n",
      "self.output_loss= tensor(0.1367, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(16.0143, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1311, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(15.8197, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2740, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(15.2667, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e000-i0087 => L=15.541 acc= 59% / t(ms):   4.9  68.2 405.0)\n",
      "self.output_loss= tensor(0.1095, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(15.7789, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2323, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(15.8502, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2186, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(15.1868, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e000-i0090 => L=15.405 acc= 61% / t(ms):   4.7  67.2 405.1)\n",
      "self.output_loss= tensor(0.1060, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(15.6422, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1449, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(15.1860, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2132, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(14.9083, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e000-i0093 => L=15.121 acc= 65% / t(ms):   4.7  66.6 411.2)\n",
      "self.output_loss= tensor(0.1753, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(15.1150, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0879, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(14.7327, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1590, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(15.3355, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e000-i0096 => L=15.495 acc= 52% / t(ms):   4.8  66.1 404.1)\n",
      "self.output_loss= tensor(0.1329, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(14.3203, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2202, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(14.4408, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1856, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(14.7418, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e000-i0099 => L=14.927 acc= 54% / t(ms):   4.6  65.6 393.4)\n",
      "Validation : 5.0% (timings : 31.02 9.61)\n",
      "Validation : 30.0% (timings : 16.33 24.50)\n",
      "Validation : 53.0% (timings : 13.92 28.89)\n",
      "Validation : 81.0% (timings : 9.11 31.15)\n",
      "field_list[0].shape[0] is 382707\n",
      "AHN mean IoU = 60.3%\n",
      "self.output_loss= tensor(0.0702, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(13.9578, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e001-i0000 => L=14.028 acc= 62% / t(ms): 8478.2  96.8 460.2)\n",
      "self.output_loss= tensor(0.1366, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(14.1427, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1792, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(14.0723, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0630, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(14.1849, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e001-i0003 => L=14.248 acc= 64% / t(ms):  17.3  70.9 421.1)\n",
      "self.output_loss= tensor(0.1630, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(14.2928, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0773, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(13.6556, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0812, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(14.0625, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e001-i0006 => L=14.144 acc= 64% / t(ms):  14.3  71.1 420.4)\n",
      "self.output_loss= tensor(0.5091, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(15.0656, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1340, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(14.0943, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2540, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(14.7699, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e001-i0009 => L=15.024 acc= 61% / t(ms):  11.9  72.2 413.4)\n",
      "self.output_loss= tensor(0.1685, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(14.0231, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0433, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(13.7613, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0742, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(14.2544, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e001-i0012 => L=14.329 acc= 64% / t(ms):  10.6  75.3 415.4)\n",
      "self.output_loss= tensor(0.1220, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(14.2409, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1826, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(13.6157, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0646, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(14.4299, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e001-i0015 => L=14.494 acc= 73% / t(ms):   9.5  75.9 421.2)\n",
      "self.output_loss= tensor(0.1903, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(13.8805, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1185, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(13.6664, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e001-i0017 => L=13.785 acc= 69% / t(ms):   9.1  77.3 421.2)\n",
      "self.output_loss= tensor(0.1371, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(13.6573, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2138, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(14.0453, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e001-i0019 => L=14.259 acc= 55% / t(ms):   8.6  77.6 427.3)\n",
      "self.output_loss= tensor(0.1860, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(14.5611, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0806, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(14.0187, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1247, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(13.7633, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e001-i0022 => L=13.888 acc= 62% / t(ms):   7.6  76.0 418.3)\n",
      "self.output_loss= tensor(0.0972, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(13.3094, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1110, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(13.0964, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e001-i0024 => L=13.207 acc= 66% / t(ms):   7.3  75.2 425.0)\n",
      "self.output_loss= tensor(0.0734, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(13.3292, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0825, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(13.3494, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.4816, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(13.5039, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e001-i0027 => L=13.985 acc= 52% / t(ms):   7.4  74.1 418.3)\n",
      "self.output_loss= tensor(0.1722, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(13.5721, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0751, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(13.5400, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2486, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(13.1329, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e001-i0030 => L=13.381 acc= 62% / t(ms):   7.0  73.5 422.1)\n",
      "self.output_loss= tensor(0.1509, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(13.3371, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1013, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(13.4866, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0851, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(13.5001, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e001-i0033 => L=13.585 acc= 51% / t(ms):   6.4  72.7 401.3)\n",
      "self.output_loss= tensor(0.1001, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(13.3561, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.4896, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(13.6059, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0551, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(13.2647, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e001-i0036 => L=13.320 acc= 56% / t(ms):   6.1  72.2 393.9)\n",
      "self.output_loss= tensor(0.1464, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(13.6179, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2068, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(12.9297, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2899, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(13.4664, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e001-i0039 => L=13.756 acc= 61% / t(ms):   5.8  71.9 388.0)\n",
      "self.output_loss= tensor(0.0577, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(13.0886, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2489, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(13.0870, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1128, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(13.2333, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e001-i0042 => L=13.346 acc= 50% / t(ms):   5.5  72.0 375.1)\n",
      "self.output_loss= tensor(0.2056, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(13.0122, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1729, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(12.8878, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2223, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(12.9067, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e001-i0045 => L=13.129 acc= 55% / t(ms):   5.3  71.6 379.6)\n",
      "self.output_loss= tensor(0.1083, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(13.0478, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1387, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(13.3524, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1085, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(12.8046, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e001-i0048 => L=12.913 acc= 61% / t(ms):   5.2  71.5 374.8)\n",
      "self.output_loss= tensor(0.1755, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(13.1270, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1298, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(12.7371, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1018, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(12.5111, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e001-i0051 => L=12.613 acc= 41% / t(ms):   5.2  71.3 364.6)\n",
      "self.output_loss= tensor(0.1131, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(12.4075, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1611, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(12.5415, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1236, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(12.0526, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e001-i0054 => L=12.176 acc= 58% / t(ms):   5.0  71.4 376.8)\n",
      "self.output_loss= tensor(0.3153, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(13.1327, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1449, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(12.5886, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1434, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(12.5442, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e001-i0057 => L=12.688 acc= 61% / t(ms):   5.0  71.4 382.0)\n",
      "self.output_loss= tensor(0.0731, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(12.8124, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1114, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(12.8020, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1650, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(12.3339, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e001-i0060 => L=12.499 acc= 51% / t(ms):   5.0  71.3 379.2)\n",
      "self.output_loss= tensor(0.1333, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(12.9821, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1439, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(12.3046, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.3713, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(13.0058, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e001-i0063 => L=13.377 acc= 46% / t(ms):   4.9  71.2 358.7)\n",
      "self.output_loss= tensor(0.1155, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(11.9471, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1825, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(12.2337, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2938, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(12.4337, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e001-i0066 => L=12.728 acc= 44% / t(ms):   4.8  71.3 360.6)\n",
      "self.output_loss= tensor(0.3810, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(12.8914, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1317, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(12.1481, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2085, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(12.2044, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e001-i0069 => L=12.413 acc= 63% / t(ms):   4.8  71.2 369.4)\n",
      "self.output_loss= tensor(0.0836, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(12.2391, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1584, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(12.1546, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1272, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(12.2344, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e001-i0072 => L=12.362 acc= 73% / t(ms):   4.8  71.3 382.5)\n",
      "self.output_loss= tensor(0.0953, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(12.1562, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1009, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(12.0784, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1319, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(11.8111, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e001-i0075 => L=11.943 acc= 46% / t(ms):   4.8  71.0 378.3)\n",
      "self.output_loss= tensor(0.2387, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(11.6857, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1358, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(11.6019, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1321, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(11.7988, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e001-i0078 => L=11.931 acc= 65% / t(ms):   4.7  71.1 383.2)\n",
      "self.output_loss= tensor(0.1254, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(11.8187, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1467, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(11.4887, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1523, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(11.5474, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e001-i0081 => L=11.700 acc= 57% / t(ms):   4.8  70.4 386.8)\n",
      "self.output_loss= tensor(0.1740, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(11.4039, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0806, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(11.5068, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1302, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(11.9541, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e001-i0084 => L=12.084 acc= 67% / t(ms):   4.7  69.0 391.9)\n",
      "self.output_loss= tensor(0.0933, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(12.4416, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0887, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(11.7779, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0772, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(11.7204, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e001-i0087 => L=11.798 acc= 65% / t(ms):   4.6  67.8 392.9)\n",
      "self.output_loss= tensor(0.0837, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(12.0024, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0811, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(11.4727, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1875, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(11.2828, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e001-i0090 => L=11.470 acc= 41% / t(ms):   4.5  67.1 387.5)\n",
      "self.output_loss= tensor(0.1033, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(11.4068, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1073, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(11.8504, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1093, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(11.6962, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e001-i0093 => L=11.805 acc= 53% / t(ms):   4.7  66.2 387.5)\n",
      "self.output_loss= tensor(0.0975, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(11.5542, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1164, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(11.2952, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0955, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(11.2367, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e001-i0096 => L=11.332 acc= 63% / t(ms):   4.6  65.8 391.0)\n",
      "self.output_loss= tensor(0.1289, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(11.3443, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0923, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(11.3724, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e001-i0098 => L=11.465 acc= 68% / t(ms):   4.6  65.7 401.4)\n",
      "self.output_loss= tensor(0.1041, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(12.6268, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Validation : 5.0% (timings : 31.53 9.18)\n",
      "Validation : 29.0% (timings : 16.99 23.69)\n",
      "Validation : 52.0% (timings : 16.04 28.05)\n",
      "Validation : 77.0% (timings : 11.86 30.43)\n",
      "field_list[0].shape[0] is 382707\n",
      "AHN mean IoU = 75.6%\n",
      "self.output_loss= tensor(0.1035, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(11.6064, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e002-i0000 => L=11.710 acc= 67% / t(ms): 6373.4 100.2 416.7)\n",
      "self.output_loss= tensor(0.0952, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(11.5856, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0913, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(11.8050, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0890, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(11.1828, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e002-i0003 => L=11.272 acc= 56% / t(ms):  18.9  69.9 360.7)\n",
      "self.output_loss= tensor(0.1008, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(11.1273, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1252, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(11.4542, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0991, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(11.1168, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e002-i0006 => L=11.216 acc= 56% / t(ms):  15.2  70.0 368.0)\n",
      "self.output_loss= tensor(0.1156, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(11.2650, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1865, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(11.5691, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1116, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(11.0629, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e002-i0009 => L=11.174 acc= 72% / t(ms):  12.3  70.0 381.8)\n",
      "self.output_loss= tensor(0.3627, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(10.8804, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1560, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(10.9473, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1458, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(11.1364, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e002-i0012 => L=11.282 acc= 51% / t(ms):  10.3  69.9 383.3)\n",
      "self.output_loss= tensor(0.1270, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(10.9719, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0951, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(10.9121, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0896, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(10.6631, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e002-i0015 => L=10.753 acc= 66% / t(ms):   8.8  70.1 384.8)\n",
      "self.output_loss= tensor(0.1380, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(11.0305, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0313, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(10.9428, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0952, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(10.9377, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e002-i0018 => L=11.033 acc= 48% / t(ms):   7.8  70.1 385.0)\n",
      "self.output_loss= tensor(0.0751, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(10.7098, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1936, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(11.2784, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0803, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(11.0168, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e002-i0021 => L=11.097 acc= 53% / t(ms):   7.0  70.1 386.4)\n",
      "self.output_loss= tensor(0.2586, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(10.6838, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0775, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(10.8539, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1324, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(11.5025, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e002-i0024 => L=11.635 acc= 47% / t(ms):   6.5  71.3 381.6)\n",
      "self.output_loss= tensor(0.0903, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(10.7341, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1979, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(10.6654, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1335, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(10.4919, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e002-i0027 => L=10.625 acc= 53% / t(ms):   6.5  72.9 385.6)\n",
      "self.output_loss= tensor(0.1819, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(10.8479, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0758, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(10.9591, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1265, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(10.9919, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e002-i0030 => L=11.118 acc= 54% / t(ms):   6.2  72.4 382.9)\n",
      "self.output_loss= tensor(0.1837, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(11.2705, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0733, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(10.6312, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2239, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(10.5006, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e002-i0033 => L=10.725 acc= 65% / t(ms):   6.1  76.7 389.7)\n",
      "self.output_loss= tensor(0.2439, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(10.7622, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0916, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(10.4134, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1479, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(10.4539, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e002-i0036 => L=10.602 acc= 48% / t(ms):   8.0  81.8 385.8)\n",
      "self.output_loss= tensor(0.0866, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(10.2677, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1342, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(10.6877, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1230, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(10.7468, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e002-i0039 => L=10.870 acc= 43% / t(ms):   7.7  78.7 381.1)\n",
      "self.output_loss= tensor(0.1609, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(10.1923, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1660, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(10.5347, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0759, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(10.5284, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e002-i0042 => L=10.604 acc= 48% / t(ms):   6.9  76.1 388.1)\n",
      "self.output_loss= tensor(0.0906, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(10.4136, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0967, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(10.6722, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e002-i0044 => L=10.769 acc= 65% / t(ms):   6.5  75.0 399.8)\n",
      "self.output_loss= tensor(0.0823, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(10.8472, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1526, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(10.6777, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1069, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(10.8982, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e002-i0047 => L=11.005 acc= 51% / t(ms):   6.3  73.5 396.3)\n",
      "self.output_loss= tensor(0.0698, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(10.4228, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0856, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(10.3541, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1412, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(10.0395, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e002-i0050 => L=10.181 acc= 63% / t(ms):   5.9  72.4 390.3)\n",
      "self.output_loss= tensor(0.1177, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(10.2216, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0701, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.7525, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.3011, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(10.0972, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e002-i0053 => L=10.398 acc= 45% / t(ms):   5.9  71.7 385.9)\n",
      "self.output_loss= tensor(0.0658, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.9991, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0997, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(10.3053, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1076, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.6159, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e002-i0056 => L=9.723 acc= 76% / t(ms):   5.7  71.3 403.5)\n",
      "self.output_loss= tensor(0.0887, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.9655, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0760, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(10.0763, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e002-i0058 => L=10.152 acc= 60% / t(ms):   5.7  70.7 409.9)\n",
      "self.output_loss= tensor(0.1025, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.9279, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0830, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(10.2497, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2314, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(10.6404, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e002-i0061 => L=10.872 acc= 37% / t(ms):   5.5  70.3 393.6)\n",
      "self.output_loss= tensor(0.1044, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(10.2379, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2102, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(10.5613, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1325, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.9414, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e002-i0064 => L=10.074 acc= 41% / t(ms):   5.3  70.2 382.0)\n",
      "self.output_loss= tensor(0.1700, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(10.0059, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0955, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.6091, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1737, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(10.0648, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e002-i0067 => L=10.238 acc= 39% / t(ms):   5.1  70.0 370.2)\n",
      "self.output_loss= tensor(0.0986, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.2628, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0757, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.3680, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1929, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.6963, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e002-i0070 => L=9.889 acc= 53% / t(ms):   4.9  69.9 372.6)\n",
      "self.output_loss= tensor(0.0864, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.4129, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0843, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.6089, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e002-i0072 => L=9.693 acc= 57% / t(ms):   4.9  69.9 389.3)\n",
      "self.output_loss= tensor(0.1147, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.6856, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1133, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.8254, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0750, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.5264, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e002-i0075 => L=9.601 acc= 50% / t(ms):   5.1  70.1 389.2)\n",
      "self.output_loss= tensor(0.0534, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(10.3135, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0926, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(10.0030, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1340, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.4688, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e002-i0078 => L=9.603 acc= 53% / t(ms):   5.2  69.9 388.6)\n",
      "self.output_loss= tensor(0.1116, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(10.0424, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1482, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(10.4211, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1459, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(10.0025, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e002-i0081 => L=10.148 acc= 63% / t(ms):   5.2  69.1 390.0)\n",
      "self.output_loss= tensor(0.1213, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.9113, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0861, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.7916, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0648, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.6531, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e002-i0084 => L=9.718 acc= 64% / t(ms):   5.1  67.7 397.3)\n",
      "self.output_loss= tensor(0.0780, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(10.0936, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1736, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(10.2434, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0968, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.8847, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e002-i0087 => L=9.981 acc= 55% / t(ms):   4.9  66.5 393.2)\n",
      "self.output_loss= tensor(0.2122, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.4747, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1172, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.5977, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0794, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.8457, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e002-i0090 => L=9.925 acc= 57% / t(ms):   4.7  65.7 401.0)\n",
      "self.output_loss= tensor(0.0608, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.6487, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0923, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.7971, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0778, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.4032, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e002-i0093 => L=9.481 acc= 55% / t(ms):   4.9  65.8 407.0)\n",
      "self.output_loss= tensor(0.0799, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.6510, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1969, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.9460, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0927, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.5762, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e002-i0096 => L=9.669 acc= 52% / t(ms):   5.0  65.1 403.6)\n",
      "self.output_loss= tensor(0.1156, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.9259, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0480, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.7892, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0714, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.8110, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e002-i0099 => L=9.882 acc= 60% / t(ms):   4.8  64.7 400.1)\n",
      "Validation : 3.0% (timings : 37.76 5.95)\n",
      "Validation : 28.0% (timings : 18.42 22.27)\n",
      "Validation : 52.0% (timings : 19.21 27.92)\n",
      "Validation : 81.0% (timings : 10.26 30.07)\n",
      "field_list[0].shape[0] is 382707\n",
      "AHN mean IoU = 73.8%\n",
      "self.output_loss= tensor(0.1842, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.9058, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e003-i0000 => L=10.090 acc= 59% / t(ms): 6347.2  82.9 393.2)\n",
      "self.output_loss= tensor(0.0550, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.3690, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2014, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.8291, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1144, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.5337, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e003-i0003 => L=9.648 acc= 60% / t(ms):  21.2  84.3 331.0)\n",
      "self.output_loss= tensor(0.1558, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(10.1001, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0909, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.5438, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.7644, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.5094, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e003-i0006 => L=10.274 acc= 62% / t(ms):  16.9  80.6 351.9)\n",
      "self.output_loss= tensor(0.2159, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.9688, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0899, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.4902, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0639, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.2875, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e003-i0009 => L=9.351 acc= 55% / t(ms):  13.7  78.0 368.5)\n",
      "self.output_loss= tensor(0.0386, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.6033, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0537, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.1615, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2557, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.7563, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e003-i0012 => L=10.012 acc= 49% / t(ms):  11.3  75.8 372.1)\n",
      "self.output_loss= tensor(0.0779, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.4198, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0595, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.2956, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0685, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.1179, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e003-i0015 => L=9.186 acc= 56% / t(ms):  10.0  74.5 380.8)\n",
      "self.output_loss= tensor(0.0876, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.4734, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1180, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.2727, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0910, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.1713, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e003-i0018 => L=9.262 acc= 49% / t(ms):   8.7  73.4 378.7)\n",
      "self.output_loss= tensor(0.1247, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.4857, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0758, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.5106, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1581, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.4197, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e003-i0021 => L=9.578 acc= 64% / t(ms):   7.9  72.7 387.3)\n",
      "self.output_loss= tensor(0.0833, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.5336, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.4169, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.8236, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0664, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.4093, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e003-i0024 => L=9.476 acc= 58% / t(ms):   7.0  71.9 376.4)\n",
      "self.output_loss= tensor(0.0351, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.3840, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1028, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.3807, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1048, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.1951, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e003-i0027 => L=9.300 acc= 64% / t(ms):   6.7  71.6 388.9)\n",
      "self.output_loss= tensor(0.0700, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.3189, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0594, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.2709, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0803, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.9106, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e003-i0030 => L=9.991 acc= 66% / t(ms):   6.3  71.8 401.7)\n",
      "self.output_loss= tensor(0.0840, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.4434, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1364, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.3555, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0718, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.0874, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e003-i0033 => L=9.159 acc= 63% / t(ms):   6.0  71.5 404.4)\n",
      "self.output_loss= tensor(0.1944, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.5580, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1632, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.9431, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1891, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(10.0099, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e003-i0036 => L=10.199 acc= 50% / t(ms):   5.8  71.4 399.2)\n",
      "self.output_loss= tensor(0.2604, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.2196, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2723, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(10.0792, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1044, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.1626, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e003-i0039 => L=9.267 acc= 61% / t(ms):   5.9  78.0 389.3)\n",
      "self.output_loss= tensor(0.0935, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.0065, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1053, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.9488, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1944, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.2286, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e003-i0042 => L=9.423 acc= 63% / t(ms):   5.7  75.9 396.1)\n",
      "self.output_loss= tensor(0.0896, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.3621, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1040, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.1309, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0865, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.0351, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e003-i0045 => L=9.122 acc= 54% / t(ms):   5.3  77.7 388.4)\n",
      "self.output_loss= tensor(0.1422, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.2990, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0909, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.7438, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e003-i0047 => L=9.835 acc= 68% / t(ms):   8.2  78.8 404.6)\n",
      "self.output_loss= tensor(0.2632, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.3117, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0884, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.5943, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0698, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.8756, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e003-i0050 => L=9.945 acc= 57% / t(ms):   7.4  76.6 394.4)\n",
      "self.output_loss= tensor(0.1487, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.1765, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1066, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.3541, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1525, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.3886, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e003-i0053 => L=9.541 acc= 57% / t(ms):   6.9  74.9 397.0)\n",
      "self.output_loss= tensor(0.0978, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.9170, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2099, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.0327, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e003-i0055 => L=9.243 acc= 69% / t(ms):   6.7  74.1 407.6)\n",
      "self.output_loss= tensor(0.0886, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.3015, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1479, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.2058, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1042, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.1868, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e003-i0058 => L=9.291 acc= 68% / t(ms):   6.7  73.5 406.8)\n",
      "self.output_loss= tensor(0.1148, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.0214, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0752, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.4480, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e003-i0060 => L=9.523 acc= 51% / t(ms):   6.3  72.6 411.5)\n",
      "self.output_loss= tensor(0.0813, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.2029, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0791, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.0906, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0754, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.7350, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e003-i0063 => L=8.810 acc= 66% / t(ms):   5.9  71.9 405.9)\n",
      "self.output_loss= tensor(0.1929, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.5118, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0752, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.0420, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0927, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.0193, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e003-i0066 => L=9.112 acc= 71% / t(ms):   5.6  71.6 409.8)\n",
      "self.output_loss= tensor(0.0891, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.7871, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0688, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.0578, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0846, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.7332, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e003-i0069 => L=8.818 acc= 67% / t(ms):   5.4  71.3 398.6)\n",
      "self.output_loss= tensor(0.0622, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.1124, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0969, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.0493, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0963, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.5938, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e003-i0072 => L=8.690 acc= 64% / t(ms):   5.3  71.0 396.6)\n",
      "self.output_loss= tensor(0.0681, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.7120, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2002, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.6081, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0742, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.8178, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e003-i0075 => L=8.892 acc= 65% / t(ms):   5.2  70.8 399.4)\n",
      "self.output_loss= tensor(0.0522, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.8826, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0988, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.0278, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1976, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.5385, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e003-i0078 => L=9.736 acc= 38% / t(ms):   5.3  70.5 388.9)\n",
      "self.output_loss= tensor(0.1473, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.6548, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0843, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.9265, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0581, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.8963, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e003-i0081 => L=8.954 acc= 61% / t(ms):   5.1  69.8 395.9)\n",
      "self.output_loss= tensor(0.2523, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.5270, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0555, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.1113, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0812, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.1171, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e003-i0084 => L=9.198 acc= 52% / t(ms):   4.9  68.2 392.2)\n",
      "self.output_loss= tensor(0.0729, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.7441, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0877, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.9173, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e003-i0086 => L=9.005 acc= 65% / t(ms):   4.8  67.3 399.8)\n",
      "self.output_loss= tensor(0.0752, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.0207, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0961, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.6888, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1209, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.8793, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e003-i0089 => L=9.000 acc= 68% / t(ms):   4.6  66.3 406.2)\n",
      "self.output_loss= tensor(0.0389, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.1272, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0847, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.0090, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0994, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.0345, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e003-i0092 => L=9.134 acc= 66% / t(ms):   4.5  65.7 404.5)\n",
      "self.output_loss= tensor(0.2939, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.2294, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0729, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.8462, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0777, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.8155, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e003-i0095 => L=8.893 acc= 65% / t(ms):   4.7  65.2 394.9)\n",
      "self.output_loss= tensor(0.0441, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.0434, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0522, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.1401, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1665, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.0135, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e003-i0098 => L=9.180 acc= 46% / t(ms):   5.1  65.1 383.5)\n",
      "self.output_loss= tensor(0.0721, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.3594, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Validation : 4.0% (timings : 34.78 7.57)\n",
      "Validation : 30.0% (timings : 23.74 23.39)\n",
      "Validation : 57.0% (timings : 11.91 28.39)\n",
      "Validation : 80.0% (timings : 12.04 29.81)\n",
      "field_list[0].shape[0] is 382707\n",
      "AHN mean IoU = 74.6%\n",
      "self.output_loss= tensor(0.1325, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4920, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e004-i0000 => L=8.625 acc= 68% / t(ms): 6355.2 107.9 405.8)\n",
      "self.output_loss= tensor(0.0718, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.7698, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1295, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.7578, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2370, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.9470, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e004-i0003 => L=9.184 acc= 49% / t(ms):  26.2  72.1 404.9)\n",
      "self.output_loss= tensor(0.0680, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.9588, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0668, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.5845, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1124, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.9314, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e004-i0006 => L=9.044 acc= 64% / t(ms):  20.6  71.7 398.0)\n",
      "self.output_loss= tensor(0.0788, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.6882, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0640, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.6604, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1227, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.7099, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e004-i0009 => L=8.833 acc= 75% / t(ms):  16.4  71.6 406.0)\n",
      "self.output_loss= tensor(0.0682, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.7229, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0707, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4798, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0687, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.8605, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e004-i0012 => L=8.929 acc= 69% / t(ms):  13.3  71.3 407.0)\n",
      "self.output_loss= tensor(0.0523, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.5341, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0743, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.8335, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0460, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2887, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e004-i0015 => L=8.335 acc= 55% / t(ms):  11.0  70.7 397.6)\n",
      "self.output_loss= tensor(0.1183, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.8012, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0530, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.5462, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e004-i0017 => L=8.599 acc= 64% / t(ms):   9.8  70.8 404.6)\n",
      "self.output_loss= tensor(0.0945, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.7218, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0895, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.7209, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0526, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.7051, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e004-i0020 => L=8.758 acc= 58% / t(ms):   8.5  70.9 393.3)\n",
      "self.output_loss= tensor(0.0936, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.0194, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0500, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.0357, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0767, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.9727, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e004-i0023 => L=9.049 acc= 58% / t(ms):   7.5  70.5 387.6)\n",
      "self.output_loss= tensor(0.1437, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.6422, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0514, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.9983, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2319, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.5074, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e004-i0026 => L=8.739 acc= 56% / t(ms):   6.8  70.7 390.8)\n",
      "self.output_loss= tensor(0.1408, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.5332, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0847, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.7551, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0943, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.5754, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e004-i0029 => L=8.670 acc= 51% / t(ms):   6.5  70.7 391.4)\n",
      "self.output_loss= tensor(0.0597, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.8074, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0526, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.8928, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1358, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.7434, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e004-i0032 => L=8.879 acc= 57% / t(ms):   6.1  70.5 389.7)\n",
      "self.output_loss= tensor(0.0910, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.5798, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2790, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.8473, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0634, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.7034, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e004-i0035 => L=8.767 acc= 53% / t(ms):   5.8  70.6 382.0)\n",
      "self.output_loss= tensor(0.0835, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.9011, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0443, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.8846, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1885, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.8569, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e004-i0038 => L=9.045 acc= 44% / t(ms):   5.7  70.8 382.6)\n",
      "self.output_loss= tensor(0.0605, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.9008, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0598, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.6789, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0473, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.8687, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e004-i0041 => L=8.916 acc= 59% / t(ms):   5.8  70.5 381.0)\n",
      "self.output_loss= tensor(0.0664, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.6686, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1261, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2818, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0545, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.4371, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e004-i0044 => L=9.492 acc= 48% / t(ms):   5.6  70.4 381.6)\n",
      "self.output_loss= tensor(0.0716, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.8630, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1309, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.6002, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0836, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.0137, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e004-i0047 => L=9.097 acc= 65% / t(ms):   5.4  70.6 385.8)\n",
      "self.output_loss= tensor(0.0487, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.7823, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1576, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4122, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0529, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.8124, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e004-i0050 => L=8.865 acc= 49% / t(ms):   5.5  70.4 382.1)\n",
      "self.output_loss= tensor(0.0697, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.6774, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0817, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4445, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0904, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.5654, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e004-i0053 => L=8.656 acc= 50% / t(ms):   6.2  74.9 370.5)\n",
      "self.output_loss= tensor(0.0610, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.5073, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0725, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.8625, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e004-i0055 => L=8.935 acc= 55% / t(ms):   6.5  76.2 378.7)\n",
      "self.output_loss= tensor(0.1277, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3415, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0404, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.6280, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0473, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.5304, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e004-i0058 => L=8.578 acc= 58% / t(ms):   6.7  75.4 389.7)\n",
      "self.output_loss= tensor(0.1001, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.5916, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1144, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.7810, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1127, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.6854, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e004-i0061 => L=8.798 acc= 52% / t(ms):   6.7  77.5 386.5)\n",
      "self.output_loss= tensor(0.0501, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2981, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0979, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3224, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1018, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2951, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e004-i0064 => L=8.397 acc= 59% / t(ms):   6.5  81.0 385.9)\n",
      "self.output_loss= tensor(0.1012, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.6219, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0854, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.9990, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0540, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.7228, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e004-i0067 => L=8.777 acc= 70% / t(ms):   6.5  78.2 393.6)\n",
      "self.output_loss= tensor(0.0715, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3596, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0539, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2707, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0432, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3261, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e004-i0070 => L=8.369 acc= 54% / t(ms):   6.0  76.0 393.8)\n",
      "self.output_loss= tensor(0.0635, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.6947, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2061, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4563, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0760, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3287, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e004-i0073 => L=8.405 acc= 62% / t(ms):   5.8  74.5 397.9)\n",
      "self.output_loss= tensor(0.2440, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.9128, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0413, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2569, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1695, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.5599, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e004-i0076 => L=8.729 acc= 64% / t(ms):   5.9  73.5 396.4)\n",
      "self.output_loss= tensor(0.3617, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3626, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0606, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3941, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e004-i0078 => L=8.455 acc= 58% / t(ms):   5.7  72.8 401.8)\n",
      "self.output_loss= tensor(0.2324, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.8931, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1105, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.5732, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0743, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.0820, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e004-i0081 => L=9.156 acc= 56% / t(ms):   5.5  71.5 397.8)\n",
      "self.output_loss= tensor(0.1065, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.0588, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0361, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9449, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0899, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.7217, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e004-i0084 => L=8.812 acc= 64% / t(ms):   5.3  69.6 391.9)\n",
      "self.output_loss= tensor(0.0905, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.1094, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1431, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.7883, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0569, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2410, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e004-i0087 => L=8.298 acc= 63% / t(ms):   5.0  67.9 387.3)\n",
      "self.output_loss= tensor(0.0742, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.5130, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0681, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.5629, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0713, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.7916, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e004-i0090 => L=8.863 acc= 53% / t(ms):   4.8  66.9 389.5)\n",
      "self.output_loss= tensor(0.0838, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2549, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0543, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.7238, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1294, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.9053, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e004-i0093 => L=9.035 acc= 58% / t(ms):   4.7  66.2 392.9)\n",
      "self.output_loss= tensor(0.1485, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.8002, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0845, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4986, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0710, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1424, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e004-i0096 => L=8.213 acc= 60% / t(ms):   4.7  65.6 397.6)\n",
      "self.output_loss= tensor(0.0696, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3991, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0952, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2281, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1183, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.0244, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e004-i0099 => L=9.143 acc= 48% / t(ms):   4.7  65.3 395.1)\n",
      "Validation : 6.0% (timings : 28.36 10.37)\n",
      "Validation : 28.0% (timings : 18.84 23.24)\n",
      "Validation : 52.0% (timings : 13.66 28.12)\n",
      "Validation : 76.0% (timings : 12.66 29.65)\n",
      "field_list[0].shape[0] is 382707\n",
      "AHN mean IoU = 72.4%\n",
      "self.output_loss= tensor(0.1163, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4868, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e005-i0000 => L=8.603 acc= 58% / t(ms): 6430.1 102.8 427.6)\n",
      "self.output_loss= tensor(0.1070, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.8960, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2879, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.8712, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1371, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3193, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e005-i0003 => L=8.456 acc= 45% / t(ms):  29.0  74.6 346.8)\n",
      "self.output_loss= tensor(0.1021, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.6865, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0504, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3556, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e005-i0005 => L=8.406 acc= 59% / t(ms):  24.5  74.0 362.9)\n",
      "self.output_loss= tensor(0.1029, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.6190, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0689, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3812, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1157, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.6464, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e005-i0008 => L=8.762 acc= 56% / t(ms):  19.1  72.9 355.1)\n",
      "self.output_loss= tensor(0.1105, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4904, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0591, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.6273, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0747, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3716, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e005-i0011 => L=8.446 acc= 51% / t(ms):  15.2  72.2 360.8)\n",
      "self.output_loss= tensor(0.3272, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3356, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1121, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3162, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0911, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.5754, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e005-i0014 => L=8.667 acc= 61% / t(ms):  12.4  71.8 369.9)\n",
      "self.output_loss= tensor(0.0975, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.5488, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1501, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2780, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0895, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4947, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e005-i0017 => L=8.584 acc= 52% / t(ms):  10.4  71.7 369.6)\n",
      "self.output_loss= tensor(0.1027, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9932, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1003, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.5574, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1034, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.9520, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e005-i0020 => L=9.055 acc= 55% / t(ms):   9.2  71.3 376.1)\n",
      "self.output_loss= tensor(0.0639, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3522, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0666, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.7331, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0663, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2855, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e005-i0023 => L=8.352 acc= 63% / t(ms):   8.0  71.2 385.3)\n",
      "self.output_loss= tensor(0.0781, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2617, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1148, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3618, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0521, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.8773, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e005-i0026 => L=8.929 acc= 58% / t(ms):   7.2  71.0 389.3)\n",
      "self.output_loss= tensor(0.0471, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.5741, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0854, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.5124, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0779, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4429, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e005-i0029 => L=8.521 acc= 59% / t(ms):   6.6  70.9 390.3)\n",
      "self.output_loss= tensor(0.0551, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.8032, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0926, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4602, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1717, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8705, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e005-i0032 => L=8.042 acc= 69% / t(ms):   6.1  70.7 394.2)\n",
      "self.output_loss= tensor(0.1582, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.8230, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1282, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3236, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0550, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.6036, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e005-i0035 => L=8.659 acc= 60% / t(ms):   5.8  70.7 397.2)\n",
      "self.output_loss= tensor(0.1049, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2011, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2497, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.6931, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1079, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.7054, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e005-i0038 => L=8.813 acc= 39% / t(ms):   5.6  70.3 376.6)\n",
      "self.output_loss= tensor(0.0775, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1979, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0945, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.8546, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0602, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2771, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e005-i0041 => L=8.337 acc= 67% / t(ms):   5.7  70.5 374.3)\n",
      "self.output_loss= tensor(0.0989, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.7072, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0629, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.7135, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1054, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.7166, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e005-i0044 => L=8.822 acc= 59% / t(ms):   5.5  70.2 385.0)\n",
      "self.output_loss= tensor(0.1076, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3188, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1035, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.8274, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0738, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.7047, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e005-i0047 => L=8.778 acc= 49% / t(ms):   5.3  70.3 382.8)\n",
      "self.output_loss= tensor(0.0764, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4888, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0902, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4782, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0745, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.5131, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e005-i0050 => L=8.588 acc= 58% / t(ms):   5.2  70.3 386.1)\n",
      "self.output_loss= tensor(0.0855, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0467, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0403, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1369, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1091, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2858, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e005-i0053 => L=8.395 acc= 65% / t(ms):   5.1  70.3 392.2)\n",
      "self.output_loss= tensor(0.1539, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4905, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0878, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4372, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1216, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3231, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e005-i0056 => L=8.445 acc= 53% / t(ms):   5.3  70.5 392.5)\n",
      "self.output_loss= tensor(0.1205, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.7695, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1281, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.6047, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0520, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3867, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e005-i0059 => L=8.439 acc= 56% / t(ms):   5.2  70.6 390.6)\n",
      "self.output_loss= tensor(0.1843, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4227, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0600, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1985, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0670, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4529, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e005-i0062 => L=8.520 acc= 56% / t(ms):   5.1  70.5 383.7)\n",
      "self.output_loss= tensor(0.0531, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2417, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0482, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.7658, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e005-i0064 => L=8.814 acc= 59% / t(ms):   5.3  70.5 391.5)\n",
      "self.output_loss= tensor(0.0636, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.5325, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1771, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.6554, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e005-i0066 => L=8.833 acc= 40% / t(ms):   5.7  72.5 396.6)\n",
      "self.output_loss= tensor(0.0939, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4350, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0290, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2831, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0749, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.6884, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e005-i0069 => L=8.763 acc= 54% / t(ms):   6.0  75.3 387.8)\n",
      "self.output_loss= tensor(0.2784, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.5866, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0538, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1698, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1584, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.6751, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e005-i0072 => L=8.833 acc= 57% / t(ms):   5.9  74.8 385.0)\n",
      "self.output_loss= tensor(0.0869, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2798, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0538, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3806, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e005-i0074 => L=8.434 acc= 63% / t(ms):   9.0  74.3 389.2)\n",
      "self.output_loss= tensor(0.2399, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.8166, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0525, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2730, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0936, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.5992, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e005-i0077 => L=8.693 acc= 52% / t(ms):   8.4  74.8 388.9)\n",
      "self.output_loss= tensor(0.0610, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4881, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0944, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0261, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0864, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4098, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e005-i0080 => L=8.496 acc= 56% / t(ms):   7.4  73.2 391.9)\n",
      "self.output_loss= tensor(0.0641, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4127, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0623, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4556, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0441, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4896, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e005-i0083 => L=8.534 acc= 57% / t(ms):   6.8  70.2 385.1)\n",
      "self.output_loss= tensor(0.1204, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1718, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0688, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3273, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0577, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.6250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e005-i0086 => L=8.683 acc= 60% / t(ms):   6.3  68.2 387.0)\n",
      "self.output_loss= tensor(0.0803, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4692, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0494, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1811, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0858, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3224, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e005-i0089 => L=8.408 acc= 63% / t(ms):   5.7  66.3 385.1)\n",
      "self.output_loss= tensor(0.2199, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3165, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1457, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1352, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0502, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2736, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e005-i0092 => L=8.324 acc= 53% / t(ms):   5.6  65.2 382.4)\n",
      "self.output_loss= tensor(0.4001, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1279, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0529, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4034, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0675, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4824, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e005-i0095 => L=8.550 acc= 60% / t(ms):   5.3  64.3 383.6)\n",
      "self.output_loss= tensor(0.0339, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4445, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0537, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0948, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0627, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7806, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e005-i0098 => L=7.843 acc= 61% / t(ms):   5.1  63.7 383.4)\n",
      "self.output_loss= tensor(0.1358, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2793, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Validation : 4.0% (timings : 33.57 8.41)\n",
      "Validation : 27.0% (timings : 20.33 22.40)\n",
      "Validation : 50.0% (timings : 17.16 28.41)\n",
      "Validation : 76.0% (timings : 10.34 30.17)\n",
      "field_list[0].shape[0] is 382707\n",
      "AHN mean IoU = 71.0%\n",
      "self.output_loss= tensor(0.0703, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0581, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e006-i0000 => L=8.128 acc= 54% / t(ms): 6470.0  89.0 396.2)\n",
      "self.output_loss= tensor(0.0612, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.6790, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1391, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2143, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0427, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.7243, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e006-i0003 => L=8.767 acc= 58% / t(ms):  21.4  89.3 331.2)\n",
      "self.output_loss= tensor(0.0786, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0850, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0740, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.6908, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0807, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4131, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e006-i0006 => L=8.494 acc= 65% / t(ms):  16.9  84.4 344.5)\n",
      "self.output_loss= tensor(0.2626, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0717, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0898, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3870, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e006-i0008 => L=8.477 acc= 52% / t(ms):  14.7  82.2 362.4)\n",
      "self.output_loss= tensor(0.0565, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1211, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0622, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3545, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1140, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.5418, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e006-i0011 => L=8.656 acc= 50% / t(ms):  12.3  79.3 366.7)\n",
      "self.output_loss= tensor(0.0528, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1455, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0650, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4329, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0612, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4662, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e006-i0014 => L=8.527 acc= 63% / t(ms):  10.3  77.1 379.4)\n",
      "self.output_loss= tensor(0.2135, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.6143, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0764, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4898, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2521, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.7168, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e006-i0017 => L=8.969 acc= 42% / t(ms):   8.8  75.5 373.7)\n",
      "self.output_loss= tensor(0.0614, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4182, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1522, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.9061, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0575, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3367, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e006-i0020 => L=8.394 acc= 65% / t(ms):   7.8  74.1 380.5)\n",
      "self.output_loss= tensor(0.0792, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3051, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2181, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1297, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0588, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2225, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e006-i0023 => L=8.281 acc= 64% / t(ms):   6.9  73.2 388.8)\n",
      "self.output_loss= tensor(0.0540, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1879, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1329, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.7049, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1046, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2408, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e006-i0026 => L=8.345 acc= 56% / t(ms):   6.5  72.7 390.3)\n",
      "self.output_loss= tensor(0.0597, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2898, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0526, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1594, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e006-i0028 => L=8.212 acc= 75% / t(ms):   6.3  72.5 399.8)\n",
      "self.output_loss= tensor(0.0600, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4384, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0862, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4662, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2632, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3767, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e006-i0031 => L=8.640 acc= 39% / t(ms):   6.0  72.8 391.5)\n",
      "self.output_loss= tensor(0.0395, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2172, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0785, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2077, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0867, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1957, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e006-i0034 => L=8.282 acc= 49% / t(ms):   5.7  72.5 381.8)\n",
      "self.output_loss= tensor(0.0374, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3797, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1637, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3766, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0944, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3229, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e006-i0037 => L=8.417 acc= 49% / t(ms):   5.5  72.2 379.2)\n",
      "self.output_loss= tensor(0.0787, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1988, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0595, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3683, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e006-i0039 => L=8.428 acc= 56% / t(ms):   5.3  72.1 391.4)\n",
      "self.output_loss= tensor(0.0692, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.5380, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0531, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9318, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2470, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0504, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e006-i0042 => L=8.297 acc= 44% / t(ms):   5.4  71.8 381.6)\n",
      "self.output_loss= tensor(0.0590, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0737, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0672, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7781, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0516, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3507, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e006-i0045 => L=8.402 acc= 62% / t(ms):   5.5  71.7 390.9)\n",
      "self.output_loss= tensor(0.0747, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0565, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1968, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9532, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0449, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2510, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e006-i0048 => L=8.296 acc= 62% / t(ms):   5.7  71.9 400.4)\n",
      "self.output_loss= tensor(0.3930, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0268, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1069, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9670, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e006-i0050 => L=8.074 acc= 64% / t(ms):   5.5  71.6 405.0)\n",
      "self.output_loss= tensor(0.0797, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3177, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0985, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.5280, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0685, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0812, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e006-i0053 => L=8.150 acc= 46% / t(ms):   5.3  71.3 395.2)\n",
      "self.output_loss= tensor(0.1023, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2575, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0811, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2207, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0796, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2870, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e006-i0056 => L=8.367 acc= 58% / t(ms):   5.2  71.2 394.7)\n",
      "self.output_loss= tensor(0.0635, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0817, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0486, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3227, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0538, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3231, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e006-i0059 => L=8.377 acc= 45% / t(ms):   5.1  71.4 381.6)\n",
      "self.output_loss= tensor(0.0837, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3118, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1253, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8359, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0695, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2795, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e006-i0062 => L=8.349 acc= 60% / t(ms):   5.0  70.9 385.0)\n",
      "self.output_loss= tensor(0.1306, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2434, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0693, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3438, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0705, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9529, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e006-i0065 => L=8.023 acc= 62% / t(ms):   4.9  71.1 388.5)\n",
      "self.output_loss= tensor(0.0486, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2099, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0502, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2149, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0586, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0387, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e006-i0068 => L=8.097 acc= 60% / t(ms):   5.1  71.2 386.4)\n",
      "self.output_loss= tensor(0.1346, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3454, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0647, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3571, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0487, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3293, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e006-i0071 => L=8.378 acc= 66% / t(ms):   5.4  71.2 395.6)\n",
      "self.output_loss= tensor(0.2008, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2871, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1545, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4735, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0396, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1417, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e006-i0074 => L=8.181 acc= 64% / t(ms):   5.3  71.1 402.3)\n",
      "self.output_loss= tensor(0.0586, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1736, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0863, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4493, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1209, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.5336, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e006-i0077 => L=8.655 acc= 49% / t(ms):   5.1  71.2 395.4)\n",
      "self.output_loss= tensor(0.0825, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4825, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0659, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4323, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0515, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0098, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e006-i0080 => L=8.061 acc= 52% / t(ms):   6.0  72.7 390.0)\n",
      "self.output_loss= tensor(0.0814, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1480, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0663, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0476, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0665, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2544, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e006-i0083 => L=8.321 acc= 61% / t(ms):   5.8  71.6 393.3)\n",
      "self.output_loss= tensor(0.1179, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2191, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0909, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0323, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2045, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.9575, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e006-i0086 => L=9.162 acc= 43% / t(ms):   9.5  70.4 382.4)\n",
      "self.output_loss= tensor(0.0568, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0208, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0544, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0391, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0706, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0021, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e006-i0089 => L=8.073 acc= 71% / t(ms):   8.2  72.8 385.8)\n",
      "self.output_loss= tensor(0.2362, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9436, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0664, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.5367, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0435, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2197, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e006-i0092 => L=8.263 acc= 66% / t(ms):   8.2  72.6 388.3)\n",
      "self.output_loss= tensor(0.0765, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0411, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0617, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0437, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e006-i0094 => L=8.105 acc= 53% / t(ms):   7.4  71.2 398.2)\n",
      "self.output_loss= tensor(0.0612, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0815, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0784, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3398, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0527, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3326, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e006-i0097 => L=8.385 acc= 61% / t(ms):   6.5  69.3 393.2)\n",
      "self.output_loss= tensor(0.0955, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1499, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0400, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.5301, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Validation : 4.0% (timings : 34.08 7.89)\n",
      "Validation : 27.0% (timings : 20.43 22.50)\n",
      "Validation : 51.0% (timings : 13.33 28.78)\n",
      "Validation : 78.0% (timings : 8.57 30.13)\n",
      "field_list[0].shape[0] is 382707\n",
      "AHN mean IoU = 71.5%\n",
      "self.output_loss= tensor(0.0702, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1234, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e007-i0000 => L=8.194 acc= 70% / t(ms): 6366.4 104.4 430.6)\n",
      "self.output_loss= tensor(0.0745, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1302, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0882, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1279, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0764, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2723, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e007-i0003 => L=8.349 acc= 49% / t(ms):  20.9  75.3 373.6)\n",
      "self.output_loss= tensor(0.0360, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.5059, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1416, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3594, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0480, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3299, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e007-i0006 => L=8.378 acc= 49% / t(ms):  16.6  74.1 377.9)\n",
      "self.output_loss= tensor(0.0991, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3426, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0694, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3578, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0688, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3350, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e007-i0009 => L=8.404 acc= 71% / t(ms):  13.7  73.4 389.2)\n",
      "self.output_loss= tensor(0.1699, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4502, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2591, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.1907, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0717, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2121, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e007-i0012 => L=8.284 acc= 58% / t(ms):  11.3  73.3 379.5)\n",
      "self.output_loss= tensor(0.0805, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1904, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0793, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4315, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2743, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1571, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e007-i0015 => L=8.431 acc= 55% / t(ms):   9.6  72.7 373.6)\n",
      "self.output_loss= tensor(0.1412, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2235, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2401, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.8950, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0745, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3537, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e007-i0018 => L=8.428 acc= 58% / t(ms):   8.4  72.4 376.7)\n",
      "self.output_loss= tensor(0.1287, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3360, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1006, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.5138, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0693, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.7721, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e007-i0021 => L=8.841 acc= 60% / t(ms):   7.5  72.1 377.2)\n",
      "self.output_loss= tensor(0.1414, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4204, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1251, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1117, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0285, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.5737, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e007-i0024 => L=8.602 acc= 54% / t(ms):   6.8  72.0 376.3)\n",
      "self.output_loss= tensor(0.0570, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3364, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0490, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4761, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0855, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2754, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e007-i0027 => L=8.361 acc= 53% / t(ms):   6.4  72.1 375.2)\n",
      "self.output_loss= tensor(0.1072, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.5530, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1016, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.5252, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1664, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(9.1486, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e007-i0030 => L=9.315 acc= 39% / t(ms):   6.2  71.7 363.1)\n",
      "self.output_loss= tensor(0.2093, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.7482, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0910, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.5618, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2095, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3163, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e007-i0033 => L=8.526 acc= 48% / t(ms):   6.1  71.7 364.1)\n",
      "self.output_loss= tensor(0.0867, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.5053, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0517, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4191, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e007-i0035 => L=8.471 acc= 72% / t(ms):   6.1  71.5 377.8)\n",
      "self.output_loss= tensor(0.1265, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2380, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1308, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3391, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0415, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0559, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e007-i0038 => L=8.097 acc= 70% / t(ms):   6.2  71.6 392.0)\n",
      "self.output_loss= tensor(0.1420, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2663, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1097, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.5458, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0614, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.8540, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e007-i0041 => L=8.915 acc= 57% / t(ms):   6.0  71.5 388.7)\n",
      "self.output_loss= tensor(0.0783, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.8722, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0648, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4742, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e007-i0043 => L=8.539 acc= 64% / t(ms):   5.8  71.5 398.9)\n",
      "self.output_loss= tensor(0.0583, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.6246, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1579, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4970, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1548, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.8326, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e007-i0046 => L=8.987 acc= 55% / t(ms):   5.9  71.4 389.9)\n",
      "self.output_loss= tensor(0.3958, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3798, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1388, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.6110, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0628, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.5466, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e007-i0049 => L=8.609 acc= 65% / t(ms):   5.6  71.4 391.8)\n",
      "self.output_loss= tensor(0.0864, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0665, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1006, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1949, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1180, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.5011, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e007-i0052 => L=8.619 acc= 58% / t(ms):   5.4  71.4 390.5)\n",
      "self.output_loss= tensor(0.0908, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0632, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1112, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3584, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e007-i0054 => L=8.470 acc= 66% / t(ms):   5.3  71.4 396.8)\n",
      "self.output_loss= tensor(0.1265, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.5036, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2546, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.9517, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0636, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4304, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e007-i0057 => L=8.494 acc= 53% / t(ms):   5.3  71.5 390.7)\n",
      "self.output_loss= tensor(0.0818, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3156, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0619, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2256, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e007-i0059 => L=8.288 acc= 66% / t(ms):   5.3  71.6 399.7)\n",
      "self.output_loss= tensor(0.0419, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.7328, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2446, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4946, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0648, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3449, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e007-i0062 => L=8.410 acc= 52% / t(ms):   5.2  71.8 392.3)\n",
      "self.output_loss= tensor(0.1237, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.9218, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0696, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.5754, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2917, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1561, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e007-i0065 => L=8.448 acc= 70% / t(ms):   5.4  71.5 393.0)\n",
      "self.output_loss= tensor(0.0558, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.5432, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1906, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1379, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1187, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4820, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e007-i0068 => L=8.601 acc= 44% / t(ms):   5.3  71.4 386.8)\n",
      "self.output_loss= tensor(0.1005, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0858, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0785, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.6643, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0617, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2164, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e007-i0071 => L=8.278 acc= 51% / t(ms):   5.2  71.3 382.9)\n",
      "self.output_loss= tensor(0.1515, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0408, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0996, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3653, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1189, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.9159, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e007-i0074 => L=9.035 acc= 51% / t(ms):   5.1  71.1 378.8)\n",
      "self.output_loss= tensor(0.1145, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9953, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1970, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1328, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1534, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1964, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e007-i0077 => L=8.350 acc= 72% / t(ms):   5.1  71.2 389.8)\n",
      "self.output_loss= tensor(0.1311, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3860, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0577, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2079, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e007-i0079 => L=8.266 acc= 56% / t(ms):   5.3  71.1 397.2)\n",
      "self.output_loss= tensor(0.0791, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1963, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0681, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9974, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1187, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2968, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e007-i0082 => L=8.415 acc= 76% / t(ms):   5.4  69.9 395.0)\n",
      "self.output_loss= tensor(0.0609, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3234, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0556, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.7935, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0813, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9437, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e007-i0085 => L=8.025 acc= 68% / t(ms):   5.2  68.5 395.2)\n",
      "self.output_loss= tensor(0.0728, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.5215, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1325, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2740, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1099, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0394, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e007-i0088 => L=8.149 acc= 58% / t(ms):   5.0  67.7 395.0)\n",
      "self.output_loss= tensor(0.0500, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1956, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2578, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3730, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0650, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1646, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e007-i0091 => L=8.230 acc= 58% / t(ms):   4.9  67.0 391.2)\n",
      "self.output_loss= tensor(0.0991, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2661, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0769, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0570, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0970, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4908, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e007-i0094 => L=8.588 acc= 58% / t(ms):   5.0  66.4 389.8)\n",
      "self.output_loss= tensor(0.0620, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0457, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0464, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1141, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0632, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.6985, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e007-i0097 => L=8.762 acc= 70% / t(ms):   5.2  66.7 396.4)\n",
      "self.output_loss= tensor(0.1319, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4525, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0450, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2646, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Validation : 2.0% (timings : 39.25 6.87)\n",
      "Validation : 27.0% (timings : 17.16 24.97)\n",
      "Validation : 52.0% (timings : 10.77 29.97)\n",
      "Validation : 80.0% (timings : 8.68 30.76)\n",
      "field_list[0].shape[0] is 382707\n",
      "AHN mean IoU = 74.1%\n",
      "self.output_loss= tensor(0.0689, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2823, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e008-i0000 => L=8.351 acc= 56% / t(ms): 6340.7  92.4 403.4)\n",
      "self.output_loss= tensor(0.0698, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2907, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0581, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.5555, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1010, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0332, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e008-i0003 => L=8.134 acc= 58% / t(ms):  26.8  81.6 379.5)\n",
      "self.output_loss= tensor(0.1444, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.5391, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0946, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.7006, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0578, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9816, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e008-i0006 => L=8.039 acc= 60% / t(ms):  21.1  78.7 377.1)\n",
      "self.output_loss= tensor(0.1018, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3947, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0432, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1874, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0738, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0091, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e008-i0009 => L=8.083 acc= 57% / t(ms):  16.7  76.6 376.8)\n",
      "self.output_loss= tensor(0.4465, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.8001, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1096, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4747, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0934, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4407, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e008-i0012 => L=8.534 acc= 66% / t(ms):  13.8  75.3 359.1)\n",
      "self.output_loss= tensor(0.2413, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8082, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0677, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3701, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e008-i0014 => L=8.438 acc= 65% / t(ms):  12.1  74.5 374.0)\n",
      "self.output_loss= tensor(0.0455, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2586, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0651, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0435, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1593, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0334, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e008-i0017 => L=8.193 acc= 63% / t(ms):  10.2  73.7 381.8)\n",
      "self.output_loss= tensor(0.0728, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1970, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0628, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3395, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0538, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2288, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e008-i0020 => L=8.283 acc= 57% / t(ms):   9.0  73.2 391.6)\n",
      "self.output_loss= tensor(0.0692, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0013, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1095, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.5345, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1796, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.8336, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e008-i0023 => L=9.013 acc= 54% / t(ms):   7.9  72.5 386.3)\n",
      "self.output_loss= tensor(0.0719, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9212, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0538, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3343, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e008-i0025 => L=8.388 acc= 57% / t(ms):   7.6  72.1 394.8)\n",
      "self.output_loss= tensor(0.0989, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1810, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1328, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2592, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e008-i0027 => L=8.392 acc= 65% / t(ms):   7.2  72.0 401.9)\n",
      "self.output_loss= tensor(0.0918, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9812, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0901, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0675, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0573, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.5493, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e008-i0030 => L=8.607 acc= 55% / t(ms):   6.7  71.9 398.4)\n",
      "self.output_loss= tensor(0.0604, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2622, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0678, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0172, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0867, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9121, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e008-i0033 => L=7.999 acc= 66% / t(ms):   6.2  71.7 404.4)\n",
      "self.output_loss= tensor(0.0740, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1685, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0743, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8531, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.3240, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.5328, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e008-i0036 => L=8.857 acc= 40% / t(ms):   6.1  71.6 400.9)\n",
      "self.output_loss= tensor(0.0472, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0287, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1156, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3194, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1076, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9195, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e008-i0039 => L=8.027 acc= 58% / t(ms):   5.8  71.2 390.0)\n",
      "self.output_loss= tensor(0.0257, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2629, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0467, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7867, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1162, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1887, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e008-i0042 => L=8.305 acc= 50% / t(ms):   5.5  70.9 385.8)\n",
      "self.output_loss= tensor(0.2329, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2578, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0920, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3279, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e008-i0044 => L=8.420 acc= 64% / t(ms):   5.4  70.7 398.3)\n",
      "self.output_loss= tensor(0.1123, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8365, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0731, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9971, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0799, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0811, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e008-i0047 => L=8.161 acc= 56% / t(ms):   5.3  70.7 399.3)\n",
      "self.output_loss= tensor(0.0735, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2021, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1061, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9646, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0814, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7261, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e008-i0050 => L=7.807 acc= 76% / t(ms):   5.4  71.0 399.2)\n",
      "self.output_loss= tensor(0.1689, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.5787, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0843, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9083, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0799, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9358, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e008-i0053 => L=8.016 acc= 59% / t(ms):   5.7  70.8 392.4)\n",
      "self.output_loss= tensor(0.1098, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1753, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0555, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7396, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0759, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0169, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e008-i0056 => L=8.093 acc= 60% / t(ms):   5.4  70.7 393.5)\n",
      "self.output_loss= tensor(0.0549, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0454, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0639, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3086, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0731, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8028, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e008-i0059 => L=7.876 acc= 49% / t(ms):   5.3  70.6 388.7)\n",
      "self.output_loss= tensor(0.2372, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8853, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1283, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8940, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e008-i0061 => L=8.022 acc= 74% / t(ms):   5.2  70.7 400.7)\n",
      "self.output_loss= tensor(0.0775, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0603, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0579, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1307, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0938, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.5842, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e008-i0064 => L=8.678 acc= 49% / t(ms):   5.0  70.5 386.1)\n",
      "self.output_loss= tensor(0.0965, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1689, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1072, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0964, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0846, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2458, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e008-i0067 => L=8.330 acc= 52% / t(ms):   5.0  70.5 388.9)\n",
      "self.output_loss= tensor(0.0870, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1522, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1242, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1264, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e008-i0069 => L=8.251 acc= 59% / t(ms):   5.0  70.5 400.7)\n",
      "self.output_loss= tensor(0.0398, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9865, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0580, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9109, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e008-i0071 => L=7.969 acc= 67% / t(ms):   5.0  70.7 405.7)\n",
      "self.output_loss= tensor(0.0466, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8844, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0950, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3443, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0765, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2653, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e008-i0074 => L=8.342 acc= 58% / t(ms):   5.3  70.8 412.0)\n",
      "self.output_loss= tensor(0.2310, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0493, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0888, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9688, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0779, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0095, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e008-i0077 => L=8.087 acc= 55% / t(ms):   5.4  70.6 402.3)\n",
      "self.output_loss= tensor(0.1463, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9328, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0712, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7827, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0413, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9179, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e008-i0080 => L=7.959 acc= 64% / t(ms):   5.3  70.3 404.0)\n",
      "self.output_loss= tensor(0.0684, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6682, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0856, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2148, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0536, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0970, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e008-i0083 => L=8.151 acc= 75% / t(ms):   5.1  68.6 413.1)\n",
      "self.output_loss= tensor(0.0751, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0081, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0681, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4038, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0499, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2937, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e008-i0086 => L=8.344 acc= 56% / t(ms):   4.9  67.1 401.4)\n",
      "self.output_loss= tensor(0.0773, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9398, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1271, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3092, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0853, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8498, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e008-i0089 => L=7.935 acc= 70% / t(ms):   5.0  66.2 400.5)\n",
      "self.output_loss= tensor(0.0375, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9813, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0701, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9910, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1605, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9785, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e008-i0092 => L=8.139 acc= 53% / t(ms):   4.7  65.4 394.2)\n",
      "self.output_loss= tensor(0.0839, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2042, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0510, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3362, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0630, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7929, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e008-i0095 => L=7.856 acc= 54% / t(ms):   4.6  64.8 385.3)\n",
      "self.output_loss= tensor(0.1121, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0141, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1719, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0097, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0627, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6166, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e008-i0098 => L=7.679 acc= 59% / t(ms):   4.9  64.6 377.4)\n",
      "self.output_loss= tensor(0.1152, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1736, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Validation : 4.0% (timings : 34.49 7.31)\n",
      "Validation : 28.0% (timings : 18.27 22.65)\n",
      "Validation : 52.0% (timings : 13.52 27.97)\n",
      "Validation : 77.0% (timings : 10.75 29.78)\n",
      "field_list[0].shape[0] is 382707\n",
      "AHN mean IoU = 70.1%\n",
      "self.output_loss= tensor(0.0954, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9187, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e009-i0000 => L=8.014 acc= 63% / t(ms): 6396.7  89.9 391.3)\n",
      "self.output_loss= tensor(0.0632, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1774, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0611, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6874, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e009-i0002 => L=7.749 acc= 52% / t(ms):  24.2  88.2 387.6)\n",
      "self.output_loss= tensor(0.0713, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3746, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1740, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9742, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e009-i0004 => L=8.148 acc= 62% / t(ms):  21.6  85.6 398.3)\n",
      "self.output_loss= tensor(0.1065, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7938, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1329, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3551, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e009-i0006 => L=8.488 acc= 70% / t(ms):  18.7  84.3 404.5)\n",
      "self.output_loss= tensor(0.0376, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1831, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0595, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7633, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0674, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4771, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e009-i0009 => L=8.544 acc= 61% / t(ms):  16.5  84.9 400.4)\n",
      "self.output_loss= tensor(0.0387, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0388, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0853, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9726, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0564, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9759, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e009-i0012 => L=8.032 acc= 51% / t(ms):  13.7  81.1 388.3)\n",
      "self.output_loss= tensor(0.0701, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9757, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0531, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3811, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0801, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0031, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e009-i0015 => L=8.083 acc= 61% / t(ms):  11.4  78.3 390.2)\n",
      "self.output_loss= tensor(0.0399, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6340, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0688, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0248, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e009-i0017 => L=8.094 acc= 63% / t(ms):  10.2  76.5 402.7)\n",
      "self.output_loss= tensor(0.0512, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2847, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1551, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9751, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0559, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8882, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e009-i0020 => L=7.944 acc= 55% / t(ms):   8.8  74.9 394.2)\n",
      "self.output_loss= tensor(0.1131, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0097, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0657, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8164, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0870, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9836, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e009-i0023 => L=8.071 acc= 60% / t(ms):   7.7  73.7 392.2)\n",
      "self.output_loss= tensor(0.0277, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8304, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0230, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0903, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0698, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0037, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e009-i0026 => L=8.073 acc= 66% / t(ms):   7.0  72.9 393.8)\n",
      "self.output_loss= tensor(0.1195, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1330, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0269, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0507, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0946, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0657, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e009-i0029 => L=8.160 acc= 55% / t(ms):   6.4  72.3 391.7)\n",
      "self.output_loss= tensor(0.0705, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0674, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0442, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0633, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0637, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0793, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e009-i0032 => L=8.143 acc= 62% / t(ms):   6.1  72.0 394.1)\n",
      "self.output_loss= tensor(0.0486, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7742, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2992, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1532, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1312, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0787, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e009-i0035 => L=8.210 acc= 50% / t(ms):   6.0  71.6 393.1)\n",
      "self.output_loss= tensor(0.0599, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4375, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0435, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8424, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e009-i0037 => L=7.886 acc= 63% / t(ms):   5.7  71.3 400.8)\n",
      "self.output_loss= tensor(0.0553, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8989, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0718, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.5558, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0822, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9322, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e009-i0040 => L=8.014 acc= 74% / t(ms):   5.5  71.4 405.6)\n",
      "self.output_loss= tensor(0.0211, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0430, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0533, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9808, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0543, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2352, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e009-i0043 => L=8.289 acc= 55% / t(ms):   5.4  71.2 394.5)\n",
      "self.output_loss= tensor(0.0524, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1615, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1427, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1182, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e009-i0045 => L=8.261 acc= 66% / t(ms):   5.3  71.1 401.7)\n",
      "self.output_loss= tensor(0.0554, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.6506, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0798, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2397, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0915, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6041, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e009-i0048 => L=7.696 acc= 69% / t(ms):   5.3  71.1 406.0)\n",
      "self.output_loss= tensor(0.0836, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1851, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0536, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6705, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0512, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2536, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e009-i0051 => L=8.305 acc= 47% / t(ms):   5.2  71.1 394.1)\n",
      "self.output_loss= tensor(0.0314, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1364, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0557, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5802, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0527, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.5619, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e009-i0054 => L=8.615 acc= 44% / t(ms):   5.1  71.0 387.6)\n",
      "self.output_loss= tensor(0.0629, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5169, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0370, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8217, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e009-i0056 => L=7.859 acc= 60% / t(ms):   5.2  70.9 394.7)\n",
      "self.output_loss= tensor(0.1108, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8085, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0818, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8582, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0829, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7424, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e009-i0059 => L=7.825 acc= 53% / t(ms):   5.4  70.9 392.9)\n",
      "self.output_loss= tensor(0.0633, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1086, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1978, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8987, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0522, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5334, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e009-i0062 => L=7.586 acc= 67% / t(ms):   5.3  70.9 392.3)\n",
      "self.output_loss= tensor(0.0488, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7946, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2654, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8652, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0572, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0518, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e009-i0065 => L=8.109 acc= 58% / t(ms):   5.2  71.0 392.3)\n",
      "self.output_loss= tensor(0.0766, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0710, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0537, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7499, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1183, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0921, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e009-i0068 => L=8.210 acc= 59% / t(ms):   5.6  70.8 385.7)\n",
      "self.output_loss= tensor(0.0454, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8534, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0678, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6291, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1213, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9907, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e009-i0071 => L=8.112 acc= 45% / t(ms):   5.5  71.1 386.4)\n",
      "self.output_loss= tensor(0.1646, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9130, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0447, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7687, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0653, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7979, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e009-i0074 => L=7.863 acc= 63% / t(ms):   5.4  71.1 385.8)\n",
      "self.output_loss= tensor(0.0411, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9507, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0791, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7220, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0693, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6753, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e009-i0077 => L=7.745 acc= 63% / t(ms):   5.3  71.0 395.8)\n",
      "self.output_loss= tensor(0.0891, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8144, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1700, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7850, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e009-i0079 => L=7.955 acc= 70% / t(ms):   5.2  70.8 408.4)\n",
      "self.output_loss= tensor(0.0853, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8189, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0524, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9170, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0436, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0020, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e009-i0082 => L=8.046 acc= 49% / t(ms):   5.2  69.6 397.5)\n",
      "self.output_loss= tensor(0.1157, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7418, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0746, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.6295, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0445, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2470, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e009-i0085 => L=8.291 acc= 74% / t(ms):   5.0  68.4 406.9)\n",
      "self.output_loss= tensor(0.1776, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0318, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0402, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0093, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1490, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8195, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e009-i0088 => L=7.969 acc= 65% / t(ms):   5.1  67.6 401.6)\n",
      "self.output_loss= tensor(0.1318, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3190, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0414, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9387, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0680, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0292, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e009-i0091 => L=8.097 acc= 62% / t(ms):   4.9  66.9 401.5)\n",
      "self.output_loss= tensor(0.0958, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8166, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1171, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9616, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0642, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1831, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e009-i0094 => L=8.247 acc= 61% / t(ms):   4.9  66.4 391.7)\n",
      "self.output_loss= tensor(0.1220, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0441, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1641, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4538, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0558, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8447, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e009-i0097 => L=7.900 acc= 64% / t(ms):   5.1  66.2 398.5)\n",
      "self.output_loss= tensor(0.0514, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7705, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1166, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4712, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Validation : 1.0% (timings : 43.88 4.69)\n",
      "Validation : 22.0% (timings : 29.91 22.57)\n",
      "Validation : 47.0% (timings : 15.84 27.82)\n",
      "Validation : 72.0% (timings : 10.34 31.25)\n",
      "Validation : 97.0% (timings : 11.70 29.50)\n",
      "field_list[0].shape[0] is 382707\n",
      "AHN mean IoU = 73.4%\n",
      "self.output_loss= tensor(0.0329, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8787, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e010-i0000 => L=7.912 acc= 55% / t(ms): 6733.1  93.2 370.0)\n",
      "self.output_loss= tensor(0.0845, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0865, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1097, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2572, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0959, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4235, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e010-i0003 => L=8.519 acc= 36% / t(ms):  22.4  78.8 350.2)\n",
      "self.output_loss= tensor(0.0300, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1350, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1051, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.8585, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1219, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2899, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e010-i0006 => L=8.412 acc= 50% / t(ms):  17.6  76.9 340.9)\n",
      "self.output_loss= tensor(0.0400, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8229, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0470, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0282, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1159, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6561, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e010-i0009 => L=7.772 acc= 62% / t(ms):  14.4  75.4 357.1)\n",
      "self.output_loss= tensor(0.0862, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7457, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0537, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8364, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0652, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2999, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e010-i0012 => L=8.365 acc= 69% / t(ms):  16.0  74.5 377.8)\n",
      "self.output_loss= tensor(0.2244, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7431, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0511, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7229, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0712, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7165, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e010-i0015 => L=7.788 acc= 54% / t(ms):  13.3  74.9 380.1)\n",
      "self.output_loss= tensor(0.0260, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9998, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0766, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9913, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0666, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9083, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e010-i0018 => L=7.975 acc= 41% / t(ms):  11.1  73.8 369.9)\n",
      "self.output_loss= tensor(0.0680, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6523, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1220, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8309, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e010-i0020 => L=7.953 acc= 61% / t(ms):  10.6  79.7 373.5)\n",
      "self.output_loss= tensor(0.0598, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8145, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0719, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4331, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1943, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1595, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e010-i0023 => L=8.354 acc= 50% / t(ms):  11.3  83.4 370.6)\n",
      "self.output_loss= tensor(0.1066, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8144, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0502, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5845, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e010-i0025 => L=7.635 acc= 65% / t(ms):  10.9  82.4 379.0)\n",
      "self.output_loss= tensor(0.0813, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7686, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0732, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1864, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0890, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9893, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e010-i0028 => L=8.078 acc= 51% / t(ms):   9.2  79.5 380.1)\n",
      "self.output_loss= tensor(0.1304, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0924, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0550, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9796, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0695, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8723, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e010-i0031 => L=7.942 acc= 60% / t(ms):   8.3  77.3 387.5)\n",
      "self.output_loss= tensor(0.0237, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0072, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1812, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9738, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0595, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9850, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e010-i0034 => L=8.044 acc= 59% / t(ms):   7.4  75.7 384.3)\n",
      "self.output_loss= tensor(0.0502, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7254, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0307, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9561, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e010-i0036 => L=7.987 acc= 60% / t(ms):   7.2  74.7 391.9)\n",
      "self.output_loss= tensor(0.0571, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3262, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1015, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0356, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0600, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0007, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e010-i0039 => L=8.061 acc= 67% / t(ms):   6.6  73.9 397.9)\n",
      "self.output_loss= tensor(0.0672, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6724, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0372, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2452, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0528, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8050, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e010-i0042 => L=7.858 acc= 61% / t(ms):   6.2  73.2 392.2)\n",
      "self.output_loss= tensor(0.0943, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8745, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1225, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9144, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0494, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8518, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e010-i0045 => L=7.901 acc= 62% / t(ms):   5.9  72.5 384.6)\n",
      "self.output_loss= tensor(0.0803, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0511, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0575, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5337, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0653, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9716, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e010-i0048 => L=8.037 acc= 64% / t(ms):   5.6  72.2 380.8)\n",
      "self.output_loss= tensor(0.1144, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6855, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0499, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9811, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e010-i0050 => L=8.031 acc= 62% / t(ms):   5.5  72.0 391.0)\n",
      "self.output_loss= tensor(0.0494, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9983, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0874, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7334, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1128, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1133, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e010-i0053 => L=8.226 acc= 47% / t(ms):   5.4  71.9 391.2)\n",
      "self.output_loss= tensor(0.0459, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0184, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1296, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8301, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1311, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9350, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e010-i0056 => L=8.066 acc= 59% / t(ms):   5.3  71.7 386.9)\n",
      "self.output_loss= tensor(0.0399, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1827, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0747, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7191, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0418, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5846, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e010-i0059 => L=7.626 acc= 72% / t(ms):   5.2  71.7 394.6)\n",
      "self.output_loss= tensor(0.0288, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8745, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0659, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0213, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1648, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2714, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e010-i0062 => L=8.436 acc= 51% / t(ms):   5.3  71.6 388.2)\n",
      "self.output_loss= tensor(0.0335, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1378, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0877, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1100, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e010-i0064 => L=8.198 acc= 73% / t(ms):   5.3  71.9 395.3)\n",
      "self.output_loss= tensor(0.0735, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0627, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0386, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8790, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0746, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0302, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e010-i0067 => L=8.105 acc= 75% / t(ms):   5.2  71.8 394.9)\n",
      "self.output_loss= tensor(0.0691, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7464, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0619, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9616, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0937, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.5256, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e010-i0070 => L=8.619 acc= 44% / t(ms):   5.2  71.7 390.2)\n",
      "self.output_loss= tensor(0.0845, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8738, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0691, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0059, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0444, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2839, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e010-i0073 => L=8.328 acc= 62% / t(ms):   5.1  71.9 390.2)\n",
      "self.output_loss= tensor(0.0559, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1335, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0659, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7930, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e010-i0075 => L=7.859 acc= 75% / t(ms):   5.1  71.9 397.3)\n",
      "self.output_loss= tensor(0.1269, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1618, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0577, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9391, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0282, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1831, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e010-i0078 => L=8.211 acc= 51% / t(ms):   5.0  71.6 400.4)\n",
      "self.output_loss= tensor(0.0723, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7930, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0551, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2757, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0561, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8874, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e010-i0081 => L=7.944 acc= 69% / t(ms):   5.0  70.8 393.8)\n",
      "self.output_loss= tensor(0.0844, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9628, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0444, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9306, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0457, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5569, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e010-i0084 => L=7.603 acc= 56% / t(ms):   4.9  69.1 382.6)\n",
      "self.output_loss= tensor(0.0588, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0266, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0424, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4438, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0663, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9502, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e010-i0087 => L=8.016 acc= 59% / t(ms):   5.0  68.0 378.8)\n",
      "self.output_loss= tensor(0.1076, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1548, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0417, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9508, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1888, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8946, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e010-i0090 => L=8.083 acc= 37% / t(ms):   4.9  67.0 366.0)\n",
      "self.output_loss= tensor(0.0600, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0330, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1190, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9368, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0401, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7486, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e010-i0093 => L=7.789 acc= 55% / t(ms):   5.0  66.6 373.9)\n",
      "self.output_loss= tensor(0.1736, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1821, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0674, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7523, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0412, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7926, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e010-i0096 => L=7.834 acc= 53% / t(ms):   4.9  66.3 369.5)\n",
      "self.output_loss= tensor(0.1738, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7614, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0930, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6517, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0794, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6737, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e010-i0099 => L=7.753 acc= 48% / t(ms):   4.9  65.8 372.6)\n",
      "Validation : 3.0% (timings : 37.86 5.99)\n",
      "Validation : 27.0% (timings : 19.86 22.06)\n",
      "Validation : 51.0% (timings : 13.86 28.11)\n",
      "Validation : 80.0% (timings : 9.19 30.24)\n",
      "field_list[0].shape[0] is 382707\n",
      "AHN mean IoU = 68.9%\n",
      "self.output_loss= tensor(0.0693, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1403, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e011-i0000 => L=8.210 acc= 68% / t(ms): 6194.2 103.0 498.6)\n",
      "self.output_loss= tensor(0.0730, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8718, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0481, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9202, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0723, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9356, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e011-i0003 => L=8.008 acc= 41% / t(ms):  21.1  75.3 339.1)\n",
      "self.output_loss= tensor(0.1380, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9929, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.3265, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5209, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e011-i0005 => L=7.847 acc= 66% / t(ms):  18.2  74.5 356.0)\n",
      "self.output_loss= tensor(0.2666, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9069, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1066, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9385, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0502, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3196, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e011-i0008 => L=8.370 acc= 64% / t(ms):  14.7  73.8 359.6)\n",
      "self.output_loss= tensor(0.0426, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9615, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0536, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0908, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0493, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6210, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e011-i0011 => L=7.670 acc= 63% / t(ms):  12.1  73.1 370.5)\n",
      "self.output_loss= tensor(0.0460, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7286, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0394, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6670, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0853, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6950, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e011-i0014 => L=7.780 acc= 48% / t(ms):  10.3  72.5 369.6)\n",
      "self.output_loss= tensor(0.0252, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2891, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0204, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7821, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1531, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9668, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e011-i0017 => L=8.120 acc= 58% / t(ms):   8.9  72.3 376.0)\n",
      "self.output_loss= tensor(0.0649, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7005, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1014, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6587, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2112, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9583, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e011-i0020 => L=8.170 acc= 47% / t(ms):   8.0  71.8 373.6)\n",
      "self.output_loss= tensor(0.0700, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6584, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0645, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7943, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e011-i0022 => L=7.859 acc= 61% / t(ms):   7.4  71.3 390.3)\n",
      "self.output_loss= tensor(0.3353, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4881, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0441, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1201, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0619, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1356, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e011-i0025 => L=8.197 acc= 57% / t(ms):   6.8  71.1 384.2)\n",
      "self.output_loss= tensor(0.0782, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9306, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2808, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2444, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e011-i0027 => L=8.525 acc= 52% / t(ms):   6.8  73.3 391.7)\n",
      "self.output_loss= tensor(0.0737, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3848, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0582, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8794, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1589, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0063, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e011-i0030 => L=8.165 acc= 44% / t(ms):   6.4  73.7 392.6)\n",
      "self.output_loss= tensor(0.0842, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9809, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0569, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9260, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e011-i0032 => L=7.983 acc= 67% / t(ms):   7.5  78.7 395.3)\n",
      "self.output_loss= tensor(0.0682, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2116, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0704, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2640, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0504, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0724, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e011-i0035 => L=8.123 acc= 58% / t(ms):   7.5  78.5 392.8)\n",
      "self.output_loss= tensor(0.0805, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6673, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0911, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9622, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0846, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1905, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e011-i0038 => L=8.275 acc= 53% / t(ms):   8.3  80.5 393.7)\n",
      "self.output_loss= tensor(0.0609, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1675, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0539, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1228, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1351, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5871, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e011-i0041 => L=7.722 acc= 71% / t(ms):   7.6  77.9 399.6)\n",
      "self.output_loss= tensor(0.0715, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7171, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1421, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6021, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0669, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1389, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e011-i0044 => L=8.206 acc= 50% / t(ms):   6.8  75.9 395.9)\n",
      "self.output_loss= tensor(0.0472, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8397, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1578, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7037, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0763, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9318, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e011-i0047 => L=8.008 acc= 65% / t(ms):   6.6  74.4 395.9)\n",
      "self.output_loss= tensor(0.1026, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7293, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0742, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5520, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0815, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9228, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e011-i0050 => L=8.004 acc= 61% / t(ms):   6.4  73.5 390.3)\n",
      "self.output_loss= tensor(0.1017, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9986, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1193, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8631, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.8908, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7047, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e011-i0053 => L=8.596 acc= 66% / t(ms):   6.0  72.7 406.5)\n",
      "self.output_loss= tensor(0.0640, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7956, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0443, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8511, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0577, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8400, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e011-i0056 => L=7.898 acc= 66% / t(ms):   5.7  72.1 400.9)\n",
      "self.output_loss= tensor(0.0413, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8770, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0954, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2880, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0575, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8864, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e011-i0059 => L=7.944 acc= 73% / t(ms):   5.5  71.5 398.3)\n",
      "self.output_loss= tensor(0.0447, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9924, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0548, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9164, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1287, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8606, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e011-i0062 => L=7.989 acc= 57% / t(ms):   5.4  71.4 394.4)\n",
      "self.output_loss= tensor(0.0814, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9773, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0943, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1356, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0507, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6368, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e011-i0065 => L=7.688 acc= 58% / t(ms):   5.5  71.3 395.6)\n",
      "self.output_loss= tensor(0.0826, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0867, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0628, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7011, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0462, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6020, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e011-i0068 => L=7.648 acc= 56% / t(ms):   5.4  71.1 392.2)\n",
      "self.output_loss= tensor(0.0628, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7741, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0214, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1989, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0659, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2139, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e011-i0071 => L=8.280 acc= 48% / t(ms):   5.2  70.8 379.3)\n",
      "self.output_loss= tensor(0.0396, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5028, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2621, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.5951, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0520, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0753, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e011-i0074 => L=8.127 acc= 71% / t(ms):   5.5  71.0 382.2)\n",
      "self.output_loss= tensor(0.0920, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5989, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0507, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9008, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0381, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8785, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e011-i0077 => L=7.917 acc= 66% / t(ms):   5.4  70.9 388.7)\n",
      "self.output_loss= tensor(0.0530, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9940, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0481, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5364, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e011-i0079 => L=7.585 acc= 70% / t(ms):   5.3  70.8 398.3)\n",
      "self.output_loss= tensor(0.0734, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6990, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1026, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6644, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0665, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5760, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e011-i0082 => L=7.643 acc= 57% / t(ms):   5.1  69.1 393.0)\n",
      "self.output_loss= tensor(0.0607, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7363, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0380, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8440, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e011-i0084 => L=7.882 acc= 69% / t(ms):   5.1  67.9 404.6)\n",
      "self.output_loss= tensor(0.1273, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8848, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0539, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0781, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0306, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7796, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e011-i0087 => L=7.810 acc= 51% / t(ms):   4.9  66.6 384.5)\n",
      "self.output_loss= tensor(0.3067, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4734, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0644, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6325, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0358, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8867, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e011-i0090 => L=7.922 acc= 61% / t(ms):   4.8  65.6 385.6)\n",
      "self.output_loss= tensor(0.0427, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8680, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0793, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1769, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0648, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0063, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e011-i0093 => L=8.071 acc= 49% / t(ms):   4.7  64.9 375.6)\n",
      "self.output_loss= tensor(0.0785, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9503, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0692, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8408, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0767, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8547, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e011-i0096 => L=7.931 acc= 68% / t(ms):   4.7  64.5 388.5)\n",
      "self.output_loss= tensor(0.0334, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5372, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0596, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9051, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0255, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0145, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e011-i0099 => L=8.040 acc= 52% / t(ms):   4.7  64.2 388.7)\n",
      "Validation : 5.0% (timings : 30.32 9.46)\n",
      "Validation : 29.0% (timings : 15.95 24.26)\n",
      "Validation : 52.0% (timings : 13.91 29.17)\n",
      "Validation : 79.0% (timings : 8.62 30.54)\n",
      "field_list[0].shape[0] is 382707\n",
      "AHN mean IoU = 71.1%\n",
      "self.output_loss= tensor(0.0813, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0089, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e012-i0000 => L=8.090 acc= 49% / t(ms): 6479.7  78.3 370.7)\n",
      "self.output_loss= tensor(0.1086, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8642, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0629, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0968, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1673, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7062, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e012-i0003 => L=7.873 acc= 75% / t(ms):  25.2  82.4 348.5)\n",
      "self.output_loss= tensor(0.0694, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6992, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0390, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7409, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2343, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8139, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e012-i0006 => L=8.048 acc= 52% / t(ms):  19.8  79.6 355.3)\n",
      "self.output_loss= tensor(0.0576, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5880, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0498, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7910, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0697, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4894, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e012-i0009 => L=7.559 acc= 59% / t(ms):  16.1  77.6 370.6)\n",
      "self.output_loss= tensor(0.0981, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9845, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1076, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9905, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1105, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6464, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e012-i0012 => L=7.757 acc= 64% / t(ms):  13.1  76.0 370.1)\n",
      "self.output_loss= tensor(0.0543, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7702, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0361, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5560, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0518, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6900, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e012-i0015 => L=7.742 acc= 63% / t(ms):  11.1  74.7 383.2)\n",
      "self.output_loss= tensor(0.0395, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5477, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0526, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3791, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0558, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1169, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e012-i0018 => L=8.173 acc= 48% / t(ms):   9.4  73.7 374.7)\n",
      "self.output_loss= tensor(0.0678, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9478, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1011, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4892, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0786, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8301, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e012-i0021 => L=7.909 acc= 71% / t(ms):   8.2  73.2 384.4)\n",
      "self.output_loss= tensor(0.0386, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6861, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0866, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0211, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0604, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1708, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e012-i0024 => L=8.231 acc= 51% / t(ms):   7.3  72.7 378.6)\n",
      "self.output_loss= tensor(0.0485, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7167, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1064, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5942, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0743, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0492, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e012-i0027 => L=8.123 acc= 61% / t(ms):   6.7  72.7 379.3)\n",
      "self.output_loss= tensor(0.0453, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0683, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0349, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7717, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0960, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7184, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e012-i0030 => L=7.814 acc= 62% / t(ms):   6.3  72.4 386.2)\n",
      "self.output_loss= tensor(0.0445, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8799, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0696, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3212, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1867, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6584, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e012-i0033 => L=7.845 acc= 48% / t(ms):   6.0  72.2 376.6)\n",
      "self.output_loss= tensor(0.1143, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7668, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1415, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2454, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0992, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2293, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e012-i0036 => L=8.329 acc= 51% / t(ms):   5.7  71.9 366.0)\n",
      "self.output_loss= tensor(0.0876, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8516, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0700, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7887, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e012-i0038 => L=7.859 acc= 61% / t(ms):   5.5  71.8 380.1)\n",
      "self.output_loss= tensor(0.0676, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0544, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0472, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6675, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0567, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7741, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e012-i0041 => L=7.831 acc= 74% / t(ms):   5.3  74.8 396.7)\n",
      "self.output_loss= tensor(0.0467, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0676, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0834, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1588, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1426, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8882, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e012-i0044 => L=8.031 acc= 45% / t(ms):   5.3  74.7 394.0)\n",
      "self.output_loss= tensor(0.0741, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9053, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1073, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7074, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0373, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4918, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e012-i0047 => L=7.529 acc= 47% / t(ms):   7.9  78.0 382.7)\n",
      "self.output_loss= tensor(0.0664, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0850, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1234, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2970, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1228, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5753, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e012-i0050 => L=7.698 acc= 77% / t(ms):   7.9  79.8 391.3)\n",
      "self.output_loss= tensor(0.0992, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4092, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0601, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7963, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e012-i0052 => L=7.856 acc= 56% / t(ms):   7.3  83.4 397.5)\n",
      "self.output_loss= tensor(0.0254, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8648, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1278, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0174, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1503, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0420, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e012-i0055 => L=8.192 acc= 43% / t(ms):   6.9  82.4 381.5)\n",
      "self.output_loss= tensor(0.0990, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9427, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0503, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9569, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0383, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9674, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e012-i0058 => L=8.006 acc= 61% / t(ms):   6.4  79.4 388.2)\n",
      "self.output_loss= tensor(0.1399, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8970, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0587, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9366, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e012-i0060 => L=7.995 acc= 68% / t(ms):   6.4  77.9 401.9)\n",
      "self.output_loss= tensor(0.1051, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0912, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1848, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0900, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0441, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8029, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e012-i0063 => L=7.847 acc= 55% / t(ms):   5.9  76.1 385.4)\n",
      "self.output_loss= tensor(0.0415, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7296, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0486, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6854, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e012-i0065 => L=7.734 acc= 69% / t(ms):   5.7  75.2 394.2)\n",
      "self.output_loss= tensor(0.0382, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5462, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0535, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9207, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0564, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8405, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e012-i0068 => L=7.897 acc= 52% / t(ms):   5.5  74.3 390.1)\n",
      "self.output_loss= tensor(0.3437, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3752, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0416, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9534, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0595, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0371, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e012-i0071 => L=8.097 acc= 56% / t(ms):   5.7  73.7 381.4)\n",
      "self.output_loss= tensor(0.0480, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0024, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0448, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7196, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0414, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7680, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e012-i0074 => L=7.809 acc= 68% / t(ms):   5.6  73.1 387.9)\n",
      "self.output_loss= tensor(0.0631, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9191, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0609, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9630, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1362, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5947, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e012-i0077 => L=7.731 acc= 71% / t(ms):   5.8  72.8 394.7)\n",
      "self.output_loss= tensor(0.0590, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7405, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0608, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7160, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0574, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6181, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e012-i0080 => L=7.675 acc= 59% / t(ms):   5.8  72.3 395.9)\n",
      "self.output_loss= tensor(0.0420, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7675, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0351, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3065, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0451, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7669, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e012-i0083 => L=7.812 acc= 52% / t(ms):   5.6  70.3 390.8)\n",
      "self.output_loss= tensor(0.1087, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2412, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0460, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7661, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1414, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8666, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e012-i0086 => L=8.008 acc= 69% / t(ms):   5.4  68.8 399.7)\n",
      "self.output_loss= tensor(0.0662, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9934, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0406, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0024, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1385, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0817, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e012-i0089 => L=8.220 acc= 44% / t(ms):   5.3  67.8 394.2)\n",
      "self.output_loss= tensor(0.0739, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8653, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0662, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7326, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0668, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6688, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e012-i0092 => L=7.736 acc= 55% / t(ms):   5.2  67.0 396.7)\n",
      "self.output_loss= tensor(0.1275, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1016, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0450, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9051, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0395, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0168, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e012-i0095 => L=8.056 acc= 55% / t(ms):   5.1  66.4 390.1)\n",
      "self.output_loss= tensor(0.0451, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6704, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1103, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8906, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0462, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8542, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e012-i0098 => L=7.900 acc= 68% / t(ms):   5.1  66.1 394.8)\n",
      "self.output_loss= tensor(0.0369, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6533, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Validation : 5.0% (timings : 31.30 9.05)\n",
      "Validation : 29.0% (timings : 16.94 23.47)\n",
      "Validation : 53.0% (timings : 12.63 28.80)\n",
      "Validation : 79.0% (timings : 9.59 30.04)\n",
      "field_list[0].shape[0] is 382707\n",
      "AHN mean IoU = 73.7%\n",
      "self.output_loss= tensor(0.0507, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4157, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e013-i0000 => L=7.466 acc= 65% / t(ms): 6301.5 102.8 425.8)\n",
      "self.output_loss= tensor(0.0999, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9229, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0339, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5851, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e013-i0002 => L=7.619 acc= 61% / t(ms):  22.5  90.1 408.8)\n",
      "self.output_loss= tensor(0.0735, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6636, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0683, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8180, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0509, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7164, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e013-i0005 => L=7.767 acc= 58% / t(ms):  17.8  85.1 413.1)\n",
      "self.output_loss= tensor(0.0551, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6624, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0905, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0114, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0444, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5237, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e013-i0008 => L=7.568 acc= 63% / t(ms):  14.3  81.3 409.4)\n",
      "self.output_loss= tensor(0.0709, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6071, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0698, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4611, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1496, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6002, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e013-i0011 => L=7.750 acc= 72% / t(ms):  11.8  78.4 411.5)\n",
      "self.output_loss= tensor(0.0516, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5568, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0388, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9939, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0488, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4336, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e013-i0014 => L=7.482 acc= 64% / t(ms):  10.0  76.5 405.4)\n",
      "self.output_loss= tensor(0.0448, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7604, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0883, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7874, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0555, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6585, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e013-i0017 => L=7.714 acc= 55% / t(ms):   8.6  75.0 398.2)\n",
      "self.output_loss= tensor(0.1386, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9955, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0580, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0678, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0265, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6981, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e013-i0020 => L=7.725 acc= 55% / t(ms):   7.6  74.0 400.2)\n",
      "self.output_loss= tensor(0.0604, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7599, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0767, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9712, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0469, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7734, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e013-i0023 => L=7.820 acc= 62% / t(ms):   7.1  73.6 393.1)\n",
      "self.output_loss= tensor(0.0725, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4561, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0598, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5640, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0389, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0834, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e013-i0026 => L=8.122 acc= 60% / t(ms):   6.6  72.9 394.0)\n",
      "self.output_loss= tensor(0.0527, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6185, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1065, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1345, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0583, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3976, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e013-i0029 => L=8.456 acc= 57% / t(ms):   6.4  72.4 390.4)\n",
      "self.output_loss= tensor(0.0520, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8892, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0459, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8389, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0244, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9790, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e013-i0032 => L=8.003 acc= 61% / t(ms):   6.3  72.2 390.3)\n",
      "self.output_loss= tensor(0.0435, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8692, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0720, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4975, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0959, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6665, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e013-i0035 => L=7.762 acc= 74% / t(ms):   6.0  72.1 396.8)\n",
      "self.output_loss= tensor(0.0579, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8894, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0555, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8498, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e013-i0037 => L=7.905 acc= 69% / t(ms):   5.8  71.8 403.9)\n",
      "self.output_loss= tensor(0.1486, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0532, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0721, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0515, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1380, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8159, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e013-i0040 => L=7.954 acc= 44% / t(ms):   5.9  71.7 390.7)\n",
      "self.output_loss= tensor(0.0281, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8781, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1097, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7413, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0763, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5027, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e013-i0043 => L=7.579 acc= 55% / t(ms):   5.9  71.5 395.8)\n",
      "self.output_loss= tensor(0.0364, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5445, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0534, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5087, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0675, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8301, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e013-i0046 => L=7.898 acc= 43% / t(ms):   5.9  71.4 384.1)\n",
      "self.output_loss= tensor(0.0442, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9826, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0470, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7678, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0600, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3001, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e013-i0049 => L=8.360 acc= 51% / t(ms):   5.7  71.3 380.6)\n",
      "self.output_loss= tensor(0.1126, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7053, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0670, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8835, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1173, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4667, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e013-i0052 => L=7.584 acc= 51% / t(ms):   5.5  71.3 377.7)\n",
      "self.output_loss= tensor(0.0256, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5736, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0559, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8588, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1021, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7435, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e013-i0055 => L=7.846 acc= 46% / t(ms):   5.5  72.2 372.8)\n",
      "self.output_loss= tensor(0.2143, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.3437, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0279, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8713, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0532, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0473, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e013-i0058 => L=8.100 acc= 75% / t(ms):   5.3  71.8 378.2)\n",
      "self.output_loss= tensor(0.0678, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8358, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1130, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7160, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e013-i0060 => L=7.829 acc= 70% / t(ms):   5.9  74.1 385.4)\n",
      "self.output_loss= tensor(0.0512, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8205, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1422, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5168, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e013-i0062 => L=7.659 acc= 66% / t(ms):   8.3  74.9 396.4)\n",
      "self.output_loss= tensor(0.0657, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7711, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0855, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.1682, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1004, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7413, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e013-i0065 => L=7.842 acc= 66% / t(ms):   7.5  74.6 396.6)\n",
      "self.output_loss= tensor(0.1006, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6638, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1006, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5859, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0869, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1102, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e013-i0068 => L=8.197 acc= 44% / t(ms):   9.1  77.0 391.9)\n",
      "self.output_loss= tensor(0.1176, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.3330, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0625, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8637, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e013-i0070 => L=7.926 acc= 54% / t(ms):   8.3  76.0 399.4)\n",
      "self.output_loss= tensor(0.1362, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0135, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1063, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1146, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0412, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6585, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e013-i0073 => L=7.700 acc= 61% / t(ms):   7.5  74.9 389.9)\n",
      "self.output_loss= tensor(0.0657, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9893, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0516, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8038, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0372, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7938, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e013-i0076 => L=7.831 acc= 67% / t(ms):   6.8  74.0 394.3)\n",
      "self.output_loss= tensor(0.0547, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4051, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1065, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8938, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0447, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5439, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e013-i0079 => L=7.589 acc= 68% / t(ms):   6.3  73.2 399.4)\n",
      "self.output_loss= tensor(0.0373, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5777, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0307, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5256, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0536, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0730, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e013-i0082 => L=8.127 acc= 65% / t(ms):   5.9  71.1 400.2)\n",
      "self.output_loss= tensor(0.0695, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7046, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0379, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.3335, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e013-i0084 => L=7.371 acc= 67% / t(ms):   5.6  69.9 409.6)\n",
      "self.output_loss= tensor(0.0546, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6894, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0851, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1927, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0598, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9194, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e013-i0087 => L=7.979 acc= 52% / t(ms):   5.3  68.5 402.8)\n",
      "self.output_loss= tensor(0.0472, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8536, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0905, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9242, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e013-i0089 => L=8.015 acc= 61% / t(ms):   5.3  67.8 409.4)\n",
      "self.output_loss= tensor(0.0581, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8057, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0470, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9169, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0377, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5269, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e013-i0092 => L=7.565 acc= 59% / t(ms):   5.1  67.1 399.6)\n",
      "self.output_loss= tensor(0.0510, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8548, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0482, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7046, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0560, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6569, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e013-i0095 => L=7.713 acc= 62% / t(ms):   4.9  66.4 398.5)\n",
      "self.output_loss= tensor(0.0784, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7016, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0738, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9442, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0354, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2515, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e013-i0098 => L=8.287 acc= 64% / t(ms):   4.8  66.0 398.2)\n",
      "self.output_loss= tensor(0.0487, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6133, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Validation : 4.0% (timings : 33.89 8.38)\n",
      "Validation : 29.0% (timings : 15.81 23.99)\n",
      "Validation : 50.0% (timings : 15.86 28.62)\n",
      "Validation : 76.0% (timings : 10.16 31.19)\n",
      "field_list[0].shape[0] is 382707\n",
      "AHN mean IoU = 71.4%\n",
      "self.output_loss= tensor(0.0639, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5948, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e014-i0000 => L=7.659 acc= 51% / t(ms): 6467.4  99.5 392.7)\n",
      "self.output_loss= tensor(0.0370, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.3170, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2324, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0340, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1000, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1071, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e014-i0003 => L=8.207 acc= 51% / t(ms):  25.5  80.0 341.0)\n",
      "self.output_loss= tensor(0.0481, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5287, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0408, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8906, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e014-i0005 => L=7.931 acc= 59% / t(ms):  21.6  78.2 363.9)\n",
      "self.output_loss= tensor(0.1819, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0974, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0621, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0539, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0578, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0577, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e014-i0008 => L=8.116 acc= 57% / t(ms):  17.5  76.1 367.3)\n",
      "self.output_loss= tensor(0.0401, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8716, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1457, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5358, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0365, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4779, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e014-i0011 => L=7.514 acc= 54% / t(ms):  14.3  74.6 376.7)\n",
      "self.output_loss= tensor(0.0672, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.2590, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0472, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4106, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0619, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9180, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e014-i0014 => L=7.980 acc= 67% / t(ms):  11.7  72.9 383.7)\n",
      "self.output_loss= tensor(0.0957, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9578, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1643, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6311, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0815, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4106, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e014-i0017 => L=7.492 acc= 62% / t(ms):   9.8  72.0 389.4)\n",
      "self.output_loss= tensor(0.1266, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5688, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0514, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1353, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0826, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6031, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e014-i0020 => L=7.686 acc= 51% / t(ms):   8.6  71.6 380.9)\n",
      "self.output_loss= tensor(0.0546, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7618, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0411, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6188, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0868, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4767, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e014-i0023 => L=7.563 acc= 72% / t(ms):   7.7  71.3 387.8)\n",
      "self.output_loss= tensor(0.0591, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.6377, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0446, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5060, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0535, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8286, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e014-i0026 => L=7.882 acc= 58% / t(ms):   6.9  70.6 379.9)\n",
      "self.output_loss= tensor(0.0329, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7199, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0476, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5157, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0638, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6894, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e014-i0029 => L=7.753 acc= 63% / t(ms):   6.3  70.6 382.6)\n",
      "self.output_loss= tensor(0.0453, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2676, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0364, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5356, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1343, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7491, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e014-i0032 => L=7.883 acc= 71% / t(ms):   6.0  70.7 392.3)\n",
      "self.output_loss= tensor(0.0641, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9645, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0747, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5905, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e014-i0034 => L=7.665 acc= 65% / t(ms):   5.8  70.5 400.6)\n",
      "self.output_loss= tensor(0.0408, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5731, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0636, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6374, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0592, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5280, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e014-i0037 => L=7.587 acc= 49% / t(ms):   5.7  70.3 395.7)\n",
      "self.output_loss= tensor(0.0458, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7516, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0471, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6155, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0662, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7748, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e014-i0040 => L=7.841 acc= 65% / t(ms):   5.5  70.3 400.7)\n",
      "self.output_loss= tensor(0.0311, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1635, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0771, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5678, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0770, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5461, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e014-i0043 => L=7.623 acc= 72% / t(ms):   5.3  70.3 404.2)\n",
      "self.output_loss= tensor(0.0604, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8738, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0596, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0079, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1504, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5536, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e014-i0046 => L=7.704 acc= 76% / t(ms):   5.4  70.1 412.1)\n",
      "self.output_loss= tensor(0.0466, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.2778, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0668, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6353, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1817, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5714, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e014-i0049 => L=7.753 acc= 60% / t(ms):   5.5  70.1 406.9)\n",
      "self.output_loss= tensor(0.1506, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1349, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0291, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.2889, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0305, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5086, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e014-i0052 => L=7.539 acc= 55% / t(ms):   5.2  70.0 395.5)\n",
      "self.output_loss= tensor(0.1582, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7871, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0788, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7490, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0526, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5879, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e014-i0055 => L=7.641 acc= 58% / t(ms):   5.2  70.1 395.5)\n",
      "self.output_loss= tensor(0.2009, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8974, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0365, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5708, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0346, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4621, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e014-i0058 => L=7.497 acc= 60% / t(ms):   5.1  70.1 390.1)\n",
      "self.output_loss= tensor(0.0858, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8118, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0408, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5047, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1437, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7840, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e014-i0061 => L=7.928 acc= 32% / t(ms):   5.0  70.2 382.7)\n",
      "self.output_loss= tensor(0.0364, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6136, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0564, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4059, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e014-i0063 => L=7.462 acc= 74% / t(ms):   5.0  70.2 395.4)\n",
      "self.output_loss= tensor(0.0544, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6020, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0198, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7609, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0335, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9086, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e014-i0066 => L=7.942 acc= 61% / t(ms):   4.9  70.1 398.4)\n",
      "self.output_loss= tensor(0.0267, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.3222, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0976, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7751, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0747, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6116, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e014-i0069 => L=7.686 acc= 61% / t(ms):   5.4  71.4 395.7)\n",
      "self.output_loss= tensor(0.0504, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4372, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0603, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.3726, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2651, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4515, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e014-i0072 => L=8.717 acc= 31% / t(ms):   5.9  75.4 381.5)\n",
      "self.output_loss= tensor(0.0867, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4574, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0472, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8384, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0507, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6528, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e014-i0075 => L=7.703 acc= 70% / t(ms):   5.6  76.1 386.5)\n",
      "self.output_loss= tensor(0.0463, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6495, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1880, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.3779, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e014-i0077 => L=7.566 acc= 76% / t(ms):   5.4  75.2 395.2)\n",
      "self.output_loss= tensor(0.0424, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1131, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0527, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8562, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e014-i0079 => L=7.909 acc= 51% / t(ms):   6.5  78.3 396.5)\n",
      "self.output_loss= tensor(0.0431, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5698, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0242, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0701, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1347, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9881, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e014-i0082 => L=8.123 acc= 70% / t(ms):   6.0  74.8 399.5)\n",
      "self.output_loss= tensor(0.0588, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1608, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1456, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7191, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0289, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7300, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e014-i0085 => L=7.759 acc= 45% / t(ms):   5.5  71.9 389.1)\n",
      "self.output_loss= tensor(0.0341, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6178, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0754, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5469, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0646, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8892, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e014-i0088 => L=7.954 acc= 63% / t(ms):   5.6  69.8 392.4)\n",
      "self.output_loss= tensor(0.1331, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0300, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0457, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8084, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0306, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8557, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e014-i0091 => L=7.886 acc= 52% / t(ms):   5.3  68.1 385.9)\n",
      "self.output_loss= tensor(0.0672, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7634, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0508, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7799, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0641, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8465, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e014-i0094 => L=7.911 acc= 59% / t(ms):   5.0  67.0 387.9)\n",
      "self.output_loss= tensor(0.0687, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0184, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1727, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5330, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0677, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7051, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e014-i0097 => L=7.773 acc= 61% / t(ms):   4.8  66.2 394.0)\n",
      "self.output_loss= tensor(0.0278, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.5528, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0437, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7897, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Validation : 5.0% (timings : 30.99 9.53)\n",
      "Validation : 30.0% (timings : 17.99 24.77)\n",
      "Validation : 53.0% (timings : 17.26 28.32)\n",
      "Validation : 80.0% (timings : 8.79 30.66)\n",
      "field_list[0].shape[0] is 382707\n",
      "AHN mean IoU = 69.7%\n",
      "self.output_loss= tensor(0.0593, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7653, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e015-i0000 => L=7.825 acc= 66% / t(ms): 6323.3  93.4 377.0)\n",
      "self.output_loss= tensor(0.0431, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9402, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0624, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5107, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e015-i0002 => L=7.573 acc= 66% / t(ms):  24.0  87.6 378.5)\n",
      "self.output_loss= tensor(0.0587, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5642, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0315, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4889, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0547, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5850, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e015-i0005 => L=7.640 acc= 70% / t(ms):  18.8  83.1 388.2)\n",
      "self.output_loss= tensor(0.0703, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4773, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0560, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6320, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0778, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4735, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e015-i0008 => L=7.551 acc= 60% / t(ms):  14.9  80.0 390.5)\n",
      "self.output_loss= tensor(0.0748, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6881, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0422, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5948, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0539, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5501, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e015-i0011 => L=7.604 acc= 75% / t(ms):  12.5  77.7 397.6)\n",
      "self.output_loss= tensor(0.1315, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4881, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0366, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8240, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0492, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.3992, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e015-i0014 => L=7.448 acc= 70% / t(ms):  10.5  75.9 398.2)\n",
      "self.output_loss= tensor(0.0574, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6577, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0549, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7707, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0733, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5812, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e015-i0017 => L=7.655 acc= 55% / t(ms):   8.9  74.5 390.1)\n",
      "self.output_loss= tensor(0.0274, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7730, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0397, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4626, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0798, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4111, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e015-i0020 => L=7.491 acc= 46% / t(ms):   8.0  73.7 381.4)\n",
      "self.output_loss= tensor(0.0483, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6559, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0709, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6775, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0741, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8147, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e015-i0023 => L=7.889 acc= 48% / t(ms):   7.2  73.2 379.9)\n",
      "self.output_loss= tensor(0.0696, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8853, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0695, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5960, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0553, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4741, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e015-i0026 => L=7.529 acc= 56% / t(ms):   6.6  72.6 377.7)\n",
      "self.output_loss= tensor(0.0387, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5808, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0484, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7403, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0614, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6580, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e015-i0029 => L=7.719 acc= 65% / t(ms):   6.1  72.3 378.8)\n",
      "self.output_loss= tensor(0.1244, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2571, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0702, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5746, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0593, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4692, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e015-i0032 => L=7.529 acc= 66% / t(ms):   6.0  72.0 382.3)\n",
      "self.output_loss= tensor(0.0389, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6945, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0855, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6856, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.2426, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8068, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e015-i0035 => L=8.049 acc= 53% / t(ms):   5.7  71.8 385.5)\n",
      "self.output_loss= tensor(0.0809, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1581, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0883, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5010, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0704, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1417, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e015-i0038 => L=8.212 acc= 45% / t(ms):   5.5  71.9 374.7)\n",
      "self.output_loss= tensor(0.0392, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5566, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0429, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5099, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e015-i0040 => L=7.553 acc= 73% / t(ms):   5.3  71.7 385.9)\n",
      "self.output_loss= tensor(0.0789, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8506, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0585, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0049, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.3531, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4155, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e015-i0043 => L=8.769 acc= 36% / t(ms):   5.3  71.3 385.6)\n",
      "self.output_loss= tensor(0.0756, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6772, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0319, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.3922, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e015-i0045 => L=7.424 acc= 55% / t(ms):   5.1  71.5 393.6)\n",
      "self.output_loss= tensor(0.0413, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9252, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0956, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6030, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0894, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9115, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e015-i0048 => L=8.001 acc= 50% / t(ms):   5.3  71.6 390.4)\n",
      "self.output_loss= tensor(0.0527, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6201, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0363, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7645, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0471, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5788, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e015-i0051 => L=7.626 acc= 74% / t(ms):   5.4  71.6 394.4)\n",
      "self.output_loss= tensor(0.0421, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9424, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1308, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.2634, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0596, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8296, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e015-i0054 => L=7.889 acc= 59% / t(ms):   5.3  71.5 394.7)\n",
      "self.output_loss= tensor(0.0637, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.2339, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0520, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0130, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0639, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6157, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e015-i0057 => L=7.680 acc= 59% / t(ms):   5.2  71.3 402.3)\n",
      "self.output_loss= tensor(0.0269, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0356, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0597, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7977, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0720, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.3750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e015-i0060 => L=7.447 acc= 56% / t(ms):   5.1  71.2 399.0)\n",
      "self.output_loss= tensor(0.0641, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5161, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0415, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4616, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0475, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5262, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e015-i0063 => L=7.574 acc= 38% / t(ms):   5.0  71.1 385.6)\n",
      "self.output_loss= tensor(0.0261, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.2075, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0984, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9177, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0415, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6863, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e015-i0066 => L=7.728 acc= 60% / t(ms):   4.9  71.2 383.6)\n",
      "self.output_loss= tensor(0.1188, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5782, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0249, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6122, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0502, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9267, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e015-i0069 => L=7.977 acc= 59% / t(ms):   5.0  71.4 384.7)\n",
      "self.output_loss= tensor(0.1302, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5160, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0511, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.2915, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e015-i0071 => L=7.343 acc= 53% / t(ms):   5.1  70.9 393.1)\n",
      "self.output_loss= tensor(0.0248, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0802, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0725, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7440, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0259, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.2571, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e015-i0074 => L=7.283 acc= 65% / t(ms):   5.2  70.9 393.4)\n",
      "self.output_loss= tensor(0.0359, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7379, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0487, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5404, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0521, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6141, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e015-i0077 => L=7.666 acc= 56% / t(ms):   5.1  71.0 397.6)\n",
      "self.output_loss= tensor(0.0571, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7753, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0559, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4809, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0594, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4404, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e015-i0080 => L=7.500 acc= 71% / t(ms):   5.1  70.8 396.3)\n",
      "self.output_loss= tensor(0.0322, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6311, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0330, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6930, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0696, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9668, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e015-i0083 => L=8.036 acc= 52% / t(ms):   4.8  69.2 395.0)\n",
      "self.output_loss= tensor(0.0317, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8852, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0445, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9253, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0417, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6097, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e015-i0086 => L=7.651 acc= 70% / t(ms):   5.0  69.2 402.5)\n",
      "self.output_loss= tensor(0.0647, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6501, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0745, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1416, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0446, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4362, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e015-i0089 => L=7.481 acc= 45% / t(ms):   5.1  69.9 384.1)\n",
      "self.output_loss= tensor(0.0326, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5734, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0479, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6022, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1141, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7591, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e015-i0092 => L=7.873 acc= 68% / t(ms):   5.5  69.6 390.8)\n",
      "self.output_loss= tensor(0.0612, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5845, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0525, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7145, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0284, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e015-i0095 => L=7.528 acc= 62% / t(ms):   5.3  69.5 389.4)\n",
      "self.output_loss= tensor(0.0523, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6733, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.3414, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4751, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e015-i0097 => L=7.816 acc= 75% / t(ms):   6.7  72.5 401.9)\n",
      "self.output_loss= tensor(0.0369, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5183, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0428, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.2720, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Validation : 4.0% (timings : 33.88 7.95)\n",
      "Validation : 28.0% (timings : 18.70 22.47)\n",
      "Validation : 50.0% (timings : 17.05 27.45)\n",
      "Validation : 77.0% (timings : 9.97 29.43)\n",
      "field_list[0].shape[0] is 382707\n",
      "AHN mean IoU = 70.8%\n",
      "self.output_loss= tensor(0.0624, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7557, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e016-i0000 => L=7.818 acc= 70% / t(ms): 6429.0  98.1 432.5)\n",
      "self.output_loss= tensor(0.1607, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7160, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0834, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9011, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0262, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4107, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e016-i0003 => L=7.437 acc= 62% / t(ms):  31.0  69.9 373.7)\n",
      "self.output_loss= tensor(0.0512, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.3210, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0387, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.1716, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0614, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.3792, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e016-i0006 => L=7.441 acc= 55% / t(ms):  24.1  70.2 383.0)\n",
      "self.output_loss= tensor(0.0830, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1232, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0399, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.3297, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0382, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4228, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e016-i0009 => L=7.461 acc= 55% / t(ms):  19.1  70.3 375.1)\n",
      "self.output_loss= tensor(0.0357, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7172, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0804, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4129, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0393, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5573, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e016-i0012 => L=7.597 acc= 59% / t(ms):  15.2  70.2 368.6)\n",
      "self.output_loss= tensor(0.0831, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0628, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0351, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6164, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1031, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7850, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e016-i0015 => L=7.888 acc= 60% / t(ms):  12.4  70.3 372.0)\n",
      "self.output_loss= tensor(0.0295, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4366, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0454, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9659, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0543, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1391, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e016-i0018 => L=8.193 acc= 51% / t(ms):  10.4  70.4 374.3)\n",
      "self.output_loss= tensor(0.0412, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7982, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0562, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7155, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0728, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5591, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e016-i0021 => L=7.632 acc= 46% / t(ms):   8.9  70.3 376.6)\n",
      "self.output_loss= tensor(0.0465, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.3040, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0337, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4872, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e016-i0023 => L=7.521 acc= 62% / t(ms):   8.1  70.4 388.0)\n",
      "self.output_loss= tensor(0.0685, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4448, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0528, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8686, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0325, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.3727, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e016-i0026 => L=7.405 acc= 58% / t(ms):   7.3  70.3 383.3)\n",
      "self.output_loss= tensor(0.0405, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6199, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0548, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4574, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0174, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6107, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e016-i0029 => L=7.628 acc= 54% / t(ms):   6.6  70.6 392.6)\n",
      "self.output_loss= tensor(0.0303, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4106, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0574, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5266, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e016-i0031 => L=7.584 acc= 65% / t(ms):   6.6  70.5 400.7)\n",
      "self.output_loss= tensor(0.0419, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5054, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0422, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6334, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0374, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.4427, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e016-i0034 => L=8.480 acc= 64% / t(ms):   6.3  70.3 393.2)\n",
      "self.output_loss= tensor(0.0609, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6283, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0274, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5205, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e016-i0036 => L=7.548 acc= 53% / t(ms):   6.0  70.5 400.4)\n",
      "self.output_loss= tensor(0.0248, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8126, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0395, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5445, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0385, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.3060, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e016-i0039 => L=7.344 acc= 65% / t(ms):   5.9  70.5 397.0)\n",
      "self.output_loss= tensor(0.0485, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9889, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1518, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7279, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0799, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e016-i0042 => L=7.480 acc= 48% / t(ms):   5.6  70.3 376.2)\n",
      "self.output_loss= tensor(0.0511, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5987, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0289, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.3814, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0389, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2457, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e016-i0045 => L=8.285 acc= 45% / t(ms):   5.4  70.3 380.8)\n",
      "self.output_loss= tensor(0.0471, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.3353, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0608, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.2548, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0483, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8245, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e016-i0048 => L=7.873 acc= 63% / t(ms):   5.3  70.5 385.0)\n",
      "self.output_loss= tensor(0.0338, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.2385, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0698, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7467, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0336, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6058, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e016-i0051 => L=7.639 acc= 64% / t(ms):   5.2  70.4 386.0)\n",
      "self.output_loss= tensor(0.0560, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.2363, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0398, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5907, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e016-i0053 => L=7.630 acc= 67% / t(ms):   5.2  70.4 397.0)\n",
      "self.output_loss= tensor(0.0525, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6068, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0484, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.3782, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1627, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7383, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e016-i0056 => L=7.901 acc= 42% / t(ms):   5.1  70.4 381.2)\n",
      "self.output_loss= tensor(0.0921, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0867, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0294, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5679, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0750, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1536, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e016-i0059 => L=8.229 acc= 52% / t(ms):   5.0  70.6 383.7)\n",
      "self.output_loss= tensor(0.0462, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8125, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0369, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.3668, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0433, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7075, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e016-i0062 => L=7.751 acc= 61% / t(ms):   4.9  70.3 390.1)\n",
      "self.output_loss= tensor(0.0415, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7717, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0323, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8912, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0744, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9679, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e016-i0065 => L=8.042 acc= 55% / t(ms):   5.0  70.6 390.8)\n",
      "self.output_loss= tensor(0.1049, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8294, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0645, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2235, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0222, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.2457, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e016-i0068 => L=7.268 acc= 64% / t(ms):   5.0  70.9 376.1)\n",
      "self.output_loss= tensor(0.0198, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.3614, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0557, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9767, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0282, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4546, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e016-i0071 => L=7.483 acc= 71% / t(ms):   4.9  70.6 384.4)\n",
      "self.output_loss= tensor(0.0376, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7081, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0364, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7372, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0480, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4875, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e016-i0074 => L=7.535 acc= 59% / t(ms):   5.1  70.8 388.6)\n",
      "self.output_loss= tensor(0.0705, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6415, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0289, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0424, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1493, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5974, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e016-i0077 => L=7.747 acc= 74% / t(ms):   5.1  70.7 398.2)\n",
      "self.output_loss= tensor(0.0269, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5385, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0484, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7937, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0950, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1447, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e016-i0080 => L=8.240 acc= 48% / t(ms):   5.0  70.5 394.0)\n",
      "self.output_loss= tensor(0.0395, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6605, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0762, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6420, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0346, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4912, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e016-i0083 => L=7.526 acc= 62% / t(ms):   4.9  68.9 394.7)\n",
      "self.output_loss= tensor(0.0565, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6670, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0438, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.2395, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e016-i0085 => L=7.283 acc= 69% / t(ms):   5.0  68.0 406.7)\n",
      "self.output_loss= tensor(0.0574, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9466, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0985, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8771, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0603, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4629, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e016-i0088 => L=7.523 acc= 75% / t(ms):   4.8  66.8 403.2)\n",
      "self.output_loss= tensor(0.0258, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7087, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1447, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6124, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0254, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8984, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e016-i0091 => L=7.924 acc= 40% / t(ms):   4.9  66.0 396.9)\n",
      "self.output_loss= tensor(0.0583, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8622, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0559, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6568, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0449, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5348, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e016-i0094 => L=7.580 acc= 68% / t(ms):   4.7  65.4 399.2)\n",
      "self.output_loss= tensor(0.0532, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8016, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0430, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4473, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0698, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8993, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e016-i0097 => L=7.969 acc= 50% / t(ms):   4.6  65.1 390.6)\n",
      "self.output_loss= tensor(0.0737, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6309, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0537, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7520, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Validation : 2.0% (timings : 40.74 5.84)\n",
      "Validation : 27.0% (timings : 19.40 23.32)\n",
      "Validation : 50.0% (timings : 16.46 28.54)\n",
      "Validation : 76.0% (timings : 10.13 30.23)\n",
      "field_list[0].shape[0] is 382707\n",
      "AHN mean IoU = 72.2%\n",
      "self.output_loss= tensor(0.0890, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6027, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e017-i0000 => L=7.692 acc= 65% / t(ms): 6507.1  84.0 437.4)\n",
      "self.output_loss= tensor(0.0445, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5173, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0719, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4400, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e017-i0002 => L=7.512 acc= 65% / t(ms):  33.5  90.7 433.1)\n",
      "self.output_loss= tensor(0.0577, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5155, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0470, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2206, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0460, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4511, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e017-i0005 => L=7.497 acc= 61% / t(ms):  25.8  85.6 427.6)\n",
      "self.output_loss= tensor(0.0874, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5204, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0367, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4531, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e017-i0007 => L=7.490 acc= 68% / t(ms):  21.8  82.8 428.9)\n",
      "self.output_loss= tensor(0.1026, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7110, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0725, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.3965, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1347, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7043, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e017-i0010 => L=7.839 acc= 51% / t(ms):  17.3  79.3 401.7)\n",
      "self.output_loss= tensor(0.0374, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6535, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0537, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7600, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0604, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.2582, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e017-i0013 => L=7.319 acc= 67% / t(ms):  13.9  77.1 404.2)\n",
      "self.output_loss= tensor(0.0817, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.3140, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0426, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4847, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0954, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4412, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e017-i0016 => L=7.537 acc= 54% / t(ms):  11.5  75.5 404.9)\n",
      "self.output_loss= tensor(0.0504, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9189, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0744, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4587, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0769, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7422, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e017-i0019 => L=7.819 acc= 57% / t(ms):   9.6  74.2 399.3)\n",
      "self.output_loss= tensor(0.0237, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4668, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0592, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7418, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1005, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6095, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e017-i0022 => L=7.710 acc= 50% / t(ms):   8.3  73.5 390.5)\n",
      "self.output_loss= tensor(0.0378, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5717, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0360, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4407, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0515, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4792, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e017-i0025 => L=7.531 acc= 70% / t(ms):   7.4  72.9 393.2)\n",
      "self.output_loss= tensor(0.0546, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.3167, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0705, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4187, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e017-i0027 => L=7.489 acc= 72% / t(ms):   6.9  72.7 399.9)\n",
      "self.output_loss= tensor(0.0663, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4147, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0414, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5738, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0257, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.1778, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e017-i0030 => L=7.203 acc= 55% / t(ms):   6.3  72.1 395.7)\n",
      "self.output_loss= tensor(0.0561, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4373, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0435, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7029, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e017-i0032 => L=7.746 acc= 61% / t(ms):   6.0  71.9 400.9)\n",
      "self.output_loss= tensor(0.0295, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7459, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0848, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4052, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0403, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5270, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e017-i0035 => L=7.567 acc= 64% / t(ms):   5.8  71.7 396.4)\n",
      "self.output_loss= tensor(0.0499, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6095, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0317, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6613, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0564, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7915, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e017-i0038 => L=7.848 acc= 47% / t(ms):   5.6  71.3 381.4)\n",
      "self.output_loss= tensor(0.0901, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.3994, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0407, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5499, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0420, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5879, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e017-i0041 => L=7.630 acc= 48% / t(ms):   5.6  71.3 383.9)\n",
      "self.output_loss= tensor(0.0629, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0429, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0355, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5221, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0295, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4423, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e017-i0044 => L=7.472 acc= 47% / t(ms):   5.3  71.1 381.7)\n",
      "self.output_loss= tensor(0.0529, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.0470, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0537, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5207, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1147, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4158, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e017-i0047 => L=7.531 acc= 72% / t(ms):   5.5  71.3 391.9)\n",
      "self.output_loss= tensor(0.0839, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5608, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0367, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8924, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0628, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6423, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e017-i0050 => L=7.705 acc= 69% / t(ms):   5.2  71.1 392.0)\n",
      "self.output_loss= tensor(0.0410, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.2696, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0826, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8330, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0339, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.1304, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e017-i0053 => L=7.164 acc= 69% / t(ms):   5.1  71.1 395.7)\n",
      "self.output_loss= tensor(0.0741, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5762, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0546, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8873, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0253, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.3317, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e017-i0056 => L=7.357 acc= 61% / t(ms):   5.0  71.2 402.8)\n",
      "self.output_loss= tensor(0.0937, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5927, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0567, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9426, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0939, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7624, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e017-i0059 => L=7.856 acc= 49% / t(ms):   5.0  71.1 398.8)\n",
      "self.output_loss= tensor(0.0698, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7495, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0459, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9319, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0399, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e017-i0062 => L=7.765 acc= 66% / t(ms):   5.3  71.1 403.4)\n",
      "self.output_loss= tensor(0.0289, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8293, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0327, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7520, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e017-i0064 => L=7.785 acc= 63% / t(ms):   5.2  73.6 406.5)\n",
      "self.output_loss= tensor(0.0952, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0017, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0325, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4325, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0344, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7219, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e017-i0067 => L=7.756 acc= 66% / t(ms):   5.1  72.7 399.7)\n",
      "self.output_loss= tensor(0.0398, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5072, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0324, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4190, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0515, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5059, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e017-i0070 => L=7.557 acc= 59% / t(ms):   5.2  72.4 402.6)\n",
      "self.output_loss= tensor(0.0544, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5031, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0353, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5545, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0484, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6592, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e017-i0073 => L=7.708 acc= 47% / t(ms):   5.2  72.2 392.7)\n",
      "self.output_loss= tensor(0.0403, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6081, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0571, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5923, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0570, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1865, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e017-i0076 => L=8.244 acc= 34% / t(ms):   5.1  71.9 373.7)\n",
      "self.output_loss= tensor(0.0326, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4775, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0655, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6329, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0540, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.1168, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e017-i0079 => L=7.171 acc= 53% / t(ms):   5.2  71.8 377.6)\n",
      "self.output_loss= tensor(0.0553, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9504, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0702, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5653, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0710, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.3387, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e017-i0082 => L=7.410 acc= 63% / t(ms):   5.3  70.4 386.4)\n",
      "self.output_loss= tensor(0.0547, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9394, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0585, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5860, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0400, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.3082, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e017-i0085 => L=7.348 acc= 66% / t(ms):   5.1  68.9 395.6)\n",
      "self.output_loss= tensor(0.0460, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.1854, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0473, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9318, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0933, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0583, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e017-i0088 => L=8.152 acc= 46% / t(ms):   4.9  67.8 381.1)\n",
      "self.output_loss= tensor(0.0384, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.3605, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0266, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7970, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0518, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.3133, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e017-i0091 => L=7.365 acc= 46% / t(ms):   5.2  67.1 383.6)\n",
      "self.output_loss= tensor(0.0453, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4092, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0507, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.1946, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0500, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5015, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e017-i0094 => L=7.552 acc= 60% / t(ms):   5.1  66.5 383.7)\n",
      "self.output_loss= tensor(0.0340, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4063, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0552, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6476, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0331, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7215, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e017-i0097 => L=7.755 acc= 65% / t(ms):   4.9  65.8 389.2)\n",
      "self.output_loss= tensor(0.0681, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4911, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0237, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4649, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e017-i0099 => L=7.489 acc= 58% / t(ms):   4.7  65.7 399.0)\n",
      "Validation : 4.0% (timings : 34.49 7.79)\n",
      "Validation : 29.0% (timings : 16.85 23.19)\n",
      "Validation : 50.0% (timings : 18.23 27.68)\n",
      "Validation : 78.0% (timings : 8.79 30.03)\n",
      "field_list[0].shape[0] is 382707\n",
      "AHN mean IoU = 71.6%\n",
      "self.output_loss= tensor(0.0498, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9716, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e018-i0000 => L=8.021 acc= 47% / t(ms): 6351.4 107.0 361.0)\n",
      "self.output_loss= tensor(0.1390, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9178, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0872, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0393, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2147, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e018-i0003 => L=8.254 acc= 52% / t(ms):  41.1  90.8 349.6)\n",
      "self.output_loss= tensor(0.1391, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5478, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0551, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7080, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0601, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7161, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e018-i0006 => L=7.776 acc= 51% / t(ms):  31.4  85.7 352.8)\n",
      "self.output_loss= tensor(0.0246, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6535, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0357, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5503, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e018-i0008 => L=7.586 acc= 76% / t(ms):  27.3  84.7 372.4)\n",
      "self.output_loss= tensor(0.0635, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4896, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0470, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6350, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0322, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4736, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e018-i0011 => L=7.506 acc= 50% / t(ms):  22.6  87.0 372.2)\n",
      "self.output_loss= tensor(0.0268, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6886, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0701, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.2286, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0318, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6811, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e018-i0014 => L=7.713 acc= 63% / t(ms):  18.0  84.4 379.9)\n",
      "self.output_loss= tensor(0.0337, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6880, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0381, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5874, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0348, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2856, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e018-i0017 => L=8.320 acc= 65% / t(ms):  14.4  80.7 387.8)\n",
      "self.output_loss= tensor(0.1881, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.2659, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0515, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6766, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0278, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8083, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e018-i0020 => L=7.836 acc= 57% / t(ms):  11.8  78.1 390.1)\n",
      "self.output_loss= tensor(0.0318, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5361, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0324, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4846, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e018-i0022 => L=7.517 acc= 63% / t(ms):  10.5  76.8 397.0)\n",
      "self.output_loss= tensor(0.0281, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9186, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0668, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5323, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0495, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5746, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e018-i0025 => L=7.624 acc= 61% / t(ms):   8.9  75.5 392.0)\n",
      "self.output_loss= tensor(0.0289, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8988, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0379, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6546, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0214, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7402, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e018-i0028 => L=7.762 acc= 59% / t(ms):   8.0  74.3 391.0)\n",
      "self.output_loss= tensor(0.0383, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4306, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0478, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2249, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0420, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7028, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e018-i0031 => L=7.745 acc= 71% / t(ms):   7.2  73.4 394.9)\n",
      "self.output_loss= tensor(0.0500, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7642, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0307, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5645, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0380, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6473, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e018-i0034 => L=7.685 acc= 64% / t(ms):   6.5  72.8 401.8)\n",
      "self.output_loss= tensor(0.0446, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5952, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1445, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8703, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0478, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6749, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e018-i0037 => L=7.723 acc= 79% / t(ms):   6.5  72.2 397.3)\n",
      "self.output_loss= tensor(0.0474, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7100, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0427, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.3927, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0110, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4282, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e018-i0040 => L=7.439 acc= 56% / t(ms):   6.1  71.9 395.9)\n",
      "self.output_loss= tensor(0.0291, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6345, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0185, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4870, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0405, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6884, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e018-i0043 => L=7.729 acc= 63% / t(ms):   5.7  71.6 395.6)\n",
      "self.output_loss= tensor(0.0389, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.3876, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0292, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4432, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0395, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.3116, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e018-i0046 => L=7.351 acc= 57% / t(ms):   5.5  71.4 390.7)\n",
      "self.output_loss= tensor(0.0265, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.3988, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0322, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4118, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0205, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.1371, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e018-i0049 => L=7.158 acc= 68% / t(ms):   5.3  71.1 389.1)\n",
      "self.output_loss= tensor(0.0316, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8346, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0252, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.6163, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0444, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.2937, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e018-i0052 => L=7.338 acc= 73% / t(ms):   5.1  70.9 396.7)\n",
      "self.output_loss= tensor(0.0323, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.1979, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0322, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6070, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1406, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7753, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e018-i0055 => L=7.916 acc= 48% / t(ms):   5.3  71.0 397.1)\n",
      "self.output_loss= tensor(0.0518, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6304, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0560, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5122, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0391, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7427, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e018-i0058 => L=7.782 acc= 59% / t(ms):   5.2  71.2 391.3)\n",
      "self.output_loss= tensor(0.0586, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5792, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0375, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5363, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0934, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8227, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e018-i0061 => L=7.916 acc= 62% / t(ms):   5.1  71.2 384.7)\n",
      "self.output_loss= tensor(0.0405, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9445, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0346, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8847, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0476, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.3944, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e018-i0064 => L=7.442 acc= 48% / t(ms):   5.1  71.2 387.9)\n",
      "self.output_loss= tensor(0.0551, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.9314, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0529, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5702, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0367, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7131, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e018-i0067 => L=7.750 acc= 64% / t(ms):   5.2  71.1 392.8)\n",
      "self.output_loss= tensor(0.0544, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8014, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0380, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5274, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0585, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.0346, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e018-i0070 => L=8.093 acc= 46% / t(ms):   5.2  71.1 380.2)\n",
      "self.output_loss= tensor(0.0543, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.3120, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.1057, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.2604, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0533, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.3169, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e018-i0073 => L=7.370 acc= 56% / t(ms):   5.2  71.3 369.6)\n",
      "self.output_loss= tensor(0.0607, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.2593, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0597, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8207, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0537, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5685, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e018-i0076 => L=7.622 acc= 62% / t(ms):   5.0  71.1 374.6)\n",
      "self.output_loss= tensor(0.0372, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6437, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0351, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6196, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0525, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6269, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e018-i0079 => L=7.679 acc= 56% / t(ms):   4.9  71.1 374.8)\n",
      "self.output_loss= tensor(0.0467, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.2773, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0559, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.1816, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0505, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.3365, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e018-i0082 => L=7.387 acc= 64% / t(ms):   5.1  70.0 382.5)\n",
      "self.output_loss= tensor(0.0628, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7309, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0227, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4663, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0400, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6594, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e018-i0085 => L=7.699 acc= 57% / t(ms):   4.9  68.5 384.5)\n",
      "self.output_loss= tensor(0.0290, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.2787, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0588, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.3911, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0896, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.5640, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e018-i0088 => L=7.654 acc= 40% / t(ms):   4.7  67.4 372.6)\n",
      "self.output_loss= tensor(0.0443, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.4995, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0546, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.2967, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0677, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.0818, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e018-i0091 => L=7.149 acc= 70% / t(ms):   5.0  66.6 386.5)\n",
      "self.output_loss= tensor(0.0319, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6836, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0369, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.7705, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0343, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.3561, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e018-i0094 => L=7.390 acc= 52% / t(ms):   4.8  66.0 384.8)\n",
      "self.output_loss= tensor(0.0283, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6707, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0728, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.3634, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0368, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(8.1773, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "e018-i0097 => L=8.214 acc= 66% / t(ms):   4.7  65.7 393.0)\n",
      "self.output_loss= tensor(0.0300, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.8464, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "self.output_loss= tensor(0.0377, device='cuda:0', grad_fn=<NllLoss2DBackward>) self.reg_loss= tensor(7.6518, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Validation : 4.0% (timings : 34.54 7.66)\n",
      "Validation : 30.0% (timings : 18.35 23.93)\n",
      "Validation : 55.0% (timings : 11.86 28.98)\n",
      "Validation : 81.0% (timings : 12.80 30.69)\n",
      "field_list[0].shape[0] is 382707\n",
      "AHN mean IoU = 71.5%\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "print('\\nStart training')\n",
    "print('**************')\n",
    "\n",
    "# Training\n",
    "trainer.train(net, training_loader, test_loader, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('Forcing exit now')\n",
    "#os.kill(os.getpid(), signal.SIGINT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
